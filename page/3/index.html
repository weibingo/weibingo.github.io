<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="BIG DATA探索者,经济迷,浅度摄影,爱好历史,对社会意识,人文感兴趣"><meta name="keywords" content=""><meta name="author" content="weibingo"><meta name="copyright" content="weibingo"><title>BIG DATA探索者,经济迷,历史,人文 | WBINGのBLOG</title><link rel="shortcut icon" href="/favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.8.0"><link rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/4.7.0/css/font-awesome.min.css?version=1.8.0"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.css"><script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.js" defer></script><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://v1.hitokoto.cn/?encode=js&amp;charset=utf-8&amp;select=.footer_custom_text" defer></script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: {"appId":"3FYJCLGPHO","apiKey":"d730ef95ff5ff79a19b74363531c066b","indexName":"prod_weibing-blog","hits":{"per_page":10},"languages":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}.","hits_stats":"${hits} results found in ${time} ms"}},
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script><meta name="generator" content="Hexo 6.3.0"></head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="false"><div class="author-info"><div class="author-info__avatar text-center"><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/page/avatar.jpg"></div><div class="author-info__name text-center">weibingo</div><div class="author-info__description text-center">BIG DATA探索者,经济迷,浅度摄影,爱好历史,对社会意识,人文感兴趣</div><div class="follow-button"><a target="_blank" rel="noopener" href="https://github.com/weibingo">Follow Me</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">52</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">43</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">21</span></a></div></div></div><nav id="nav" style="background-image: url(https://hexo-1256892004.cos.ap-beijing.myqcloud.com/page/top.jpg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">WBINGのBLOG</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span><span class="pull-right"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> Search</span></a></span></div><div id="site-info"><div id="site-title">WBINGのBLOG</div><div id="site-sub-title">BIG DATA探索者,经济迷,历史,人文</div><div id="site-social-icons"><a class="social-icon" href="https://github.com/weibingo" target="_blank" rel="noreferrer noopener nofollow"><i class="fa-github fa"></i></a><a class="social-icon" href="https://www.jianshu.com/u/0352716a8f7d" target="_blank" rel="noreferrer noopener nofollow"><i class="fa-book fa"></i></a></div></div></nav><div id="content-outer"><div class="layout" id="content-inner"><div class="recent-post-item article-container"><a class="article-title" href="/article/2020%E6%80%BB%E7%BB%93.html">2020年回顾与感想</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2021-01-01</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E6%88%90%E9%95%BF/">成长</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E6%80%BB%E7%BB%93/">总结</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E8%A7%84%E5%88%92/">规划</a></span><div class="content"><h2 id="一、前言"><a href="#一、前言" class="headerlink" title="一、前言"></a>一、前言</h2><p>在想以何种样式来写年度总结，之前<strong>2018年的总结</strong>以挑出各个维度的几件事来总结，通过此来反思做的好的，做的差的，以及来年目标，这种挺新颖，但目标量化性不够，聚焦性不足。正好最终工作上要进行季度述职，所以打算用比较枯燥但深刻的述职模板来承载2020年总结吧。</p>
<h2 id="二、2020年总结"><a href="#二、2020年总结" class="headerlink" title="二、2020年总结"></a><strong>二、2020年总结</strong></h2><p>请重点回顾在本人在周期内的关键策略进展、重要进展、目标达成等。</p>
<h3 id="1、个人目标"><a href="#1、个人目标" class="headerlink" title="1、个人目标"></a><strong>1、个人目标</strong></h3><p>上阶段有什么个人目标</p>
<table>
<thead>
<tr>
<th><strong>阶段性目标</strong></th>
<th><strong>路径</strong></th>
</tr>
</thead>
<tbody><tr>
<td>技术能力</td>
<td>1，提升系统架构能力，能够通用性、易用性、扩展性延伸<br />2，提升技术决策能力，多调研，多总结</td>
</tr>
<tr>
<td>表达能力</td>
<td>1，提升自我沟通表达能力</td>
</tr>
<tr>
<td>经济知识能力</td>
<td>1，增加自己以经济视角看待问题能力，尝试不同的投资类型<br /></td>
</tr>
</tbody></table>
<h3 id="2、目标完成情况及工作成果"><a href="#2、目标完成情况及工作成果" class="headerlink" title="2、目标完成情况及工作成果"></a><strong>2、目标完成情况及工作成果</strong></h3><p>上阶段目标完成情况，取得了什么亮点&#x2F;成果（如有对标情况，请列举），有什么认知迭代</p></div><a class="more" href="/article/2020%E6%80%BB%E7%BB%93.html#more">Read more</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/article/doris.html">doris介绍</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-12-30</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B/">数据工程</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B/OLAP/">OLAP</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E6%95%B0%E6%8D%AE/">数据</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/OLAP/">OLAP</a></span><div class="content"><h1 id="1-基本概念"><a href="#1-基本概念" class="headerlink" title="1.基本概念"></a>1.基本概念</h1><h2 id="1-1Doris-Palo-简介"><a href="#1-1Doris-Palo-简介" class="headerlink" title="1.1Doris(Palo) 简介"></a>1.1Doris(Palo) 简介</h2><p><strong>Doris 是一个 MPP 的在线 OLAP 系统，主要整合了 Google Mesa （数据模型），Apache Impala （MPP query engine) 和 ORCFile &#x2F; Parquet (存储格式，编码和压缩) 的技术。</strong></p>
<p>Doris 具有以下特点：</p>
<ul>
<li>无外部系统依赖</li>
<li>高可靠，高可用，高可扩展</li>
<li>同时支持 高并发点查询和高吞吐的 Ad-hoc 查询</li>
<li>同时支持 批量导入和近实时 mini-batch 导入</li>
<li>兼容 MySQL 协议</li>
<li>支持 Rollup Table 和 Rollup Table 的智能查询路由</li>
<li>支持多表 Join</li>
<li>支持 Schema 在线变更</li>
<li>支持存储分级，旧的冷数据用 SATA，新的热数据用 SSD</li>
</ul>
<p>Doris 的系统架构如下:</p>
<p><strong>Doris 主要分为 FE 和 BE 两种角色，FE 主要负责查询的编译，分发和元数据管理（基于内存，类似 HDFS NN）；BE 主要负责查询的执行和存储系统。</strong></p>
<p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/doris/20201228001916-r6dgky4-doris-fe.png"></p></div><a class="more" href="/article/doris.html#more">Read more</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/article/Flink-Watermark.html">Flink：什么是 Watermark？</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-07-25</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B/">数据工程</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B/flink/">flink</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/flink/">flink</a></span><div class="content"><h1 id="1、什么是-watermark"><a href="#1、什么是-watermark" class="headerlink" title="1、什么是 watermark"></a>1、什么是 watermark</h1><p>watermark 网上有翻译成水印，但更应该是水位线，即 <strong>Flink 接受的数据就相当于浮在水面的物体， 基于物理知识，水位线的高度只会升高不会降低，那么每当新数据进来，会重新计算水位线的时间，计算结果小于当前水位线时间，则不会更新现有的水位线。 当水位线到达窗口触发时间时才会触发窗口的计算</strong>。watermark 的意义在于数据无序传递的时候有一定容错率，如果晚来的数据在容错范围之内，会当做正常传递来处理。</p>
<p>乍一看还是懵逼，那么就看下面的分析。</p>
<h1 id="2、什么是流处理"><a href="#2、什么是流处理" class="headerlink" title="2、什么是流处理"></a>2、什么是流处理</h1><p>Flink 被称为真正的流式实时计算框架，其批处理中是流处理的特殊情况。而所谓的流处理，本质特点是在处理数据时，接受一条处理一条。而批处理则是累积数据到一定程度在处理。这是他们本质的区别。</p>
<p>假如我们自己写一个流式框架。我们该如何处理消息。如下，我们看到消息按照顺序一个个发送，接受后按照顺序处理，这是没有什么问题的。</p>
<p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/flink/watermark/shunxu.png"></p>
<p>如果消息不按照顺序发送，产生了乱序，这时候该怎么处理？</p>
<p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/flink/watermark/luanxu.png"></p>
<p>其实水位线 Watermark 就是其中的解决方案之一。</p></div><a class="more" href="/article/Flink-Watermark.html#more">Read more</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/article/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E8%B6%8B%E5%8A%BF%EF%BC%9A%E4%BB%8E%E5%8F%AC%E5%9B%9E%E5%88%B0%E6%8E%92%E5%BA%8F%E5%86%8D%E5%88%B0%E9%87%8D%E6%8E%92.html">推荐系统技术演进趋势：从召回到排序再到重排</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-07-06</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E7%AE%97%E6%B3%95/">算法</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E7%AE%97%E6%B3%95/%E6%8E%A8%E8%8D%90/">推荐</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E6%A8%A1%E5%9E%8B/">模型</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E6%8E%A8%E8%8D%90/">推荐</a></span><div class="content"><p>推荐系统技术，总体而言，与NLP和图像领域比，发展速度不算太快。不过最近两年，由于深度学习等一些新技术的引入，总体还是表现出了一些比较明显的技术发展趋势。这篇文章试图从推荐系统几个环节，以及不同的技术角度，来对目前推荐技术的比较彰显的技术趋势做个归纳。个人判断较多，偏颇难免，所以还请谨慎参考。</p>
<p>在写技术趋势前，照例还是对推荐系统的宏观架构做个简单说明，以免读者迷失在技术细节中。</p>
<p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/recommend/recommend.jpg">实际的工业推荐系统，如果粗分的化，经常讲的有两个阶段。首先是召回，主要根据用户部分特征，从海量的物品库里，快速找回一小部分用户潜在感兴趣的物品，然后交给排序环节，排序环节可以融入较多特征，使用复杂模型，来精准地做个性化推荐。召回强调快，排序强调准。当然，这是传统角度看推荐这个事情。</p>
<p>但是，如果我们更细致地看实用的推荐系统，一般会有四个环节，如下图所示：</p>
<p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/recommend/step.jpg"></p>
<p>四个环节分别是：召回、粗排、精排和重排。召回目的如上所述；有时候因为每个用户召回环节返回的物品数量还是太多，怕排序环节速度跟不上，所以可以在召回和精排之间加入一个粗排环节，通过少量用户和物品特征，简单模型，来对召回的结果进行个粗略的排序，在保证一定精准的前提下，进一步减少往后传送的物品数量，粗排往往是可选的，可用可不同，跟场景有关。之后，是精排环节，使用你能想到的任何特征，可以上你能承受速度极限的复杂模型，尽量精准地对物品进行个性化排序。排序完成后，传给重排环节，传统地看，这里往往会上各种技术及业务策略，比如去已读、去重、打散、多样性保证、固定类型物品插入等等，主要是技术产品策略主导或者为了改进用户体验的。</p>
<p>那么，每个环节，从技术发展的角度看，都各自有怎样的发展趋势呢？下面我们分头说明。</p></div><a class="more" href="/article/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E8%B6%8B%E5%8A%BF%EF%BC%9A%E4%BB%8E%E5%8F%AC%E5%9B%9E%E5%88%B0%E6%8E%92%E5%BA%8F%E5%86%8D%E5%88%B0%E9%87%8D%E6%8E%92.html#more">Read more</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/article/HBase%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E4%B9%8BMemStore%E8%BF%9B%E5%8C%96%E8%AE%BA.html">HBase内存管理之MemStore进化论</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-07-04</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/HBase/">HBase</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/HBase/">HBase</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">数据结构</a></span><div class="content"><p>Java工程中内存管理总是一个绕不过去的知识模块，无论HBase、Flink还是Spark等，如果使用的JVM堆比较大同时对读写延迟等性能有较高要求，一般都会选择自己管理内存，而且一般都会选择使用部分堆外内存。HBase系统中有两块大的内存管理模块，一块是MemStore ，一块是BlockCache，这两块内存的管理在HBase的版本迭代过程中不断进行过各种优化，接下来笔者结合自己的理解，将这两个模块的内存管理迭代过程通过几篇文章梳理一遍，相信很多优化方案在各个系统中都有，举一反三，个人觉得对内核开发有很大的学习意义。本篇文章重点集中介绍MemStore内存管理优化。</p>
<h2 id="基于跳表实现的MemStore基础模型"><a href="#基于跳表实现的MemStore基础模型" class="headerlink" title="基于跳表实现的MemStore基础模型"></a>基于跳表实现的MemStore基础模型</h2><p>实现MemStore模型的数据结构是SkipList（跳表），跳表可以实现高效的查询\插入\删除操作，这些操作的期望复杂度都是O(logN)。另外，因为跳表本质上是由链表构成，所以理解和实现都更加简单。这是很多KV数据库（Redis、LevelDB等）使用跳表实现有序数据集合的两个主要原因。跳表数据结构不再赘述，网上有比较多的介绍，可以参考。</p>
<p>JDK原生自带的跳表实现目前只有ConcurrentSkipListMap（简称CSLM，注意：ConcurrentSkipListSet是基于ConcurrentSkipListMap实现的）。ConcurrentSkipListMap是JDK Map的一种实现，所以本质上是一种Map，不过这个Map中的元素是有序的。这个有序的保证就是通过跳表实现的。ConcurrentSkipListMap的结构如下图所示：</p>
<p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/hbase-memstore-evolution/ConcurrentSkipListMap.png"></p>
<p>基于ConcurrentSkipListMap这样的基础数据结构，按照最简单的思路来看，如果写入一个KeyValue到MemStore中，肯定是如下的写入步骤：</p>
<ol>
<li><p>在JVM堆中为KeyValue对象申请一块内存区域。</p>
</li>
<li><p>调用ConcurrentSkipListMap的put(K key, V value)方法将这个KeyValue对象作为参数传入。</p>
</li>
</ol></div><a class="more" href="/article/HBase%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E4%B9%8BMemStore%E8%BF%9B%E5%8C%96%E8%AE%BA.html#more">Read more</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/article/%E4%BB%8E%E4%B8%80%E5%8F%A5%E6%83%85%E8%AF%9D%E6%9D%A5%E4%BA%86%E8%A7%A3%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%91%E5%B1%95.html">从一句情话来了解语言模型的发展</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-07-04</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E7%AE%97%E6%B3%95/">算法</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E7%AE%97%E6%B3%95/NLP/">NLP</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E6%A8%A1%E5%9E%8B/">模型</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/NLP/">NLP</a></span><div class="content"><h2 id="问题定义"><a href="#问题定义" class="headerlink" title="问题定义"></a>问题定义</h2><p>一段文字，例如：今夜月色真美。代表的是什么含义？如果在春天温度适宜的 9、10 点站在阳台的人对你脱口而出地说出这句话，你会怎么理解这句话，亦或者你会怎么回应他(她)呢？</p>
<p>这句话是十九世纪末的文学家 夏目漱石对 <code>I love you</code> 的英译日标注结果（今夜は月が綺麗ですね）。根据他的标注 <code>我爱你</code> 和 <code>今夜月色真美</code> 表达了相同的意义。但是计算机这么认为吗？输入 <code>今夜月色真美</code>，它理解这句话和 <code>我爱你</code> 是相似的含义吗？这个可以被归类为自然语言理解(NLU)领域的语义匹配问题。</p>
<p>众所周知在计算机中一切都是数字信号，那么如果想让计算机理解一句话的含义，解决 <code>今夜月色真美</code> 和 <code>我爱你</code> 的语义匹配问题，那么先决问题是将一句话表示为一系列的数字信号。一个理所当然的想法是将语料库中的每一个词w用一个唯一的 n 维向量v&#x3D;[v1​,v2​,…,vn​]来表达，那么数个向量的序列seq&#x3D;{v1​,v2​,…,vm​}就可以表达一句话，这一类方法就是词嵌入模型。本期文章通过对比这个 case 在 <code>one-hot </code>、<code>n-gram </code>、<code>word2vec </code>、<code>BERT</code> 四种语言模型的结果，分析各个方法的优缺点。</p>
<h2 id="one-hot"><a href="#one-hot" class="headerlink" title="one-hot"></a>one-hot</h2><p>一个最简单的想法就是使用 one-hot 向量来表达一个词。具体流程：</p>
<ol>
<li>遍历语料库，统计词的集合W，集合大小为K</li>
<li>将每个词在集合W中的下标的元素为 1，其他位置元素为 0，构建长度为K的 0-1 向量</li>
</ol>
<p>假设我们对 <code>今夜月色真美</code> 的分词结果为：今夜、月色、真、美。那么使用 one-hot 向量就能将这个句子表示为4×K的 0-1 矩阵。我们假设语料库中一共有 10 个词：{我、爱、你、今夜、月色、真、美、今晚、漂亮、喜欢}。那么V今夜​&#x3D;[0,0,0,1,0,0,0,0,0]，V今晚​&#x3D;[0,0,0,0,0,0,0,1,0,0]，V我​&#x3D;[1,0,0,0,0,0,0,0,0,0]。</p>
<p>one-hot 词嵌入方法优点在于简单，并且最大程度地保留了每个词的信息。但是缺点也很明显：</p>
<ol>
<li>对于从未出现在语料库中的未登录词，无法进行兼容。假如词 <code>恨</code> 需要编码，那么只能编码为零向量，否则需要对所有词向量进行更新，扩展向量维度。</li>
<li>丢失了词与词之间的相关信息。例如 <code>今夜</code> 和 <code>今晚</code> 本身是相近语义的词，但是通过 one-hot 编码的向量差异并没有比 <code>我</code> 和 <code>今夜</code> 小。</li>
</ol></div><a class="more" href="/article/%E4%BB%8E%E4%B8%80%E5%8F%A5%E6%83%85%E8%AF%9D%E6%9D%A5%E4%BA%86%E8%A7%A3%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%91%E5%B1%95.html#more">Read more</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/article/dataflow-model.html">Dataflow 模型</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-12-21</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B/">数据工程</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/">流式计算</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/flink/">flink</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/">流式计算</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/spark/">spark</a></span><div class="content"><p>Dataflow 模型：是谷歌在处理无边界数据的实践中，总结的一套 SDK 级别的解决方案，其目标是做到在非有序的，无边界的海量数据上，基于事件时间进行运算，并能根据数据自身的属性进行 window 操作，同时数据处理过程的正确性，延迟，代价可根据需求进行灵活的调整配置。</p>
<h2 id="DataFlow-模型核心"><a href="#DataFlow-模型核心" class="headerlink" title="DataFlow 模型核心"></a>DataFlow 模型核心</h2><p>和 Spark 通过 micro batch 模型来处理 Streaming 场景的出发点不同，Dataflow 认为 batch 的处理模式只是 streaming 处理模式的一个子集。在无边界数据集的处理过程中，要及时产出数据结果，无限等待显然是不可能的，所以必然需要对要处理的数据划定一个窗口区间，从而对数据及时的进行分段处理和产出，而各种处理模式（stream，micro batch，session，batch），本质上，只是窗口的大小不同，窗口的划分方式不同而已。Batch 的处理模式就只是一个窗口区间涵盖了整个有边界的数据集这样的一种特例场景而已。一个设计良好的能处理无边界数据集的系统，完全能在准确性和正确性上做到和“Batch”系统一样甚至应该更好。</p></div><a class="more" href="/article/dataflow-model.html#more">Read more</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/article/%E6%9D%A5%E7%BE%8E%E5%9B%A23%E4%B8%AA%E6%9C%88%E6%80%BB%E7%BB%93.html">来美团3个月总结</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-10-19</time><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E6%80%BB%E7%BB%93/">总结</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E6%80%9D%E8%80%83/">思考</a></span><div class="content"><p>来美团也三个月了，也渐渐习惯这边的风格。再流程制度上，有让我觉得很不错的地方，也有一些需要改善的地方。自己的能力模型上，还有哪些需要提高的，接下来自己需要在这些地方进步。</p>
<h3 id="好的地方"><a href="#好的地方" class="headerlink" title="好的地方"></a>好的地方</h3><ul>
<li>文档。在文档这方便做的挺好的，把工作中很多都能记录下来，比如会议纪要，产品PRD，技术方案，月度总结等，以及各个系统的详细文档等。而且也能搜到很多技术方案设计，能力模型等。这样比较详细的学习别人怎样去做的，怎样设计的。</li>
<li>各个基础平台和系统。在这边不用什么都从头开始，公司提供了各种基础平台，比如服务发布的CI&#x2F;CD工具，微服务的RPC框架，服务治理，熔断降级等系统。以及各种存储，KV存储，es平台，大数据平台等，让自己能够专注于业务，而不需要放很多精力在以来的平台开发运维上面。</li>
<li>流程规范。大公司流程还是比较规范的，如开发上线流程，整套流程每一步都细化，大家按照这套流程开发。极大的规避掉一些因为个人理解偏差和信息对齐上面造成的上线问题，能够保质保量的进行新功能迭代上线。</li>
<li>制定绩效合同，后面绩效根据此打，更大化的做得客观。</li>
<li>因为我原来是做大数据平台的，更多的面向的是公司内部，而现在是面向用户。可以感受到这边对监控，线上问题的也紧要重视。（这个主要是我岗位的变化）</div><a class="more" href="/article/%E6%9D%A5%E7%BE%8E%E5%9B%A23%E4%B8%AA%E6%9C%88%E6%80%BB%E7%BB%93.html#more">Read more</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/article/pass-and-future.html">过去，未来</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-07-01</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E6%88%90%E9%95%BF/">成长</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E6%80%BB%E7%BB%93/">总结</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E7%9B%AE%E6%A0%87/">目标</a></span><div class="content"><p>很快，已经大半年没写博客了，这半年内，一直再准备面试，找工作，终于在7月去了自己还认为不错的公司。也发现自己已经工作四年了。如果要给自己前四年以一个词语做总结的话，我想我会选择“混沌”这个词。</p>
<h3 id="过去"><a href="#过去" class="headerlink" title="过去"></a>过去</h3><p>在物理学上，混沌（chaos）是指确定性动力学系统因对初值敏感而表现出的不可预测的、类似随机性的运动。又称浑沌。英语词Chaos源于希腊语，原始 含义是宇宙初开之前的景象，基本含义主要指混乱、无序的状态。</p>
<p>而自己曾经的过往也是这样的随机飘荡。没有为自己制定一个人生目标，也不造为何而追求，是我之前很长一段时间的状态。主要体现在我认为的以下几点：</p>
<ul>
<li>没有制定人生规划。因为没有大方向，所以很多时候更偏向于随遇而安。</li>
<li>工作单位随意性。和人生规划也有关，所以在面临单位的抉择方便没有去更加的努力。没有想好不同的单位能为我带来什么样的背景和能力。</li>
<li>情感的随意性。在情感方面，自己并没有什么优势，所以更需要自己勇于去争取。而为此，需要去提高自己的设计能力，沟通表达能力，自己却没有过多的在意。</li>
<li>到底想要什么。这个问题思考的不够深刻，因为道路上的一些阻碍，也造成前进方向的左右摇摆。</li>
<li>勇敢去争取的心。无论在工作上，情感上，生活上，如果没有一颗勇敢去争取的心，人很容易颓废，然后陷入自我怀疑。社会因为信息的不对等，所以机会更容易给予勇敢去争取的人，而不去争取的人，却只能抱怨“他不如我，为啥是他”这种无聊的问题。</li>
</ul></div><a class="more" href="/article/pass-and-future.html#more">Read more</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/article/coroutine.html">python协程</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-01-20</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/CS/">CS</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/IO/">IO</a></span><div class="content"><p>这些天，在标签调度上，可预见性的标签调度会越来越多，如果全由调度系统承载，调度系统压力增大，负责调度系统的同事担心会影响其他任务，遂在讨论下，决策开发一个简版的标签执行服务&#x2F;脚本（相比现有调度系统，只保留任务执行控制，例如池化，并发控制等，任务编排，启动时间都由调度系统控制，整个执行服务就是调度系统的一个task）。而我对此持保持意见，我认为应该增强调度系统能力，2333。</p>
<p>既然决策已定，加上部门现在主要使用python，而调度系统也使用的是airflow，所以主要开发语言也定为python。对于此执行服务&#x2F;脚本，希望能够并行的执行任务，并且能够控制每次在跑的任务数。调研了下python的并发模型，以及多线程的知识。很多说python多线程是<a target="_blank" rel="noopener" href="https://www.zhihu.com/question/23474039">鸡肋</a>，而自己也不想引入第三方并发的库，又看到python支持协程，且相比线程轻量很多，代码易理解，遂最终选定使用协程来实现这个需求。</p>
<h3 id="协程"><a href="#协程" class="headerlink" title="协程"></a>协程</h3><p>网上对协程的解释众说纷纭，有说协程是一种用户态的轻量级线程，协程的调度完全由用户控制。wikipedia的定义：<br>协程是一个无优先级的子程序调度组件，允许子程序在特点的地方挂起恢复。但大家对协程的作用倒挺统一的：</p>
<ul>
<li>占用资源少，开个协程只需要K级别内存，而新开个线程则需要M级别</li>
<li>线程之间的上下文切换，性能消耗大，而协程间切换非常快</li>
<li>相比事件驱动模型的回调复杂性，协程易于理解，写协程代码就像写同步代码一样。</li>
<li>协程的调度是协作式调度，需要协程自己主动把控制权转让出去之后，其他协程才能被执行到（很难像抢占式调度那样做到强制的 CPU 控制权切换到其他进程&#x2F;线程）</li>
</ul>
<h3 id="历史的宿命"><a href="#历史的宿命" class="headerlink" title="历史的宿命"></a>历史的宿命</h3><p>在互联网行业面临C10K问题时，线程方案不足以扛住大量的并发，这时的解决方案是epoll() 式的事件循环，nginx在这波潮流中顺利换掉apache上位。同一时间的开发社区为nginx的成绩感到震撼，出现了很多利用事件循环的应用框架，如tornado&#x2F; nodejs，也确实能够跑出更高的分数。而且python&#x2F;ruby 社区受GIL之累，几乎没有并发支持，这时事件循环是一种并发的解放。然而事件循环的异步控制流对开发者并不友好。业务代码中随处可见的mysql&#x2F;memcache调用，迅速地膨胀成一坨callback hell。这时社区发现了协程，在用户态实现上下文切换的工具，把epoll()事件循环隐藏起来，而且成本不高：用每个协程一个用户态的栈，代替手工的状态管理。似乎同时得到了事件循环和线程同步控制流的好处，既得到了epoll()的高性能，又易于开发。甚至通过monkey patch，旧的同步代码可以几乎无缝地得到异步的高性能，真是太完美了。</p></div><a class="more" href="/article/coroutine.html#more">Read more</a><hr></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-chevron-left"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer class="footer-bg" style="background-image: url(https://hexo-1256892004.cos.ap-beijing.myqcloud.com/page/top.jpg)"><div class="layout" id="footer"><div class="copyright">&copy;2017 - 2024 By weibingo</div><div class="framework-info"><span>Driven - </span><a target="_blank" rel="noopener" href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a target="_blank" rel="noopener" href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="footer_custom_text">hitokoto</div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_site_uv"><i class="fa fa-user"></i><span id="busuanzi_value_site_uv"></span><span></span></span><span class="footer-separator">|</span><span id="busuanzi_container_site_pv"><i class="fa fa-eye"></i><span id="busuanzi_value_site_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="/js/third-party/anime.min.js"></script><script src="/js/third-party/jquery.min.js"></script><script src="/js/third-party/jquery.fancybox.min.js"></script><script src="/js/third-party/velocity.min.js"></script><script src="/js/third-party/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.8.0"></script><script src="/js/fancybox.js?version=1.8.0"></script><script src="/js/sidebar.js?version=1.8.0"></script><script src="/js/copy.js?version=1.8.0"></script><script src="/js/fireworks.js?version=1.8.0"></script><script src="/js/transition.js?version=1.8.0"></script><script src="/js/scroll.js?version=1.8.0"></script><script src="/js/head.js?version=1.8.0"></script><script src="/js/search/algolia.js"></script><script src="/js/search/local-search.js"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script><div class="search-dialog" id="algolia-search"><div class="search-dialog__title" id="algolia-search-title">Algolia</div><div id="algolia-input-panel"><div id="algolia-search-input"></div></div><hr><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-stats"></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>