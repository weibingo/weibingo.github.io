<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="BIG DATA探索者,经济迷,浅度摄影,爱好历史,对社会意识,人文感兴趣"><meta name="keywords" content=""><meta name="author" content="weibingo"><meta name="copyright" content="weibingo"><title>BIG DATA探索者,经济迷,历史,人文 | WBINGのBLOG</title><link rel="shortcut icon" href="/favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.8.0"><link rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/4.7.0/css/font-awesome.min.css?version=1.8.0"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.css"><script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.js" defer></script><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://v1.hitokoto.cn/?encode=js&amp;charset=utf-8&amp;select=.footer_custom_text" defer></script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: {"appId":"3FYJCLGPHO","apiKey":"d730ef95ff5ff79a19b74363531c066b","indexName":"prod_weibing-blog","hits":{"per_page":10},"languages":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}.","hits_stats":"${hits} results found in ${time} ms"}},
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script><meta name="generator" content="Hexo 6.3.0"></head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="false"><div class="author-info"><div class="author-info__avatar text-center"><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/page/avatar.jpg"></div><div class="author-info__name text-center">weibingo</div><div class="author-info__description text-center">BIG DATA探索者,经济迷,浅度摄影,爱好历史,对社会意识,人文感兴趣</div><div class="follow-button"><a target="_blank" rel="noopener" href="https://github.com/weibingo">Follow Me</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">52</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">43</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">21</span></a></div></div></div><nav id="nav" style="background-image: url(https://hexo-1256892004.cos.ap-beijing.myqcloud.com/page/top.jpg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">WBINGのBLOG</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span><span class="pull-right"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> Search</span></a></span></div><div id="site-info"><div id="site-title">WBINGのBLOG</div><div id="site-sub-title">BIG DATA探索者,经济迷,历史,人文</div><div id="site-social-icons"><a class="social-icon" href="https://github.com/weibingo" target="_blank" rel="noreferrer noopener nofollow"><i class="fa-github fa"></i></a><a class="social-icon" href="https://www.jianshu.com/u/0352716a8f7d" target="_blank" rel="noreferrer noopener nofollow"><i class="fa-book fa"></i></a></div></div></nav><div id="content-outer"><div class="layout" id="content-inner"><div class="recent-post-item article-container"><a class="article-title" href="/article/summary-2018.html">略微糟糕的2018</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-01-04</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E6%88%90%E9%95%BF/">成长</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E6%80%BB%E7%BB%93/">总结</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E7%9B%AE%E6%A0%87/">目标</a></span><div class="content"><p>不在以流水形式记录，而网易云音乐年报体搞笑却不能展示更多。在朋友圈看了别人的发的年终总结，遂借鉴其模板。</p>
<h3 id="2018年让你印象深刻的5件事情是什么？"><a href="#2018年让你印象深刻的5件事情是什么？" class="headerlink" title="2018年让你印象深刻的5件事情是什么？"></a>2018年让你印象深刻的5件事情是什么？</h3><ol>
<li>定级答辩，完全暴露了自己的弱点，当大领导说自己的ppt很渣时，很懵逼。自己确实没太上心，做的少。虽然后来又重改了，但最终其实效果都不是很满意，包括答辩。表达能力以及技能包装能力都还需要多加练习。最后感谢领导的细心指导。</li>
<li>不应该老拿别人的弱点说事或者开玩笑。A之前说了个毫无依据的话被大家笑话，然后就竟然被大家拿出来说，以至于大家一旦把焦点给与他，他便有了种不舒服，即便知道大家也是寻乐。自己也会一直拿别人的弱点寻乐，虽然是玩笑，但别人的感受未必是玩笑。当然自己也会被拿着弱点一直攻击你，当然也是寻乐，但自己确实也有不爽，将心比心，也许有时候会意的鼓励会更好。以后自己应该多注意，少娱乐他人的弱点，多提升自己的弱点。</li>
<li>接近年底，回家办理贷款手续，正好外婆过生，一大家人和和睦睦，开开心心的氛围真好。希望明年能带外婆来北京玩，外婆那些年一路过来不容易，现在也该享享清福了。</li>
</ol>
<h3 id="你做的引以为傲的5件事？"><a href="#你做的引以为傲的5件事？" class="headerlink" title="你做的引以为傲的5件事？"></a>你做的引以为傲的5件事？</h3><ol>
<li>终于还是借着低价买的域名，开通的<a href="http://wbice.cn/">博客</a>，开始记录技术，生活的感悟，以及看书，电影。零零散散的也写了将近20篇文章，虽然内容还有待提供，以及有些是拼凑的。但还是希望自己沉淀一些知识，以及顺便提高自己的写作能力。</li>
<li>认知的提升。网络上的人云亦云，股市的追涨杀跌，以及自媒体带节奏的十万加，以及各种app推送的信息。让我意识到现在虽然信息变多了，但都是他们为了满足自己的利益而塞给观看者已经加工过的信息。对此，自己的认知的提升，能够对此消息进行独立思考，而不是跟着他人的情感走是非常重要的。而群体更能泛滥此情绪，相比独立思考，会显得更智力低下。</div><a class="more" href="/article/summary-2018.html#more">Read more</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/article/spark-streaming.html">spark streaming</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2018-12-22</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B/">数据工程</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/">流式计算</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/">流式计算</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/spark/">spark</a></span><div class="content"><p>之前讲解了Google的<a href="http://wbice.cn/article/dataflow-model.html">Dataflow</a>模型。而spark streaming是以micro batch方式来近似streaming数据进行处理。Spark Streaming从实时数据流接入数据，再将其划分为一个个小批量供后续Spark engine处理，所以实际上，Spark Streaming是按一个个小批量来处理数据流的。<br><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/spark-streaming/micro-streaming.png"></p>
<h3 id="spark-streaming"><a href="#spark-streaming" class="headerlink" title="spark streaming"></a>spark streaming</h3><p>离散数据流（DStream）是Spark Streaming最基本的抽象。它代表了一种连续的数据流，要么从某种数据源提取数据，要么从其他数据流映射转换而来。DStream内部是由一系列连续的RDD组成的，每个RDD都是不可变、分布式的数据集。每个RDD都包含了特定时间间隔内的一批数据，如下图所示：<br><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/spark-streaming/interval-rdd.png"></p>
<p>任何作用于DStream的算子，其实都会被转化为对其内部RDD的操作。例如，在代码</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> words = lines.flatMap(_.split(<span class="string">&quot; &quot;</span>))</span><br></pre></td></tr></table></figure>
<p>中，我们将lines这个DStream转成words DStream对象，其实作用于lines上的flatMap算子，会施加于lines中的每个RDD上，并生成新的对应的RDD，而这些新生成的RDD对象就组成了words这个DStream对象。其过程如下图所示：</p></div><a class="more" href="/article/spark-streaming.html#more">Read more</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/article/livy-guide.html">livy指南</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2018-12-13</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B/">数据工程</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/spark/">spark</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/livy/">livy</a></span><div class="content"><p>Livy是一个基于Spark的开源REST服务，它能够通过REST的方式将代码片段或是序列化的二进制代码提交到Spark集群中去执行。它提供了以下这些基本功能：</p>
<ul>
<li>提交Scala、Python或是R代码片段到远端的Spark集群上执行；</li>
<li>提交Java、Scala、Python所编写的Spark作业到远端的Spark集群上执行；</li>
<li>提交批处理应用在集群中运行。</li>
</ul>
<h3 id="livy安装"><a href="#livy安装" class="headerlink" title="livy安装"></a>livy安装</h3><p>livy安装很简单，从<a target="_blank" rel="noopener" href="http://livy.incubator.apache.org/download/">官网</a>下载zip包。<br>解压，设置spark和hadoop的环境。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> SPARK_HOME=spark的路径</span><br><span class="line"><span class="built_in">export</span> HADOOP_CONF_DIR=/etc/hadoop/conf （hadoop配置路径）</span><br></pre></td></tr></table></figure>

<p>然后在livy的bin目录下执行：<br>livy-server start</p>
<h3 id="livy配置"><a href="#livy配置" class="headerlink" title="livy配置"></a>livy配置</h3><p>在conf&#x2F;livy.conf文件中有配置，常用的配置：</p>
<table>
<thead>
<tr>
<th>配置信息</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td>livy.server.host &#x3D; 0.0.0.0</td>
<td>livy服务启动的host</td>
</tr>
<tr>
<td>livy.server.port &#x3D; 80</td>
<td>启动端口号</td>
</tr>
<tr>
<td>livy.spark.master &#x3D; yarn</td>
<td>livy执行spark master</td>
</tr>
<tr>
<td>livy.spark.deploy-mode &#x3D; client</td>
<td>spark启动模式</td>
</tr>
<tr>
<td>livy.repl.enable-hive-context &#x3D; true</td>
<td>启动hiveContext</td>
</tr>
<tr>
<td>livy.ui.enabled &#x3D; true</td>
<td>livy ui页面</td>
</tr>
</tbody></table>
<p>还有其他的配置，用户可以根据自己需求自行配置。<br>另外，当集群开启了kerberos验证，执行spark任务时报gss错误，需要在配置中加上：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">livy.server.launch.kerberos.keytab = /conf/xxx.keytab</span><br><span class="line">livy.server.launch.kerberos.principal = xxx@HADOOP.COM</span><br></pre></td></tr></table></figure></div><a class="more" href="/article/livy-guide.html#more">Read more</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/article/airflow-guide.html">airflow使用指南</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2018-11-28</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B/">数据工程</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/airflow/">airflow</a></span><div class="content"><p>airflow 是一个编排、调度和监控workflow的平台，由Airbnb开源。airflow 将workflow编排为tasks组成的DAGs，调度器在一组workers上按照指定的依赖关系执行tasks。同时，airflow 提供了丰富的命令行工具和简单易用的用户界面以便用户查看和操作，并且airflow提供了监控和报警系统。</p>
<h3 id="airflow-核心概念"><a href="#airflow-核心概念" class="headerlink" title="airflow 核心概念"></a>airflow 核心概念</h3><ul>
<li>DAGs：即有向无环图(Directed Acyclic Graph)，将所有需要运行的tasks按照依赖关系组织起来，描述的是所有tasks执行的顺序。</li>
<li>Operators：可以简单理解为一个class，描述了DAG中一个具体的task具体要做的事。其中，airflow内置了很多operators，如BashOperator 执行一个bash 命令，PythonOperator 调用任意的Python 函数，EmailOperator 用于发送邮件，HTTPOperator 用于发送HTTP请求， SqlOperator 用于执行SQL命令…同时，用户可以自定义Operator，这给用户提供了极大的便利性。</li>
<li>Tasks：Task 是 Operator的一个实例，也就是DAGs中的一个node。</li>
<li>Task Instance：task的一次运行。task instance 有自己的状态，包括”running”, “success”, “failed”, “skipped”, “up for retry”等。</li>
<li>Task Relationships：DAGs中的不同Tasks之间可以有依赖关系，如 TaskA &gt;&gt; TaskB，表明TaskB依赖于TaskA。</li>
</ul>
<p>通过将DAGs和Operators结合起来，用户就可以创建各种复杂的 workflow了。</p>
<h3 id="operators"><a href="#operators" class="headerlink" title="operators"></a>operators</h3><p>下面讲解下常见的operator，以及如何使用，注意点。</p></div><a class="more" href="/article/airflow-guide.html#more">Read more</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/article/google-spanner.html">Google Spanner</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2018-11-28</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B/">数据工程</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/">数据库</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/Google/">Google</a></span><div class="content"><p>原始译文厦门大学林子雨老师翻译，见<a target="_blank" rel="noopener" href="http://dblab.xmu.edu.cn/post/google-spanner/">Google Spanner (中文版)</a></p>
<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>Spanner是谷歌公司研发的、可扩展的、多版本、全球分布式、同步复制数据库。它是第一个把数据分布在全球范围内的系统，并且支持外部一致性的分布式事务。本文描述了Spanner的架构、特性、不同设计决策的背后机理和一个新的时间API，这个API可以暴露时钟的不确定性。这个API及其实现，对于支持外部一致性和许多强大特性而言，是非常重要的，这些强大特性包括：非阻塞的读、不采用锁机制的只读事务、原子模式变更。</p>
<p>Spanner是个可扩展，多版本，全球分布式还支持同步复制的数据库。他是Google的第一个可以全球扩展并且支持外部一致的事务。Spanner能做到这些，离不开一个用GPS和原子钟实现的时间API。这个API能将数据中心之间的时间同步精确到10ms以内。因此有几个给力的功能：无锁读事务，原子schema修改，读历史数据无block。</p>
<h3 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h3><p>从高层看Spanner是通过Paxos状态机将分区好的数据分布在全球的。数据复制全球化的，用户可以指定数据复制的份数和存储的地点。Spanner可以在集群或者数据发生变化的时候将数据迁移到合适的地点，做负载均衡。</p>
<p>spanner提供一些有趣的特性：</p>
<ul>
<li>应用可以细粒度的指定数据分布的位置。精确的指定数据离用户有多远，可以有效的控制读延迟(读延迟取决于最近的拷贝)。指定数据拷贝之间有多远，可以控制写的延迟(写延迟取决于最远的拷贝)。还要数据的复制份数，可以控制数据的可靠性和读性能。(多写几份，可以抵御更大的事故)</li>
<li>Spanner还有两个一般分布式数据库不具备的特性：读写的外部一致性，基于时间戳的全局的读一致。这两个特性可以让Spanner支持一致的备份，一致的MapReduce，还有原子的Schema修改。</li>
</ul>
<p>这些特性都得益于spanner有个全球时间同步机制，可以在数据提交的时候给出一个时间戳。因为时间是系列化的，所以才有外部一致性。这个很容易理解，如果有两个提交，一个在T1,一个在T2。那有更晚的时间戳那个提交是正确的。</p>
<h3 id="与关系型数据库和nosql对比"><a href="#与关系型数据库和nosql对比" class="headerlink" title="与关系型数据库和nosql对比"></a>与关系型数据库和nosql对比</h3><p><a target="_blank" rel="noopener" href="https://www.infoq.cn/article/growth-path-of-spanner">https://www.infoq.cn/article/growth-path-of-spanner</a></p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/article/hbase-case-batch.html">HBase case之scan batch</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2018-10-20</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/HBase/">HBase</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/HBase/">HBase</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E6%95%B0%E6%8D%AE/">数据</a></span><div class="content"><p>标签数据存储在Hbase中，为了加速标签探索功能，会每天导出一份全量数据表。有时候用户也会进行特定标签勾选导出需求。</p>
<h3 id="导出遇到的问题"><a href="#导出遇到的问题" class="headerlink" title="导出遇到的问题"></a>导出遇到的问题</h3><p>导出后，出现部分用户，同一个用户多条数据（两条为主），见下图：<br><img src="http://hexo-1256892004.cos.ap-beijing.myqcloud.com/hbase-case-batch/tag-1.png"></p>
<p><img src="http://hexo-1256892004.cos.ap-beijing.myqcloud.com/hbase-case-batch/tag-2.png"></p>
<p>从图中可以看出，出现了重复用户uid。</p></div><a class="more" href="/article/hbase-case-batch.html#more">Read more</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/article/hbase-snapshot.html">HBase系列之snapshot</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2018-10-12</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/HBase/">HBase</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/HBase/">HBase</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E6%95%B0%E6%8D%AE/">数据</a></span><div class="content"><h3 id="snapshot（快照）基础原理"><a href="#snapshot（快照）基础原理" class="headerlink" title="snapshot（快照）基础原理"></a>snapshot（快照）基础原理</h3><p>snapshot是很多存储系统和数据库系统都支持的功能。一个snapshot是一个全部文件系统、或者某个目录在某一时刻的镜像。实现数据文件镜像最简单粗暴的方式是加锁拷贝（之所以需要加锁，是因为镜像得到的数据必须是某一时刻完全一致的数据），拷贝的这段时间不允许对原数据进行任何形式的更新删除，仅提供只读操作，拷贝完成之后再释放锁。这种方式涉及数据的实际拷贝，数据量大的情况下必然会花费大量时间，长时间的加锁拷贝必然导致客户端长时间不能更新删除，这是生产线上不能容忍的。</p>
<p>snapshot机制并不会拷贝数据，可以理解为它是原数据的一份指针。在HBase这种LSM类型系统结构下是比较容易理解的，我们知道HBase数据文件一旦落到磁盘之后就不再允许更新删除等原地修改操作，如果想更新删除的话可以追加写入新文件（HBase中根本没有更新接口，删除命令也是追加写入）。这种机制下实现某个表的snapshot只需要给当前表的所有文件分别新建一个引用（指针），其他新写入的数据重新创建一个新文件写入即可。</p>
<p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/hbase-snapshot/snapshot.png"></p>
<p>snapshot流程主要涉及3个步骤：</p>
<ol>
<li><p>加一把全局锁，此时不允许任何的数据写入更新以及删除</p>
</li>
<li><p>将Memstore中的缓存数据flush到文件中（可选）</p>
</li>
<li><p>为所有HFile文件分别新建引用指针，这些指针元数据就是snapshot</p>
</li>
</ol>
<h3 id="snapshot作用"><a href="#snapshot作用" class="headerlink" title="snapshot作用"></a>snapshot作用</h3><ul>
<li>备份：通常情况下，对重要的业务数据，建议至少每天执行一次snapshot来保存数据的快照记录，并且定期清理过期快照，这样如果业务发生重要错误需要回滚的话是可以回滚到之前的一个快照点的。</li>
<li>迁移：可以使用ExportSnapshot功能将快照导出到另一个集群，实现数据的迁移</div><a class="more" href="/article/hbase-snapshot.html#more">Read more</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/article/hbase-region-split.html">HBase系列之region-split上</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2018-10-10</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/HBase/">HBase</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/HBase/">HBase</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E6%95%B0%E6%8D%AE/">数据</a></span><div class="content"><p>Region自动切分是HBase能够拥有良好扩张性的最重要因素之一，也必然是所有分布式系统追求无限扩展性的一副良药。那么region又是如何自动切分的呢，触发的条件又是什么？</p>
<h3 id="Region切分触发策略"><a href="#Region切分触发策略" class="headerlink" title="Region切分触发策略"></a>Region切分触发策略</h3><p>在最新稳定版（1.2.6）中，HBase已经有多达6种切分触发策略。即RegionSplitPolicy的实现子类共有6个，如下类图：<br><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/hbase-region-split/split-class.png"></p>
<p>当然，每种触发策略都有各自的适用场景，用户可以根据业务在表级别选择不同的切分触发策略。常见的切分策略如下图：<br><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/hbase-region-split/region.png"></p>
<h4 id="ConstantSizeRegionSplitPolicy"><a href="#ConstantSizeRegionSplitPolicy" class="headerlink" title="ConstantSizeRegionSplitPolicy"></a>ConstantSizeRegionSplitPolicy</h4><p>0.94版本前默认切分策略。这是最容易理解但也最容易产生误解的切分策略，从字面意思来看，当region大小大于某个阈值（hbase.hregion.max.filesize）之后就会触发切分，实际上并不是这样，真正实现中这个阈值是对于某个store来说的，即一个region中最大store的大小大于设置阈值之后才会触发切分。另外一个大家比较关心的问题是这里所说的store大小是压缩后的文件总大小还是未压缩文件总大小，实际实现中store大小为压缩后的文件大小（采用压缩的场景）。ConstantSizeRegionSplitPolicy相对来来说最容易想到，但是在生产线上这种切分策略却有相当大的弊端：切分策略对于大表和小表没有明显的区分。阈值（hbase.hregion.max.filesize）设置较大对大表比较友好，但是小表就有可能不会触发分裂，极端情况下可能就1个，这对业务来说并不是什么好事。如果设置较小则对小表友好，但一个大表就会在整个集群产生大量的region，这对于集群的管理、资源使用、failover来说都不是一件好事。</p></div><a class="more" href="/article/hbase-region-split.html#more">Read more</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/article/hbase-compact.html">HBase系列之compact</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2018-10-09</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/HBase/">HBase</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/HBase/">HBase</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E6%95%B0%E6%8D%AE/">数据</a></span><div class="content"><p>在介绍HBase Compaction之前，我们先来看一下HBase是如何存储和操作数据。<br><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/hbase-compact/hbase-store.png" alt="HBase数据存储"></p>
<p>如上图所示，HRegionServer负责打开region，并创建对应的HRegion实例。当HRegion打开之后，它会为每个表的HColumnFamily创建一Store实例，ColumnFamily是用户在创建表时定义好的，ColumnFamily在每个region中和Store实例一一对应。每个Store实例包含一个或者多个StoreFile实例，StoreFile是对实际存储数据文件HFile的轻量级封装。每个Store对应一个MemStore（也就是写内存）。一个HRegionServer共享一个HLog实例。</p>
<p>当我们不停地往HBase中写入数据，也就是往MemStore写入数据，HBase会检查MemStore是否达到了需要刷写到磁盘的阈值（更多关于MemStore刷写的信息，可以参考HBase Reference Guide关于MemStore的介绍）。如果达到刷写的条件，MemStore中的记录就会被刷写到磁盘，形成一个新的StoreFile。可想而知，随着MemStore的不断刷写，会形成越来越多的磁盘文件。然而，对于HBase来说，当每个HStore仅包含一个文件时，才会达到最佳的读效率。因此HBase会通过合并已有的HFile来减少每次读数据的磁盘寻道时间，从而提高读速度，这个文件合并过程就称为Compaction。在这里需要说明的是，显然磁盘IO也是有代价的，如果使用不慎的话，不停地重写数据可能会导致网络和磁盘过载。换句话说，compaction其实就是用当前更高的磁盘IO来换取将来更低的磁盘寻道时间。因此，何时执行compaction，其实是一个相当复杂的决策。</p>
<p>Compaction会从一个region的一个store中选择一些hfile文件进行合并。合并说来原理很简单，先从这些待合并的数据文件中读出KeyValues，再按照由小到大排列后写入一个新的文件中。之后，这个新生成的文件就会取代之前待合并的所有文件对外提供服务。HBase的compaction分为minor和major两种，每次触发compact检查，系统会自动决定执行哪一种compaction（合并）。有三种情况会触发compact检查：</p>
<ul>
<li>MemStore被刷写到磁盘；</li>
<li>用户执行shell命令compact、major_compact或者调用了相应的API；</li>
<li>HBase后台线程周期性触发检查。</li>
</ul>
<p>除非是用户使用shell命令major_compact或者调用了majorCompact() API（这种情况会强制HBase执行major合并），在其他的触发情况下，HBase服务器会首先检查上次运行到现在是否达到一个指定的时限。如果没有达到这个时限，系统会选择执行minor合并，接着检查是否满足minor合并的条件。</p>
<p>major合并中会删除那些被标记为删除的数据、超过TTL（time-to-live）时限的数据，以及超过了版本数量限制的数据，将HStore中所有的HFile重写成一个HFile。如此多的工作量，理所当然地，major合并会耗费更多的资源，合并进行时也会影响HBase的响应时间。在HBase 0.96之前，默认每天对region做一次major compact，现在这个周期被改成了7天。然而，因为major compact可能导致某台server短时间内无法响应客户端的请求，如果无法容忍这种情况的话，可以关闭自动major compact，改成在请求低谷期手动触发这一操作。</p>
<p>Minor Compaction是指选取一些小的、相邻的StoreFile将他们合并成一个更大的StoreFile，在这个过程中不会处理已经Deleted或Expired的Cell。一次Minor Compaction的结果是更少并且更大的StoreFile。</p></div><a class="more" href="/article/hbase-compact.html#more">Read more</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/article/data-model.html">八大基础分析模型</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2018-09-14</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/">数据分析</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E6%95%B0%E6%8D%AE/">数据</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E6%A8%A1%E5%9E%8B/">模型</a></span><div class="content"><p>模型是指对于某个实际问题或客观事物、规律进行抽象后的一种形式化表达方式。任何模型都有三个部分组成：目标、变量和关系。<br>通俗来讲：</p>
<ul>
<li>目标：这个模型是干嘛用的，要解决什么问题。</li>
<li>变量：自变量、因变量、中介变量，总之就是，明确变量，改变变量，即可直接呈现结果，实现目标。</li>
<li>关系：可以理解为对目标和变量进行组织。<br>下面介绍常用的八种基础分析模型，可能大家也都了解。而且这些模型，其实也在不断的优化，并且又有了一些新特性，比如用户分群模型中的“新增后”、事件模型中的“活跃比”</li>
</ul>
<h3 id="用户模型"><a href="#用户模型" class="headerlink" title="用户模型"></a>用户模型</h3><p>“用户”是以人为中心的数据分析平台的最小单元，对单个用户画像构建越完整，数据多维交叉的分析能力才能凸显。</p>
<h3 id="事件模型"><a href="#事件模型" class="headerlink" title="事件模型"></a>事件模型</h3><p>用户在产品上的行为（所有代码的交互）都是会被记录的，怎样标记是事件模型的核心，它是漏斗模型，自定义留存模型，全行为路径分析模型的数据源。</p>
<p><em><strong>活跃比：某一时间区间内触发某事件的人数占该时间区间内活跃人数的百分比。</strong></em></p></div><a class="more" href="/article/data-model.html#more">Read more</a><hr></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/page/3/"><i class="fa fa-chevron-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/5/"><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer class="footer-bg" style="background-image: url(https://hexo-1256892004.cos.ap-beijing.myqcloud.com/page/top.jpg)"><div class="layout" id="footer"><div class="copyright">&copy;2017 - 2024 By weibingo</div><div class="framework-info"><span>Driven - </span><a target="_blank" rel="noopener" href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a target="_blank" rel="noopener" href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="footer_custom_text">hitokoto</div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_site_uv"><i class="fa fa-user"></i><span id="busuanzi_value_site_uv"></span><span></span></span><span class="footer-separator">|</span><span id="busuanzi_container_site_pv"><i class="fa fa-eye"></i><span id="busuanzi_value_site_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="/js/third-party/anime.min.js"></script><script src="/js/third-party/jquery.min.js"></script><script src="/js/third-party/jquery.fancybox.min.js"></script><script src="/js/third-party/velocity.min.js"></script><script src="/js/third-party/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.8.0"></script><script src="/js/fancybox.js?version=1.8.0"></script><script src="/js/sidebar.js?version=1.8.0"></script><script src="/js/copy.js?version=1.8.0"></script><script src="/js/fireworks.js?version=1.8.0"></script><script src="/js/transition.js?version=1.8.0"></script><script src="/js/scroll.js?version=1.8.0"></script><script src="/js/head.js?version=1.8.0"></script><script src="/js/search/algolia.js"></script><script src="/js/search/local-search.js"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script><div class="search-dialog" id="algolia-search"><div class="search-dialog__title" id="algolia-search-title">Algolia</div><div id="algolia-input-panel"><div id="algolia-search-input"></div></div><hr><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-stats"></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>