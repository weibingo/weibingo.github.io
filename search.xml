<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>LMOps工具链与千帆大模型平台</title>
      <link href="/article/LMOps%E5%B7%A5%E5%85%B7%E9%93%BE%E4%B8%8E%E5%8D%83%E5%B8%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%B9%B3%E5%8F%B0.html"/>
      <url>/article/LMOps%E5%B7%A5%E5%85%B7%E9%93%BE%E4%B8%8E%E5%8D%83%E5%B8%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%B9%B3%E5%8F%B0.html</url>
      
        <content type="html"><![CDATA[<h2 id="1-从机器学习到百模大战"><a href="#1-从机器学习到百模大战" class="headerlink" title="1. 从机器学习到百模大战"></a><strong>1. 从机器学习到百模大战</strong></h2><p>众所周知，目前我们实现人工智能的主要技术手段是机器学习技术，特别是其中基于深层神经网络的深度学习技术。机器学习的本质是通过具有学习能力的算法、对数据进行建模的技术。深度学习借助大规模的算力解决了机器学习中特征表示的人工干预的瓶颈，在效果上取得了巨大突破。因此，机器学习成为目前人工智能的主流技术。</p><p>深度学习和生成式大模型之间的关系，如下图右侧所示，在 2012 年至 2016 年左右，像卷积神经网络、对抗生成网络、ResNet 等经典的深度学习模型，已经在计算视觉、语音识别、自然语言处理等领域取得了显著的效果提升。这些经典深度学习模型既有判别式、也有生成式，它们往往会在 ImageNet、COCO 等有标注的数据集上进行预训练，形成带有预训练权重、可以进一步进行 Fine-tuning 的预训练模型。</p><p>在 2017 年之后，Transformer 结构在自然语言处理领域首先被成功应用，在这之后以 Transformer 为基础组件的生成式大模型逐步成为视觉、自然语言处理、跨模态理解和生成领域的主流技术。这类技术通常以 Transformer 和注意力机制作为组件，并且它可以并行地进行自监督学习，参数规模在十亿以上。其中，将生成式大模型技术应用在语言建模上的方式，被称为「大语言模型」。在经过进一步的调优之后，形成了像 ChatGPT、文心一言等被大家熟知的对话式、生成式大语言模型应用。</p><p><img src="https://pic4.zhimg.com/80/v2-3b9525d6fccbf0b6451f7e4dab491127_1440w.webp">​</p><p>在过去的半年，我们经历了一场百模大战。尤其是在开源社区，新的大模型如雨后春笋般涌现，而大模型相关的技术也越来越标准化、同质化。在这里为大家分享一个小故事。我们可以在大模型中了解到很多「驼」系英语词汇，比如 Llama 是美洲驼，Alpaca 是羊驼，Vicuna 是小羊驼。</p><p>为什么有那么多以「驼」命名的大语言模型？因为大语言模型 Large Language Model 的缩写是 LLM，2 个 L 放在一起不方便读出来，Meta 公司为了方便大家记忆，所以选了相近的词语 Llama（美洲驼）。后来很多基于 Llama 开源模型进行调优和构建的大语言模型，都以「驼」系的名称命名。</p><p>如下图所示，我们可以看到在硅谷的大模型创业公司中，除 OpenAI 外，目前已有将近 1&#x2F;3 的资金投入了 MLOps 和 LMOps 相关的平台和工具方向。接下来，我将为大家详细拆解，在百模大战的背后，为什么 MLOps 和 LMOps 平台和工具能够获得资本的青睐。</p><p><img src="https://pic3.zhimg.com/80/v2-5135d2f5a771ab5ccbf1639e579cd8d6_1440w.webp">​</p><p>首先看看大模型在技术和应用层面带来了哪些变化。比如在以下 4 个技术层面：</p><span id="more"></span><ul><li>数据：大模型的预训练通常需要 TB-PB 级别的数据， TB-PB 级别的数据规模和对应的数据加工技术，与之前的经典深度学习模型并不相同。同时，大模型大多以多模态、指令、对话数据作为训练或调优的输入，在数据内容上和之前的经典深度学习模型也有很大的差异。</li><li>训练和调优的方法：现在千亿参数级别的大模型，往往需要千卡、甚至万卡进行分布式训练，其中的调度、容错、通信技术和之前大不相同。大模型在调优过程中也出现了很多低资源开销、高效率的技术。</li><li>大模型效果评估方式：经典深度学习模型往往基于人工标注的测试数据集，来计算客观指标，并评估模型效果。因为大模型生成的海量内容暂无标准的答案，所以我们无法全部依赖人工去评判内容的质量。因此，大模型的效果和性能需要建立与以往不同的评估基准和评估方法。</li><li>推理：通过 Prompt 工程来调教大模型的输出，无论是在自然语言处理还是视觉生成领域，之前经典的深度学习模型都不具备这些能力。</li></ul><p><img src="https://pic3.zhimg.com/80/v2-f2b07b703539d708a8435bf849ff59aa_1440w.webp">​</p><p>除技术方向上的变化外，大模型还改变了人工智能应用的构建模式，这也是大模型带来的最重要的变化。如下图所示，在过去是一个模型去完成一类特定的任务（如：人脸识别、卡证识别、多轮的对话等），需要通过训练不同的模型、使用不同的数据才能完成。在大模型出现后，我们可以在少数几个甚至在一个预训练的大模型的基础上，针对行业的场景加入相关数据、最后调优就可以完成任务。这也使得大模型的研发更加地集约化，进一步提升生产效率。</p><p>当然，这种构建模式的改变并非一蹴而就的，而是循序渐进的。但趋势是很明确的，我们正处于「大炼模型」到「炼大模型」的升级过程中。</p><p><img src="https://pic3.zhimg.com/80/v2-f84430d3230069eaa55f735a4d83708e_1440w.webp">​</p><p>大模型在技术和应用模式上带来了巨大的变化，也对企业提出了新的挑战，比如如何对 AI 能力进行运用和管理。今天，我们要介绍的 LMOps就是来解决上述挑战最有效的技术手段。</p><p> <strong>只有通过 LMOps，企业才能真正驾驭大模型，让其成为智能化升级的重要生产力。</strong> 这也是为什么在热火朝天的百模大战之后，除了超级应用之外，LMOps 平台和工具获得资本青睐的原因。</p><p>下面，我们将介绍 LMOps 相关的概念以及一系列关键的技术。</p><p><img src="https://pic4.zhimg.com/80/v2-eaa21fe5ba18bf6094433cebe94b6517_1440w.webp">​</p><h2 id="2-DevOps、MLOps-和-LMOps-概念及相关技术"><a href="#2-DevOps、MLOps-和-LMOps-概念及相关技术" class="headerlink" title="2. DevOps、MLOps 和 LMOps 概念及相关技术"></a><strong>2. DevOps、MLOps 和 LMOps 概念及相关技术</strong></h2><p>DevOps 是贯穿传统软件生命周期的方法论和最佳的技术实践，它包括软件的需求提出、代码开发、测试、上线运维和推广运营等多个环节。其中的关键技术包括需求管理、版本控制、持续集成、组件化、容器化、微服务、持续交付、自动化运维等。目前 DevOps 的平台和工具已经成为大多数软件开发企业驾驭软件研发运营最有效的方法。如下图所示，DevOps 各个环节中有大量的生态企业参与进来，共同构成了完整、繁荣的生态。</p><p><img src="https://pic1.zhimg.com/80/v2-6354f00d77fca249fa382b1d6066cba0_1440w.webp">​</p><p>在机器学习的全生命周期中，和传统软件开发类似，算法的研发和代码编写只占其中很少一部分。如下图所示，图中的黑色部分是针对模型的代码和结构进行开发。其他部分，如数据采集、加工、服务搭建、效果监控等占用了机器学习工作量的绝大部分。因此，如果企业希望驾驭机器学习，就需要有合适的，针对机器学习生命周期特点的方法论和最佳的技术实践，这也是 <a href="https://link.zhihu.com/?target=https://cloud.baidu.com/product/bml?track=weixin01">MLOps</a> 诞生的原因。</p><p>MLOps 涉及机器学习、DevOps 和数据科学的相关技术，覆盖机器学习的需求分析、数据采集、加工、模型算法开发、训练、效果评估、调优、版本管理、服务部署、推理监控以及模型持续迭代等全生命周期的过程。所以， MLOps 为企业在生产环境中稳定高效地部署和运营机器学习提供了一套具有实践意义的方案。</p><p><img src="https://pic2.zhimg.com/80/v2-031ca46f8aac3d082daebf533463b975_1440w.webp">​</p><p>接下来，为大家详细介绍本文讨论的重点 LMOps 、以及 LMOps 与 MLOps 的关系。如上文所述，相对于传统机器学习和经典的深度学习模型，大模型发生了较大的变化，带来了新的挑战。</p><p><strong>LMOps 继承了 MLOps 整体的框架和机器学习的全生命周期等主要环节，并且针对大模型的变化进行了微调适配。</strong></p><p>在生成式大模型的数据组成中，无监督数据和未标注的数据在大幅度上升。为了解决上述问题，LMOps 对无监督数据和未标注的数据加工进行了强化。对于传统的机器学习模型，我们经常需要修改代码来进行效果的强化和调整。而在 LMOps下，我们几乎不需要去修改大模型的代码，同时也会注重并行分布式训练大模型的效能的提升。另外在 LMOps 中，针对大模型出现了新的提示工程（ Prompt 工程），从工具链的角度思考哪些方面可以更加自动化、提供提示词模板等也是 MLOps 中新引入的能力。对于预训练模型的调优，在 LMOps 中也出现了新的方法，包括下文我们会介绍的 PEFT 、 SFT 方法等。</p><p>近期还有另一个非常热门的方向，主要讨论针对大语言模型，如何通过插件的方式去扩展它的能力，开源社区也有一些很好的 API 框架由此诞生。对于这部分插件的能力， 在 LMOps 生命周期中需要同时被管理、做进一步的适配和优化。</p><p><strong>综上所述，LMOps 继承了 MLOps 主体及框架，并在每个环节上都针对大模型的特点进行适配，形成新的技术实践。</strong></p><p><img src="https://pic3.zhimg.com/80/v2-986552f7ad5e597744d747736f712836_1440w.webp">​</p><p>如下图所示，虽然 LMOps 问世不久，但整个上下游的各类公司已经共同构建了繁荣的生态。其中就包括向量数据库 Pinecone、以及我们非常熟悉的 OpenAI、Hugging Face、Stable Diffusion 等做模型及模型集成的厂商。这也解释了为什么 MLOps 与 LMOps 在资本投入中占据很大比重。</p><p><img src="https://pic4.zhimg.com/80/v2-d97a2c2cc096baf8ff2d60d0dbeae8d3_1440w.webp">​</p><p>在了解了 LMOps 的相关概念之后，下面将为大家介绍 LMOps 在数据、训练、评估、推理、部署和安全这六个主要环节的核心技术。</p><p>在数据加工的环节上，大模型在预训练和再训练的阶段，往往使用的是大规模未标注数据。因此，对这些大规模未标注的数据进行加工和配比，对大模型的效果至关重要。数据加工环节包括五个步骤：</p><ul><li>首先是对特殊字符的一些清除，如火星文&#x2F; 特殊的标点清除等，替换部分异常文本。</li><li>删除低质量文档。建立低质文档的统计指标，超过某个阈值就进行删除。或通过定制的分类模型对文档质量进行自动分类。</li><li>文档去重。通常情况下，我们可以针对文档中的句子和段落等进行文档内的内容去重；针对两个内容重复阈值较高的相似文档，可以进行跨文档去重。</li><li>去除隐私数据。使用基于规则的正则表达式的方法检测个人信息，来进行隐私数据的脱敏。</li><li>建立词表（ Tokenize 的过程）。目前建立此表常用的是 SentencePiece 等方法。当我们将原始的语料加工成 token，并建立 token_id 后，再喂给大模型进行训练或者推理。</li></ul><p>对于数据加工的环境，我分享一下自己的心得 <strong>。决定大模型效果的，并不主要是模型结构和参数配置，而是数据的质量和配比，对大模型的效果会产生更加重要的影响。</strong> 比如训练大模型需要哪些来源的数据、数据的比例分配，通过加工步骤后数据的质量和多样性决定了预训练后大模型的效果。</p><p><img src="https://pic1.zhimg.com/80/v2-ff3de7bb8125197cca917629e7ab94f4_1440w.webp">​</p><p>LMOps 训练环节的核心技术，包括监督调优和基于人工反馈的强化学习。如下图所示，SFT （Supervised Fine Tuning）通过包含指令和提示数据的人工标注生成结果对大语言模型进行调优，能够较好地激发大模型的场景化能力和生成效果。RLHF（Reinforcement Learning from Human Feedback ）能够让大语言模型优先生成最符合人类喜好和价值观的结果。这也是目前大语言模型调优一定会做的技术，所以 RLHF 是 LMOps 训练环节的核心技术之一。</p><p><img src="https://pic3.zhimg.com/80/v2-e5a81ebf563a72bc100e2a08ae547aea_1440w.webp">​</p><p>除 SFT、RLHF 技术外，近期 PEFT 技术也非常热门，是目前大语言模型调优环节中广泛采用的技术，它是一系列高效率微调技术的总称。</p><p>大模型的参数量一般在十亿甚至百亿、千亿、万亿以上。如果按照传统的机器学习模型或经典的深度学习模型，对大模型的全量参数进行调优（再训练）会造成资源开销超负荷。并且，对大模型的全量参数进行调优，可能会把预训练的模型训坏掉，丧失大模型原有的能力和效果。</p><p>针对此问题，研究者提出微量调优（针对少部分参数进行调优）的办法。所以，目前常用 PEFT 手段对大模型进行调优。在 PEFT 中，常用的方法包括 P-tuning 和 LoRA，他们都是在大模型合适的位置增加需要微调的参数，来提升调优的效率、达到优化模型目的。例如 Prefix-tuning 就是在输入 token 之前构造一段和任务相关的 virtual tokens 作为 Prefix，训练的时候只更新 Prefix 的参数，而 Transformer 中的其他部分参数固定。Prompt-tuning 可以看做是 Prefix-tuning 的简化版，只在输入层加入 Prompt tokens。只要模型规模够大，简单地加入 Prompt tokens 进行微调，也能取得很好的效果。</p><p>而 LoRA 采用的是另一种方法。研究者发现，大语言模型虽然参数众多，但是在模型推理中，真正起到关键作用的还是低秩的本质维度（Low Instrisic Dimension）。因此提出了 Low-Rank Adaption (LoRA)，在涉及到矩阵相乘的模块，引入 A、B 两个低秩矩阵模块去模拟 full finetune 的过程，相当于只对语言模型中起关键作用的低秩本质维度进行更新，这就是 LoRA 的原理。这些 PEFT 方法都已经引入到 LMOps 中。</p><p><img src="https://pic3.zhimg.com/80/v2-b831bfd3ee292bbf46c1390234163dae_1440w.webp">​</p><p>对于大模型的评估，我们需要围绕评估标准、评测集、评估任务提示模板、评估工具四方面重新建立评估的流程，这四方面也是 LMOps 独有的特点：</p><ul><li>对于大模型的评估我们需要建立新的评估标准，包括针对效果、性能、安全性、生态多样性等各个维度的评估。这些能力都需要在 LMOps 中构建相应的大规模的评估标准来实现。</li><li>在过去，针对经典的深度学习的模型已经有 Benchmark 存在，但是当大模型出现之后，发现这些已经存在的评测集已经不够用了。有些小规模的评测集可能已经包含在大语言模型的训练数据当中了，再去利用这些 Benchmark 做评估，它就没有区分度了，所以新的大规模的评测集需要构建起来。因为大语言模型的能力在不断增强，所以评测集涵盖的方向需要进一步的拓展，包括像数学、历史、图像生成等跨模态等。</li><li>在评估环节，已经不是单纯的用一个指令或者 Query 输入去评估大模型的输出了，而是说会结合不同的评估模板，让机器去做自动的评估，包括通过让大语言模型去做选择题。这样的话就可以更加客观地评估在实际的使用过程中如何提升它的效果。</li><li>和评估环节相应的是评估工具，包括人工可操作的、以及面向机器的评估工具来进行自动化的评估。</li></ul><p>在评估环节，以上四个方面是 LMOps 中新增和特有的。</p><p><img src="https://pic4.zhimg.com/80/v2-2f73116c4a337ba56d083254289d9417_1440w.webp">​</p><p>在推理环节中，LMOps 中最明显的变化就是引入了 Prompt 工程（提示工程）。一个标准的 Prompt 模板，包括对任务背景的陈述，然后提供一些相关的上下文的材料。其中很重要的一点，就是如果能提供一些示例，也称为 few shot，那么大语言模型的输出的效果会显著的有一个提升，最后再加上这次输入的 Query。</p><p>而针对提示模板的构建，也有一系列的要求和实践指导。比如，提示模板的首要要求是安全无害的内容，意图本身模板足够的规范、流畅，提供真实可信的材料等。每一个使用者都需要全部遵守提示模板的要求，但每一个使用者对 Prompt 的书写各有不同，所以遵守 Prompt 模板的要求实施难度较大。所以，在 LMOps 中出现了对应的自动化生成提示工具，为使用者提供提示模板，辅助整个大模型提示工程的实现。</p><p>在很多平台型的 LMOps 工具中，还会自带 Playground，让我们可以直接以对话的形式、或分类摘要等形式直接体验训练 &#x2F; 调优完成的大模型效果。</p><p>在推理环节的最后一部分是基础的 API 服务。企业在自己的应用中使用大模型，通常将 API 与现有的业务集成，使得业务具备更加智能化的体验。从一个模型到服务，需要经历 API 授权、提供访问的 Token 凭证，并对调用进行流控、鉴权等。</p><p><img src="https://pic2.zhimg.com/80/v2-323115addaf566d61ab96bd9a35b86a5_1440w.webp">​</p><p>在部署环节，因为大语言模型参数量很大，需要在服务器上做部署，依赖大规模的 GPU 和 CPU 的资源等。</p><p>但是如果需要把这些大模型的核心能力部署到边缘或者小型化的设备上，甚至于一些性能比较好的手机上，是否有实现的可能？</p><p>大模型如果能做本地的部署，那么它的响应效率会更高，延迟会更低，数据的隐私性会更好。在部署环节，LMops 会引入很多优化，包括量化、蒸馏、交叉编译、国产芯片适配等技术。</p><p><img src="https://pic4.zhimg.com/80/v2-122b2d1c5db5da2ee0a276f0629523ef_1440w.webp">​</p><p>因为大模型的再训练、预训练的资源规模庞大，所以很多企业与个人用户是没有足够的算力资源去支撑他们完成相关任务。针对此情况，企业与个人用户需要依赖云端资源来满足自己的业务需求。</p><p>企业上云，如何保证数据的安全和隐私是企业考虑的重要因素。下图为大家详细介绍的千帆大模型平台就在安全方面做了大量的优化工作。比如千帆大模型平台进行数据加密（包括同态加密、差分隐私等）、为训练环节提供可信的计算环境（包括沙盒环境等），以及在大模型完成部署进行推理的时候如何对数据进行加密、针对用户的隐私数据进行脱敏等。</p><p><img src="https://pic3.zhimg.com/80/v2-9c9d5858abfbec4deb6bb6267a200f3e_1440w.webp">​</p><h2 id="3-千帆大模型平台"><a href="#3-千帆大模型平台" class="headerlink" title="3. 千帆大模型平台"></a><strong>3. 千帆大模型平台</strong></h2><p>接下来，我们将介绍百度智能云<a href="https://link.zhihu.com/?target=https://cloud.baidu.com/product/wenxinworkshop?track=weixin01">千帆大模型平台</a>的能力、特点，以及我们如何在业务场景中使用千帆大模型平台。</p><p>在上层模型应用上，千帆大模型平台托管了文心系列的大模型，包括文心一言 API 调用、以及文心系列大模型的管理、调优等。千帆大模型平台也针对第三方的开源大模型进行了适配，包括已上线的 BloomZ、Llama 2 等，后续千帆大模型平台也将持续引入热门、高价值的第三方大模型。</p><p>在底层资源上，千帆大模型平台提供丰富的算力资源、存储资源及系列账号的管控等服务。将异构算力、高性能的文件系统以及高性能网络管理起来，为大模型的训练、调优、推理提供良好的基础服务。</p><p><img src="https://pic3.zhimg.com/80/v2-738f8fae8685fa69272ac177a2646e8e_1440w.webp">​</p><p>千帆大模型平台具有这样几个特点：</p><ul><li>第一个就是它的易用性，只需要通过简单的几步点击就可以获得效果比较不错的一个模型。</li><li>第二个就是它功能在业内是比较全的，像数据标注和反馈、多种模型训练方式，各种 PEFT 的训练方式、模型部署当中涉及到的小型化和压缩，以及对推理服务的一些管理和插件化应用的集成等，这些功能都是比较全面的。</li><li>第三个就是千帆大模型平台是提供了非常可靠和安全的模型训练和推理服务的环境，包括可信计算的环境，包括隐私数据的脱敏、安全沙箱等。</li><li>第四个就是在千帆大模型平台上有效果和性能优化的工具链，所以使得大模型的研发效率可以得到显著的提升，研发周期可以成倍的缩短。</li><li>第五个就是千帆大模型平台是一个开放的平台，不仅有效果优异的文心一言的模型，它还会更多的引入第三方的优秀的开源大模型。</li><li>最后就是在千帆大模型平台上托管的这些模型，我们会非常注重它的这个可扩展性。这些是面向场景和面向应用的可扩展性，那包括对这个插件机制的支持，包括对这个服务应用编排的这个支持。</li></ul><p>因此，千帆大模型平台是在 LMOps 的方法论指导下，针对大模型的平台功能和工具链的一个具体实现。</p><p><img src="https://pic3.zhimg.com/80/v2-fb3aa8df7b4f0164d84270b3f1e92b3a_1440w.webp">​</p><p>接下来，我们演示一下在千帆大模型平台进行 RLHF 的过程。详细的演示 Demo 请参考「百度智能云技术站」视频号的回放，从视频的 40 分 45 秒处开始观看。</p><p><img src="https://pic2.zhimg.com/80/v2-ead4d443154ee415f2bc2ac05d0007b9_1440w.webp">​</p><h2 id="4-产业实践"><a href="#4-产业实践" class="headerlink" title="4. 产业实践"></a><strong>4. 产业实践</strong></h2><p>在这里，我们演示一个基于千帆大模型平台搭建的行业应用。这是大模型做投资顾问的场景，能够依据客户的投资偏好等，对客户的投资组合进行分析和评估，并诊断目前的投资组合中的风险，并给出进一步的投资建议和相应的逻辑。</p><p>这不仅提升了金融行业的工作效率，更重要的是他提供了创造性的输入，为决策进行辅助。</p><p>详细的演示 Demo 请参考「百度智能云技术站」视频号的回放，从视频的 44 分 30 秒处开始观看。</p><p><img src="https://pic1.zhimg.com/80/v2-6b5dd253f8242be1c5772ea9d938bc4c_1440w.webp">​</p><p>对于大型的企业，智能化升级的需要显然不是几个模型就可以满足的，他需要一整套完整的企业级解决方案。例如大型企业将业务布局在全国及下属的各类子公司，如何管理企业中不同层级的子公司对 AI 能力的建设、使用和共享，如何协同云边端的 AI 能力，都需要企业解决方案来实现。</p><p><a href="https://link.zhihu.com/?target=https://cloud.baidu.com/product/wenxinworkshop?track=weixin01">千帆大模型平台</a>和<a href="https://link.zhihu.com/?target=https://cloud.baidu.com/solution/aiplatform/index.html?track=weixin01">百度 AI 中台</a>解决方案可以帮助大型企业轻松实现从总公司到下属公司 AI 能力全生命周期的管理和建设，帮助企业实现智能化升级。</p><p><img src="https://pic3.zhimg.com/80/v2-14a2d029566eba1f970eeb21bf482bc6_1440w.webp">​</p><p>本次课程为大家全面分享了从机器学习到百模大战的发展路径、LMOps 相关概念和关键技术、以及千帆大模型平台的特点，以及产业实践四个方面的内容。</p><p><img src="https://pic1.zhimg.com/80/v2-a4875c38c0f37b3f2b2a5c80bf05e898_1440w.webp">​</p><p>‍</p>]]></content>
      
      
      <categories>
          
          <category> AI工程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大模型 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大规模AI高性能网络的设计与实践</title>
      <link href="/article/%E5%A4%A7%E8%A7%84%E6%A8%A1AI%E9%AB%98%E6%80%A7%E8%83%BD%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E8%B7%B5.html"/>
      <url>/article/%E5%A4%A7%E8%A7%84%E6%A8%A1AI%E9%AB%98%E6%80%A7%E8%83%BD%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E8%B7%B5.html</url>
      
        <content type="html"><![CDATA[<h2 id="1-大模型训练对网络的要求"><a href="#1-大模型训练对网络的要求" class="headerlink" title="1. 大模型训练对网络的要求"></a><strong>1. 大模型训练对网络的要求</strong></h2><p>我们先来聊聊大模型训练对网络的需求。</p><p>最近半年以来大模型持续火爆。虽然关于大模型的发展与应用还有很多的争论，但可以肯定的是，大模型能力已经成为了接下来人工智能发展的基础。</p><p>和以前的小模型相比，大模型对大规模的分布式并行训练有更强的诉求。</p><p>这一方面是因为模型本身非常大。受制于今天的 GPU 显存限制，我们不得不把一个模型分拆到很多个 GPU 上来存储。比如说，百度的文心大模型有 2600 亿个参数，但是实际上一个 80G 显存的 A800，算上训练中间的计算状态，也只能存放大概 10 亿-20 亿参数。那显然光是存放 2600 亿的模型本身，就需要一两百块 GPU。这已经是一个比较大的规模了。</p><p>另一方面，因为训练更多的参数需要更多的计算量，因此我们必须得引入更大规模的 GPU 来进行加速，所以我们需要的 GPU 又要有一个数量级的提升。</p><p>在百度我们根据一个任务的 GPU 卡数来命名训练的规模。比如百卡以下我们叫小规模，百卡到千卡我们叫中规模，千卡以上我们叫大规模，超过万卡我们则以超大规模进行命名。依照这个命名方式，我们可以说，千卡以上的大规模并行训练是大模型成功的基础。</p><p><img src="https://pic1.zhimg.com/80/v2-8b075997eeb63b9cb4040f95e3db72f0_1440w.webp">​</p><p>分布式并行训练有多种策略，我们这里列举出常用的三种。</p><span id="more"></span><ul><li>应用最广泛的是数据并行。在数据并行里，每个 GPU 都拥有同样的模型副本，数据集则拆分成多份给到不同的 GPU 进行训练。每一轮迭代训练完成后，各个 GPU 需要把各自反向计算得到的梯度做全局同步，然后各个 GPU 计算出下一轮迭代用到的参数。在数据并行中，网络上需要对各个 GPU 上的梯度做一次 Allreduce，通信的数据量规模和模型参数规模成正比，对于千亿规模参数的大模型来说数据通信量都是很大的。</li><li>第二种并行策略就是流水线并行。神经网络模型通常都是多层神经元的组合，包括大模型底层的 Transformer 模型也是这样。我们可以把模型按照神经元的层次进行拆分，不同层放到不同的 GPU 上去。这种并行策略需要不同 GPU 之间做层间点到点数据传递，传输的内容包括正向计算里的激活值和反向计算里的梯度值。这种通信在一个迭代里至少会发生几十次，但通信量一般不大，对网络的性能要求相对较低。</li><li>第三种并行策略就是张量并行，也就是联合多个 GPU 同时做一个张量计算，比如说矩阵乘法。这种并行策略需要多个 GPU 间对局部的张量计算结果做全局的 Allreduce 同步。这里的张量计算结果的大小，不仅和模型有关，也和训练使用的 batchsize 相关，通常都非常大，并且在一次迭代里会发生很多次这样的 Allreduce。因此张量并行对网络带宽的需求是最大的。</li></ul><p><img src="https://pic2.zhimg.com/80/v2-3d711f37a001b31eb780d797b5eb6549_1440w.webp">​</p><p>考虑到三种并行策略的特点，我们在训练大模型时，通常混合采用了三种并行策略。</p><p>首先在单机内部的多 GPU 卡间，我们采用张量并行，充分利用单机内部 NVLink 的高带宽特性。</p><p>其次，由于模型过大，单机 8 卡肯定还是放不下，因此在多机间继续采用流水线并行的策略，多路流水线并行构成一个模型训练的最小单元。</p><p>最后，为了进一步加速模型训练，我们再使用多路数据并行。注意这里数据并行的单元我们叫做一个 DP 组，每个 DP 组内部都是张量并行和流水线并行共存。</p><p>数据并行中的 Allreduce 实际上是每个 DP 组的同号卡之间进行的。比如这个图里，8 路张量并行，4 路流水线并行，3 路数据并行。在数据并行里，实际上有 32 个 Allreduce 组，每个组里有 3 张 GPU 做梯度同步。</p><p>数据并行里每张 GPU 卡都需要对 10GB 级别的数据做 Allreduce，这个 Allreduce 是大模型训练对网络的主要需求。</p><p><img src="https://pic4.zhimg.com/80/v2-4c0608e7659733d676cec3c4bd739ad7_1440w.webp">​</p><p>正是由于大模型训练里这些需求，我们提出了 AI 高性能网络的三大目标：超大规模、超高带宽以及超长稳定。</p><p>首先，规模的大小直接决定了模型训练的快慢。这张图里可以看到，对于一个 1750 亿的模型，如果采用 2 千张 GPU，仍然需要训练 100 天以上。采用 8 千卡则可以把时间压缩到 30 天左右。这对于今天快速迭代的大模型而言是非常重要的。</p><p>其次，Allreduce 的带宽直接决定了大规模分布式下的整体效率。我们可以看下面这个图，平均单 GPU 的 Allreduce 带宽有 5GB&#x2F;s 的时候，大规模分布式的整体加速比只有 70%。想要获得 90% 的加速比，单 GPU 的 AllReduce 带宽则需要做到 20GB&#x2F;s，相当于单 GPU 跑满 400G 网卡。</p><p>最后是稳定的问题，由于训练时长至少是几个星期，长时间下的稳定性显得非常重要。这个图里我们以 GPU 可用性为例来做个简化讨论，假定单 GPU 的月可用性是 99.9%，那么在千卡规模下模型训练一月内遇到故障发生中断的概率是 60%，而如果采用 8 千卡中断概率就有 99%。即使 GPU 的可用性提升到 99.99%，8 千卡下的中断概率仍然在 50% 左右。</p><p>我们这里以 GPU 可用性举例，是因为大模型训练中碰到的主要可用性问题来自于 GPU。当然网络必须保证更高的可用性，才能尽可能减少模型的训练中断，降低模型做 checkpoint 的频率以及开销。</p><p><img src="https://pic1.zhimg.com/80/v2-bc16962ca250c2c7c648fb0f326116c0_1440w.webp">​</p><h2 id="2-AIPod-高性能网络设计"><a href="#2-AIPod-高性能网络设计" class="headerlink" title="2. AIPod 高性能网络设计"></a><strong>2. AIPod 高性能网络设计</strong></h2><p>基于这样的目标，我们有针对性地设计了 AI 大底座里面的 AI 高性能网络—— AIPod。</p><p>这张图是关于 AIPod 高性能网络的点线图。注意这是一张完全图，我们把每一个网卡、每一个交换机、每一条线缆都画了出来，充分展现出这张网络的复杂性。这张网络里面有约 400 台交换机、3000 张网卡、10000 根线缆和 20000 个光模块。其中仅线缆的总长度就相当于北京到青岛的距离。</p><p><img src="https://pic4.zhimg.com/80/v2-94f0807c26fb5c456ae2b21991095023_1440w.webp">​</p><p>当然上一个图只是一个感性的认识，接下来我们要聊聊理性的设计。</p><p>为了支撑超大规模的这张 AIPod 网络，我们选择了 3 层无收敛的 CLOS 组网结构。所谓的 CLOS 组网就跟这张图展示的一样，服务器在最下面，连接到 Leaf 层交换机，也就是图里的 LF，然后 Leaf 交换再通过 Spine 交换机连接起来，就是图里的 SP。最后 Spine 交换机再通过 SuperSpine，也就是 SSP 互联起来。</p><p>我们前面说到，在大模型训练的时候，主要的通信来自于同号 GPU 卡之间，也就是一台服务器的 1 号卡和另一台服务器的 1 号卡之间通信，一台服务器的 2 号卡和另一台服务器的 2 号卡之间通信，以此类推。较少的情况下才会发生跨卡号通信，比方说一台服务器的 1 号卡和另一台服务器的 2 号卡通信。所以，AIPod 网络在设计的时候，采用了 8 通道的架构。每个服务器上的 8 个网口，对应 8 个 GPU，分别连接 8 个不同的 Leaf 交换机。这 8 个 Leaf 交换机一组，构成了一个汇聚组 Group。这样的一个汇聚组下最大可以有 512 张 GPU。进一步，8 个 Leaf 交换机再往上连入不同的 8 个通道，每个通道内 Spine 交换机和 Leaf 交换机之间做 fullmesh 全互联。这样的一个集群最大可以支持超过 16K GPU。</p><p>虽然主要的通信发生在同一个通道内，但总还是会存在跨通道的通信。所以我们通过 SuperSpine 再把不同的通道的 Spine 交换机连接起来，打通各个通道。这就是 AIPod 的组网方式。AIPod 的网络我们采用了无收敛，或者说收敛比为 1:1 的方案，也就是指交换机的上联带宽等于下联带宽，确保集群内互通带宽充足。</p><p>为了尽可能支撑更大的规模，我们在选择交换机的时候，会选用当前顶级容量的交换芯片，比如曾经的 12.8T 或者 25.6T 芯片，那么现在已经演进到了单芯片 51.2T 的交换机。</p><p><img src="https://pic1.zhimg.com/80/v2-e2e8b440b5264253f405e813e56ddef4_1440w.webp">​</p><p>上面我们主要讲了大规模的 AIPod 怎么构建。接下来我们谈谈带宽的问题。</p><p>百度智能云选择单机最大 8x400G 的接入规格，网络上选择了无收敛比的 CLOS 架构，同时也支持 RDMA 和 GDR，理论上带宽可以做到很高的水平。但是实际上，当规模一大，就会产生很多的问题。其中一个最主要的问题，就是跨交换机的选路冲突。</p><p>从技术上说，几乎所有的网络传输都有一个固有的问题，就是同一条连接在网络内要避免乱序，因为一旦发生乱序，在接收端就会触发重传逻辑导致降速。所以网络内交换机转发报文的时候，会把同一条连接的报文会向一条路径转发，而这条路径的选择就依赖哈希算法。</p><p>我们知道哈希算法总是会有冲突的，像是左边这个图里展示的，2 个跨交换机的连接如果同时选择了左边这个链路，那么就会导致左边链路拥挤而右边的链路空闲，这样两个连接的带宽都会减半。这种问题在大规模训练中太常见了。</p><p>为了缓解这类问题的影响，我们通常会在 NCCL 通信库里面设置两个 GPU 间采用多个连接的方式，比方说右边这个图，连接数一多，出现严重不均衡的概率也就越小。这种方法可以增加网络内的路由熵，减小哈希选路冲突所带来的影响，但是问题并没有彻底解决。</p><p><img src="https://pic1.zhimg.com/80/v2-a964fbb7fe6a8b2a637197860fffe964_1440w.webp">​</p><p>我们可以看到，这类问题只发生在跨交换机通信的场景。所以为了进一步减小这个问题的影响，我们应该尽可能让通信发生在一个交换机内。而同一个汇聚组内的同号 GPU 通信，是不会跨交换机的，也就没有哈希选路冲突问题。这也是为什么我们尽可能扩大一个汇聚组规模的原因。</p><p> <strong>为了减少跨交换机的通信，在 AIPod 里我们提供了网络架构感知的方法。</strong> 网络架构感知，就是允许上层感知到当前 GPU 在网络架构的什么位置，归属于哪一个汇聚组，它的 GroupID 是多少。</p><p><strong>AIPod 可以把这个信息透给上层的任务调度系统，让训练任务调度的时候，把同一个任务尽可能调度在同一个汇聚组下，这样通信肯定也就只在一个汇聚组内了。</strong></p><p>但是大模型的任务通常很大，不可能全在一个汇聚组下。这时我们就需要通过汇聚组信息对全局 GPU 做有序化处理，让通信库在构建 Allreduce 拓扑图的时候，减少跨交换机的互通流量。我们用右下角这个图来说明，4 个 GPU 做 AllReduce，采用 ring 算法，两种不同的 ring 的构建顺序，会使得跨交换机的带宽有很大的差别。显然左边的这种建 ring 的方法是更高效的，而右边则是低效的。这就是 AIPod 里面网络架构感知所带来的收益。</p><p><img src="https://pic4.zhimg.com/80/v2-e88dcf2577dbb6486d911c901e7d3423_1440w.webp">​</p><p>网络架构感知可以明显缓解跨交换机通信的数量，从而减少哈希选路冲突的影响。但是问题并没有彻底解决，冲突仍然存在。</p><p>如果想彻底解决这个问题，就需要用到网络的多路径转发能力。也就是允许报文的乱序接收，从而打破单连接报文只能选择一个路径这种假设。Infiniband 网络里面引入了这种多路径转发能力，叫做自适应路由。<strong>而在 AIPod 里面，我们依托百度的自研交换机，在以太网上通过动态负载均衡 DLB 技术也实现了类似的能力。</strong></p><p>就以下图为例，首先在发送端，网卡要通过标记允许报文被乱序处理，而在交换机上会根据当前各个路径上的队列深度、利用率等信息，计算出每个报文当前的最佳路径进行转发。这样肯定会引入同连接报文的乱序问题，所以需要在接收端对乱序的报文做重排处理。</p><p>经过这一系列的组合机制，就可以彻底解决跨交换机通信的哈希选路冲突问题。我们相信这种底层的技术能力增强，才是解决大规模训练的终极方案。</p><p><img src="https://pic4.zhimg.com/80/v2-acaac6a776c6df2a28e823c328598d73_1440w.webp">​</p><p>接下来我们再来聊聊稳定性相关的问题。</p><p>保持任务长时间不中断对于大模型训练是很重要的，但是硬件终究会有故障。举个例子，对于一个可以承载 16000 卡的集群而言，里面会有将近 10 万个光模块。考虑到真实硬件的质量水平，假定一个模块的 MTBF 是 1 千万小时。这里 MTBF 指的是一个硬件设备在故障前的平均使用时长。因为模块基数太大，哪怕是 1000 万小时的 MTBF，也会导致平均下来 4 天左右就会发生一个故障发生。在这么大的基数下，单体的小概率事件也会演变成总体的大概率事件。</p><p>所以，AIPod 网络着重构建快速从硬件故障中恢复的能力。比如网络里面的某条链路发生了故障，通过这个链路的报文都会发生丢包。我们必须让这个丢包的时长低于通信库通常设置的超时时间，这样任务才不会中断。</p><p>在 AIPod 里面，对于上行方向的这一类丢包，通过动态负载均衡技术，可以在毫秒级的时间尺度上面得到修复，也就是选择新的可用链路。而对于下行方向的这一类丢包，需要触发网络内的路由更新和路由收敛，通过优化路由更新策略以及路由下发效率，来把下行方向的丢包时长控制在秒级水平。这样我们就可以做到网络内硬件故障对训练业务基本透明。</p><p><img src="https://pic1.zhimg.com/80/v2-476b09a9ca6fc0c893c1a301859d4dc8_1440w.webp">​</p><p>当然网络的复杂度在于，有一些硬件故障是不能被显式直接感知到的。比如某些交换机芯片缺陷所带来的比特翻转问题，会导致报文在传输过程中某个比特位被修改从而丢包。这种问题不像设备故障那样可以被直接发现，非常难以排查。</p><p>为了充分发现这些隐藏的问题，我们基于百度自研交换机设计了 AIPod 网络的黑盒探测机制，确保每条链路上每秒都有黑盒探测报文。探测一旦发现连通性问题就会触发自动的定位和隔离机制，把问题链路、问题设备隔离掉，并且触发告警，让运维人员快速介入进行修复。</p><p><strong>AIPod 里面的黑盒探测机制，是保障各种网络问题被第一时间感知到的关键。</strong></p><p><img src="https://pic4.zhimg.com/80/v2-507667004e1b9429db56f71c8a6259b7_1440w.webp">​</p><p>对于 AIPod 高性能网络而言，除了连通性故障以外，还有一类故障与连通性无关，而是与无损网络有关。</p><p>AIPod 高性能网络是无损网络，也就是说网络内不会产生拥塞丢包。这是依赖网络内的 PFC 技术实现的。但是无损网络也可能会有异常。</p><p>常见的一个异常是 PFC 死锁，这个技术上比较复杂，原理我们就不展开了，从效果上看会导致网络永久性挂死。因此我们在网络内一定会启用死锁检测。但问题在于，来自于交换芯片的死锁检测总是有假阳性判断的存在，从而导致瞬时误丢包。第二个常见异常通常是来自于芯片故障，尤其是网卡芯片故障所带来的持续性 PFC 风暴，这会导致集群整体的传输效率下降。</p><p>这两类与无损网络相关的异常是固有问题，我们目前还不能完全消除。但是， <strong>通过基于百度自研交换机的 Telemetry 遥测技术，我们搭建了无损网络的性能透视平台，确保网络内的任一丢包信息和 PFC、缓存的异常变化都能被迅速感知到</strong> 。通过这样的性能透视平台，这类问题可以被第一时间发现并解决掉，最终并不会影响到大模型的稳定训练。</p><p><img src="https://pic3.zhimg.com/80/v2-45d976d89002cca882f8a918a8c59316_1440w.webp">​</p><p>讲完了 AIPod 的大规模、高带宽和长稳定设的计，接下来作为一个番外篇，我们聊聊超低延迟的 AIPod 网络。</p><p>之所以把这个内容放到番外篇来讲， <strong>是因为对于大模型训练而言，延迟并不是一个核心考虑，带宽才是核心。</strong> 只要能做到微秒级别的网络延迟，在网络上进一步降低几个微秒的延迟在端到端的性能上几乎看不出任何的影响。但是从技术上说，仍然存在一些特定的 AI 业务是延迟敏感的。AIPod 网络也一样能满足低延迟的诉求。</p><p>我们先来拆解一下网络延迟的构成，除了总线、网卡、光模块、交换机的硬件延迟以外，我们真正有机会优化的只有两个延迟，一个是光纤延迟，另一个是交换机排队时延。</p><p>光纤时延之所以重要，是因为光速是有限的。光在玻璃里的传输速度是每秒 20 万公里，换句话说，两个 GPU 间每增加 200m 光纤，就会增加 1 微秒的时延。为了让集群内任意两个 GPU 之间的延迟尽可能低，AIPod 里我们优化了整个集群在机房内的布局，使得服务器和交换机以及交换机和交换机之间的距离尽可能近，从而能够采用更短的光纤连接。</p><p>另一方面，交换机排队延迟与交换机的缓存占用有关。一个交换机端口上每有 1MB 的缓存，就会导致 25us 延迟的增加。AIPod 内部我们优化了的拥塞控制参数，尽可能保证在不影响带宽的前提下，降低交换机的缓存占用，以此实现更低的延迟。</p><p><img src="https://pic2.zhimg.com/80/v2-73555b201c81bd9d512e8c9b7a2787fd_1440w.webp">​</p><p>大规模、高带宽、长稳定、低延迟，我们关于 AIPod 高性能网络的设计要点基本讲完了。接下来再看一个番外篇。</p><p>刚才讲的 AIPod 网络主要指的是连接 GPU 的训练网络。但其实存储的读写性能也对大模型的训练非常重要，这里面就包括了数据集的读取以及训练过程中 checkpoint 的读写。</p><p> <strong>存储主要依赖的还是云上的 VPC 网络，百度智能云在 VPC 网络上也做了相应的高性能支持。</strong> 比如如果要访问并行文件系统 PFS，我们有高性能的弹性 RDMA 技术进行支撑，单客户端能够做到 200G 的带宽。</p><p>而如果要访问普通的文件存储 CFS 或者是对象存储 BOS，也可以通过挂载我们的高性能硬件负载均衡实例，单客户端获得超过 10G 的稳定带宽。</p><p>存储底层的这些高性能技术的使用，对于大模型的计算效率也有很大的贡献。</p><p><img src="https://pic3.zhimg.com/80/v2-12f6044f72b75bea1c9642cff4f04082_1440w.webp">​</p><h2 id="3-AIPod-大模型训练实践"><a href="#3-AIPod-大模型训练实践" class="headerlink" title="3. AIPod 大模型训练实践"></a><strong>3. AIPod 大模型训练实践</strong></h2><p>以上就是我们关于 AIPod 高性能网络设计的分享。接下来我们再看看百度基于 AIPod 网络所做的一些大模型训练的实践。</p><p>这里展示的是在百度百舸平台上的两个千卡规模的训练流量图，分别来自于 RoCE 集群和 IB 集群。</p><p>两个集群上的模型稍有不同，但都达到了单卡百 G 水平的通信带宽并且可以长期稳定运行。</p><p>搞过大模型训练的同学应该都有切身感受，真正把千卡任务跑起来并且顺利的跑完并不是一件容易的事情。过程中会遇到很多很多的问题，我们需要一些辅助工具来帮助我们快速判断问题的源头是什么。</p><p>这里我想着重讲两个工具，一个是任务可视化工具，一个是故障诊断工具。</p><p><img src="https://pic3.zhimg.com/80/v2-5496b2e59e37e0ba7e1c7f6a9b830c0e_1440w.webp">​</p><p>任务维度的高精度可视化工具对于判断任务是否正常训练非常的重要。这里有两个重点，一个是任务维度，另一个是高精度。</p><p>所谓任务维度，指的是我们要能够把归属于一个任务的几百上千个实例的监控数据合并到一起来看。因为并行训练的特点，这些实例理论上展现出来的网络流量信息是高度一致的。一旦有不一致的存在，我们就很容易发现异常。</p><p>所谓高精度，是指我们的监控采集必须是秒级甚至是亚秒级的。我们前面提到，一次迭代的 Allreduce 通信量是 10GB 级别的，听上去很大，但是放到一个 100G 网卡上也不过只需要 2 秒的时间就传完了，如果是 400G 网卡只需要半秒的时间。所以，如果还是采用传统的 10 秒采集甚至是分钟级采集，那么我们对网络流量的观测一定是扭曲的，会干扰我们对于任务状态的判断。比如上面这个图展示的就是早期我们做的 10 秒采集，看到的峰值带宽只有 20G，这显然是不对的。等到我们做了 1 秒采集后，就可以精确的看到脉冲式的流量图，流量峰值也达到了 100G。</p><p><img src="https://pic1.zhimg.com/80/v2-71026c839c2934bb50adfc11c51e89c8_1440w.webp">​</p><p>第二个关键工具是故障诊断工具。</p><p> <strong>大模型训练经常会碰到各种各样的异常，很多异常会表现为通信库通信异常。但是这些异常的根本原因多数情况下并不是网络问题。</strong> 举个例子，左边这个是我们一个客户的 case，在框架日志里面看到了 NCCL 相关的 Timeout。但是该 case 的真实原因其实是 GPU 的故障。针对这类问题，我们需要故障的一键定位，从各个节点的相关日志里提取信息并且自动分析，让故障的根因更快的被找到。</p><p>有些软硬件的问题并不一定导致任务完全卡死，而是会有慢节点的存在。大模型的训练会因为一个慢节点而拖累全局速度，也就是一点慢，全局慢，所以有的时候并不能直接通过任务维度的可视化工具找到问题所在。针对这个问题，我们也研发了对应的慢节点搜索工具，能够在一个集群内自动以二分的方式测试集合通信带宽，从而找到或者排除掉慢节点的存在。这对于真实问题的定位也是有很大帮助的。</p><p><img src="https://pic2.zhimg.com/80/v2-11c9eff598f697b0fa6098f1d55658b5_1440w.webp">​</p>]]></content>
      
      
      <categories>
          
          <category> AI工程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大模型 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GPT和BERT的差别</title>
      <link href="/article/GPT%E5%92%8CBERT%E7%9A%84%E5%B7%AE%E5%88%AB.html"/>
      <url>/article/GPT%E5%92%8CBERT%E7%9A%84%E5%B7%AE%E5%88%AB.html</url>
      
        <content type="html"><![CDATA[<h2 id="NLP的技术原理"><a href="#NLP的技术原理" class="headerlink" title="NLP的技术原理"></a><strong>NLP的技术原理</strong></h2><p>首先，我们要弄明白，NLP任务（自然语言处理，AI的一个技术领域，即文本类的AI任务）的核心逻辑是一个“猜概率”的游戏。</p><p>比如说，“我今天被我朋友___”，经过大量的数据训练后，AI预测空格出会出现的最高概率的词是“放鸽子了”，那么CPU就会被填到这个空格中，从而答案产生——“我今天被我朋友放鸽子了”</p><p>虽然非常不可思议，但事实就是这样，现阶段所有的NLP任务，都不意味着机器真正理解这个世界，他只是在玩文字游戏，进行一次又一次的概率解谜，本质上和我们玩报纸上的填字游戏是一个逻辑。只是我们靠知识和智慧，AI靠概率计算。</p><p>在近几年的<a href="https://link.zhihu.com/?target=https://cloud.tencent.com/product/nlp?from=10680">自然语言处理</a>领域中，BERT和GPT是两个引起广泛关注的语言模型。特别是在<a href="https://link.zhihu.com/?target=https://beta.openai.com/docs/model-index-for-researchers">GPT3.5</a>的基础上进行微调的<a href="https://link.zhihu.com/?target=https://openai.com/blog/chatgpt/">chatGPT</a>，持续出圈和火爆。chatGPT的火爆表明了预训练语言模型在自然语言处理领域具有巨大的潜力，并且在提高自然语言理解和生成能力方面取得了显著的进展。这可能会带来更多的应用和更广泛的接受。</p><p>BERT和GPT也都是基于预训练语言模型的思想，通过大量的语料训练而得到的高效率的语言模型。为了帮助大家更好的理解和选择不同的技术和模型，本文将着重比较BERT和GPT这两个语言模型之间的区别，为大家提供一个全面的认识。</p><span id="more"></span><h2 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h2><p>大约在6年前，一篇大名鼎鼎的论文《Attention Is All You Needed》正式发表，它第一次提出了注意力机制（Attention），并且在Attention的基础上创造了一个全新的NLP（自然语言处理）模型Transformer。</p><p>Transformer是GPT和BERT的前身。谷歌和OpenAI在自然语言处理技术上的优化，都是基于这个模型。</p><p>更多关于的Transformer可以看文章：<a href="https://zhuanlan.zhihu.com/p/607423406">ChatGPT与Transformer（无公式版）</a></p><p><img src="https://pic4.zhimg.com/80/v2-c5098badafbe7371e7ef328373c3bb9f_1440w.webp">​</p><p>而在目前的“猜概率”游戏环境下，基于大型语言模型（LLM，Large Language Model）演进出了最主流的两个方向，即Bert和GPT。</p><p>其中BERT是之前最流行的方向，几乎统治了所有NLP领域，并在自然语言理解类任务中发挥出色（例如文本分类，情感倾向判断等）。</p><p>而GPT方向则较为薄弱，最知名的玩家就是OpenAI了，事实上在GPT3.0发布前，GPT方向一直是弱于BERT的（GPT3.0是ChatGPT背后模型GPT3.5的前身）。</p><p>上图是Transformer的一个网络结构图，Bert的网络结构类似于Transformer的Encoder部分，而GPT类似于Transformer的Decoder部分。单从网络的组成部分的结构上来看，其最明显的在结构上的差异为Multi-Head-Attention和Masked Multi-Head-Attention。</p><p>不论是早期的利用LDA、RNN等统计模型或很小的深度学习模型的时代，还是后来利用BERT等预训练配合微调的时代，技术所提供的能力是相对原子化的，距离实际的应用场景有一定的距离。就拿前面举的让ChatGPT根据要求写英文邮件的例子，按照此前的做法，可能需要先抽取实体、事件等内容（比如时间、地点、事件等），然后通过模版或是模型形成邮件的样式，再通过一个翻译模型转化为英文。当然如果数据量足够训练端到端模型的情况下，也可以跳过中间的若干步骤。但不论采用哪种方式，要么需要将最终的场景拆解成原子化的NLP任务，要么需要对应的标注数据。而对于ChatGPT来说，只需要一个合适的指令。</p><p><img src="https://pic1.zhimg.com/80/v2-14554d66887c6741addffcdabe6dd82c_1440w.webp">​</p><p>三个阶段的NLP技术范式</p><h2 id="BERT和GPT两者之间的差别。"><a href="#BERT和GPT两者之间的差别。" class="headerlink" title="BERT和GPT两者之间的差别。"></a>BERT和GPT两者之间的差别。</h2><ul><li><strong>BERT：双向 预训练语言模型+fine-tuning（微调）</strong></li><li><strong>GPT：自回归 预训练语言模型+Prompting（指示&#x2F;提示）</strong></li></ul><p>BERT和GPT是近年来自然语言处理领域中非常重要的模型，它们代表了现代NLP技术的发展。需要注意的是, 这两个模型并不是NLP领域唯一的重要模型，在近几年中还有很多其他的模型和方法被提出，也在被广泛使用。</p><h3 id="BERT"><a href="#BERT" class="headerlink" title="BERT"></a>BERT</h3><p>BERT，全称为Bidirectional Encoder Representations from Transformers，是由Google AI Language团队在2018年提出的预训练语言模型。BERT是基于Transformer网络架构和预训练语言模型的思想而提出的。它可以在不同语言任务上达到最先进的水平。</p><p>BERT展示了预训练语言模型对于自然语言理解任务的巨大潜力，在诸多任务中取得了突破性进展，成为了自然语言理解任务中的基准模型。</p><p>BERT的训练过程分为预训练和微调两部分。</p><p>预训练是BERT模型的基础部分，它包括使用大量的文本来训练语言模型。在预训练阶段，BERT模型会学习到大量的语言知识，如词汇、语法、句子结构等。预训练的目的是为了让BERT模型具有足够的语言能力来处理各种不同的自然语言任务。</p><p>微调过程是在预训练模型的基础上，使用更小的标记数据来调整模型参数。这样可以使得模型更适合特定的任务。大部分使用BERT技术来装备NLP能力的企业，只需要通过微调来让模型更适合特定的任务，而不需要重新预训练。 而预训练过程需要大量的计算资源和时间，所以微调是一种更加高效和经济的方式。</p><p>BERT主要用于自然语言理解，具体应用如下：</p><ul><li>问答系统：BERT可以在问答系统中用来理解问题并生成答案。</li><li>句子相似度比较：BERT可以用来比较两个句子之间的相似程度。</li><li>文本分类：BERT可以用来对文本进行分类。</li><li>情感分析：BERT可以用来对文本进行情感分析。</li><li>命名实体识别：BERT可以用来识别文本中的命名实体。</li></ul><h3 id="GPT"><a href="#GPT" class="headerlink" title="GPT"></a>GPT</h3><p>GPT（Generative Pre-trained Transformer）则是由OpenAI研究团队在2018年提出的一种语言模型。其起源于对传统预训练语言模型（如ELMO和ULMFit）的改进和升级，采用了Transformer架构，并通过预训练+微调的方式实现语言理解和生成。</p><p>GPT则展示了预训练语言模型在语言生成任务中的潜力。它被广泛应用于各种文本生成任务，如文本自动完成、对话生成、文章摘要等。</p><p>GPT预训练的数据来源是网络上的大量文本数据，例如维基百科，新闻文章等。模型首先学习了基本的语言知识和结构，然后再在特定的任务上进行微调。微调过程中，模型会根据特定任务的需要来学习相关的知识。</p><p>GPT能够完成各种自然语言处理任务，在文本生成方面表现尤为优秀，可以生成各种类型的文本，如文章、诗歌、对话等。其主要具体应用如下：</p><ul><li>文本生成：GPT可以用来生成文本。</li><li>文本自动完成：GPT可以用来自动完成用户输入的文本。</li><li>语言翻译：GPT可以用来生成翻译后的文本。</li><li>对话生成: GPT可以用来生成对话</li><li>摘要生成: GPT可以用来生成文章摘要</li></ul><h2 id="Bert与GPT预训练任务区别"><a href="#Bert与GPT预训练任务区别" class="headerlink" title="Bert与GPT预训练任务区别"></a>Bert与GPT预训练任务区别</h2><p>在Bert与GPT的预训练任务的选取上，Bert与GPT所用的模型也存在着较大的差异。</p><h3 id="Bert——Masking-Input"><a href="#Bert——Masking-Input" class="headerlink" title="Bert——Masking Input"></a>Bert——Masking Input</h3><p>在Bert的预训练任务中，Bert主要使用“填空题”的方式来完成预训练：</p><p>随机盖住一些输入的文字，被mask的部分是随机决定的，当我们输入一个句子时，其中的一些词会被随机mask。</p><p><img src="https://pic4.zhimg.com/80/v2-663eccefa17dba67bbdb0d7bac9cb55b_1440w.webp">​</p><p>mask的具体实现有两种方法。</p><p><img src="https://pic4.zhimg.com/80/v2-44951ea8f0ebb808227a17e86285a553_1440w.webp">​</p><p>第一种方法是，用一个特殊的符号替换句子中的一个词，我们用 “MASK “标记来表示这个特殊符号，可以把它看作一个新字，这个字完全是一个新词，它不在字典里，这意味着mask了原文。</p><ul><li>另外一种方法，随机把某一个字换成另一个字。中文的 “湾”字被放在这里，然后可以选择另一个中文字来替换它，它可以变成 “一 “字，变成 “天 “字，变成 “大 “字，或者变成 “小 “字，我们只是用随机选择的某个字来替换它</li></ul><p>两种方法都可以使用。使用哪种方法也是随机决定的。因此，当BERT进行训练时，向BERT输入一个句子，先随机决定哪一部分的汉字将被mask。</p><p>mask后，一样是输入一个序列，我们把BERT的相应输出看作是另一个序列，接下来，我们在输入序列中寻找mask部分的相应输出，然后，这个向量将通过一个Linear transform，输入向量将与一个矩阵相乘，然后做softmax，输出一个分布。。</p><p><img src="https://pic2.zhimg.com/80/v2-9dedc6466caf8d2d59910d7ec549bb51_1440w.webp">​</p><p>这与我们在Seq2Seq模型中提到的使用transformer进行翻译时的输出分布相同。输出是一个很长的向量，包含我们想要处理的每个汉字，每一个字都对应到一个分数。</p><p>在训练过程中。我们知道被mask的字符是什么，而BERT不知道，我们可以用一个one-hot vector来表示这个字符，并使输出和one-hot vector之间的交叉熵损失最小。</p><p><img src="https://pic2.zhimg.com/80/v2-21655724093a4553c3d9fe0c22813461_1440w.webp">​</p><p>BERT要做的是，预测什么被盖住。被掩盖的字符，属于 “湾”类。</p><p>在训练中，我们在BERT之后添加一个线性模型，并将它们一起训练，尝试去预测被覆盖的字符是什么。</p><h3 id="GPT——Predict-Next-Token"><a href="#GPT——Predict-Next-Token" class="headerlink" title="GPT——Predict Next Token"></a>GPT——Predict Next Token</h3><p>GPT要做的任务是,预测接下来,会出现的token是什么</p><p>举例来说,假设训练资料里面,有一个句子是台湾大学,那GPT拿到这一笔训练资料的时候,选取BOS这个Token所对应的输出,作为Embedding的结果,用这个embedding去预测下一个应该出现的token是什么</p><p><img src="https://pic3.zhimg.com/80/v2-a4eec3dfc129d83edb1d3c83b33a2f0e_1440w.webp">​</p><p>那在这个句子里面,根据这笔训练资料,下一个应该出现的token是”台”,要训练模型,根据第一个token,根据BOS给的embedding,那它要输出”台”这个token</p><p>这个部分,有一个embedding,这边用h来表示,然后通过一个Linear Transform,再通过一个softmax,得到一个概率分布,我们希望这个输出的概率分布,跟正确答案的交叉熵越小越好。</p><p>接下来要做的事情,就是以此类推了,输入BOS跟”台”,它产生embedding,接下来它会预测,下一个出现的token是什么,以此类推来训练模型。</p><p><img src="https://pic1.zhimg.com/80/v2-2fab3ccc2a98e7d88636ad3d7ee4b244_1440w.webp">​</p><p>相同数据集体量的话，bert或许更好。但如果预训练数据暴涨的话，两者的差别就出来了。</p><p>gpt网络的训练是不需要标注数据的，这是它天然非常非常合适于超大数据量的情况的特点。</p><h2 id="Bert和GPT使用方法的区别"><a href="#Bert和GPT使用方法的区别" class="headerlink" title="Bert和GPT使用方法的区别"></a>Bert和GPT使用方法的区别</h2><p>对于Bert和GPT，其本意是提供一个预训练模型，使得人们可以方便的将其运用于下流（downstream）任务当中去。当然，这两种模型最后使用的方法也是有一些区别的。</p><h3 id="Bert的使用方法——以情感分类为例"><a href="#Bert的使用方法——以情感分类为例" class="headerlink" title="Bert的使用方法——以情感分类为例"></a>Bert的使用方法——以情感分类为例</h3><p><img src="https://pic3.zhimg.com/80/v2-44ef51c45dc4f5340ad9a0f76c8bebf6_1440w.webp">​</p><p>只要给它一个句子，也就是你想用它来判断情绪的句子，然后把CLS标记放在这个句子的前面，扔到BERT中,这4个输入实际上对应着4个输出。然后，我们只看CLS的部分。CLS在这里输出一个向量，我们对它进行Linear transform，也就是将它乘以一个Linear transform的矩阵，然后进行Softmax，就可以得到情感分类的结果。</p><p>Bert的使用大多如此，用CLS对应的Output作为Embedding的结果，然后根据不同的任务进行对应的操作来fine-turing，从某方面而言，更像是利用深度学习对文本进行特征表示的过程。</p><h3 id="GPT的使用方法"><a href="#GPT的使用方法" class="headerlink" title="GPT的使用方法"></a>GPT的使用方法</h3><p>对于GPT使用，由于GPT的参数是Bert的4倍有余，使得去fine-turing一个模型需要更长，更大的训练时间。因此GPT提出了一个更加“疯狂”的使用方式，一种更接近于人类的使用方式。</p><p>没有进行梯度下降的”Few short leaning”，也就GPT论文所提到的“In-context learning”</p><p>举例来说假设要GPT这个模型做翻译</p><p><img src="https://pic1.zhimg.com/80/v2-c873f60d5743adddbbe5cc016ac52704_1440w.webp">​</p><ul><li>先打Translate English to French，这个句子代表问题的描述</li><li>然后给它几个范例</li><li>最后接下来给一个Cheese的词，让他翻译成法语。</li></ul><h3 id="fine-tuning-VS-Prompting"><a href="#fine-tuning-VS-Prompting" class="headerlink" title="fine-tuning VS Prompting"></a><strong>fine-tuning VS Prompting</strong></h3><p>假设现在预训练好的大模型要针对具体领域工作了，他被安排成为一名鉴黄师，要分辨文章到底有没有在搞黄色。那么BERT和GPT的区别在哪里呢？</p><p>BERT：fine-tuning（微调）。微调是指模型要做某个专业领域任务时，需要收集相关的专业领域数据，做模型的小幅调整，更新相关参数。</p><p>例如，我收集一大堆标注数据，然后喂给模型进行训练，调整他的参数。经过一段时间的针对性学习后，模型对于分辨你们是否搞黄色的能力更出色了。这就是 <strong>fine-tuning</strong> ，二次学习微调。</p><p>GPT：Prompting。prompt是指当模型要做某个专业领域的任务时，我提供给他一些示例、或者引导。但不用更新模型参数，AI只是看看。</p><p>例如，我提供给AI模型10张黄色图片，告诉他这些是搞黄色的。模型看一下，效果就提升了。大家可能会说，这不就是fine-tuning吗？不是一样要额外给一些标注数据吗？</p><p>两者最大的区别就是：这种模式下，模型的参数不会做任何变化升级，这些数据就好像仅仅是给AI看了一眼——嘿，兄弟，参考下这个，但是别往心里去。</p><p>不可思议吧，但他成功了！而更令人疯狂的是，到目前为止，关于prompt明明没有对参数产生任何影响，但确实又明显提升了任务的效果，还是一个未解之谜。暂时而言大家就像程序员对待bug一样——I don’t know why , but it work lol .</p><p>这种Prompt其实就是ICT（in-Context Learning），或者你也可以称为Few shot Promot，用大白话说就是“给你一点小提示”。</p><p>同时还有另外一种Promot，称之为Zero shot Promot。ChatGPT就是Zero shot promot模式，目前一般称之为instruct了。</p><p>这种模式下用户直接用人类的语言下达命令，例如“给我写首诗”，“给我做个请教条”，但是你可以在命令的过程中用一些人类语言增强AI的效果，例如“在输出答案之前，你先每一步都想一想”。就只是增加这样一句话，AI的答案效果就会明显提升。</p><h3 id="“One-shot”-Learning-“Zero-shot”-Learning"><a href="#“One-shot”-Learning-“Zero-shot”-Learning" class="headerlink" title="“One-shot” Learning “Zero-shot” Learning"></a>“One-shot” Learning “Zero-shot” Learning</h3><p>例如我们在考听力测验的时候,都只给一个例子而已,那GPT可不可以只看一个例子,就知道它要做翻译，这个叫One-shot Learning</p><p>还有更厉害的是Zero-shot Learning,直接给它一个叙述,说现在要做翻译了,来看GPT能不能够自己就看得懂,就自动知道说要来做翻译这件事情。</p><p><img src="https://pic2.zhimg.com/80/v2-e0b518b3b008c5509498f8d261ed5619_1440w.webp">​</p><p>GPT在没有微调的情况下，这种使用方法虽然准确率不够高，但是随着GPT参数量的增加，在一定程度上仍然有着一定的准确率。</p><p><img src="https://pic4.zhimg.com/80/v2-acceb6fe776a1bf1b6a9c7e6c83eef03_1440w.webp">​</p><p>这就是GPT相比较于Bert更加独特的一种使用方式。</p><h2 id="BERT和GPT的主要区别总结"><a href="#BERT和GPT的主要区别总结" class="headerlink" title="BERT和GPT的主要区别总结"></a>BERT和GPT的主要区别总结</h2><p>从上面的介绍看，BERT和GPT都是基于Transformer的预训练模型，都包含了预训练和微调的过程。都能够应用于各种NLP的任务。但实际上，他们又有许多不同之处，在我们选择时，需要稍加注意。</p><h3 id="GPT的训练相对于BERT有以下不同之处："><a href="#GPT的训练相对于BERT有以下不同之处：" class="headerlink" title="GPT的训练相对于BERT有以下不同之处："></a>GPT的训练相对于BERT有以下不同之处：</h3><ul><li>GPT使用的是Transformer模型，而BERT使用的是双向Transformer模型。</li><li>GPT的预训练数据来源是大量的网络文本数据，而BERT的预训练数据来源是两个大型语料库，包括Wikipedia和BooksCorpus。</li><li>GPT预训练过程中，采用了语言模型的方法，即通过预测下一个词来学习语言模型，而BERT预训练过程中采用了双向预测的方法，即通过预测句子中丢失的词来学习语言模型。</li><li>GPT微调时，需要指定输入输出的语言模型任务，而BERT微调时，可以应用在多种任务上，例如文本分类、命名实体识别等。</li></ul><h3 id="GPT和BERT在使用场景上有明显的不同："><a href="#GPT和BERT在使用场景上有明显的不同：" class="headerlink" title="GPT和BERT在使用场景上有明显的不同："></a>GPT和BERT在使用场景上有明显的不同：</h3><ul><li>GPT主要用于自然语言生成任务，如文本自动补全、问答系统、文本翻译等。它可以根据给定的文本上下文生成有意义的文本，并且能够产生连贯的、人类水平的文本。</li><li>BERT则主要用于自然语言理解任务，如问题回答、文本分类、句子关系分析等。它可以理解文本中的语义和关系，并能够找出语句之间的联系。</li><li>GPT在文本生成场景中更常见，如聊天机器人，智能问答系统等。BERT在文本理解场景中更常见，如文本分类，问题回答等。</li><li>GPT对于文本生成更为敏感，而BERT对于文本理解更为敏感。</li><li>GPT在进行文本生成时需要较长的上下文，而BERT在进行文本理解时需要较短的上下文。</li><li>总的来说，GPT主要用于文本生成任务，而BERT则主要用于文本理解任务。</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>BERT模型虽然也是采用和GPT一样的Transformer模型结构，但它几乎就是为「无监督预训练+下游任务微调」的范式量身定制的模型。和GPT相比，BERT所使用的掩码语言模型任务（Masked Language Model）虽然让它失去了直接生成文本的能力，但换来的是双向编码的能力，这让模型拥有了更强的文本编码性能，直接的体现则是下游任务效果的大幅提升。而GPT为了保留生成文本的能力，只能采用单向编码。以当年的眼光来看，BERT绝对是一个更加优秀的模型。因为既然BERT和GPT两者都是采用「预训练+微调」的范式，并且下游任务依然是分类、匹配、序列标注等等「经典」的NLP任务形式，那么像BERT模型这种更注重特征编码的质量，下游任务选一个合适的损失函数去配合任务做微调，显然比GPT这种以文本生成的方式去「迂回地」完成这些任务更加直接。从BERT模型出来以后，「无监督训练+下游任务微调」的范式便奠定了它的霸主地位，各类沿着BERT的思路，琢磨「如何获得更好的文本特征编码」的方法大量涌现，以至于GPT这个以生成式任务为目标的模型显得像一个「异类」。马后炮地说，如果当时OpenAI「顺应大势」，放弃生成式预训练这条路，也许我们要等更长的时间才能见到ChatGPT这样的模型。</p><p>总的来说，BERT和GPT都是非常强大的语言模型，它们都是近年来NLP领域的重要突破。BERT是基于转移学习的思想开发的，主要用于解决语言理解相关的任务，如问答、语义关系抽取等。而GPT则是基于生成式预训练的思想开发的，主要用于解决语言生成相关的任务，如文本生成、<a href="https://link.zhihu.com/?target=https://cloud.tencent.com/product/tmt?from=10680">机器翻译</a>等。在使用场景上，BERT更适用于在已有标注数据上微调的场景，而GPT更适用于在大量未标注数据上预训练的场景。总之，BERT和GPT都是非常优秀的语言模型，在不同的任务和场景中都有很好的表现。</p><p>‍</p><p>转自：<a href="https://zhuanlan.zhihu.com/p/607605399">https://zhuanlan.zhihu.com/p/607605399</a></p>]]></content>
      
      
      <categories>
          
          <category> AI工程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大模型 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>墨菲定律&amp;康威定律</title>
      <link href="/article/%E5%A2%A8%E8%8F%B2%E5%AE%9A%E5%BE%8B&amp;%E5%BA%B7%E5%A8%81%E5%AE%9A%E5%BE%8B.html"/>
      <url>/article/%E5%A2%A8%E8%8F%B2%E5%AE%9A%E5%BE%8B&amp;%E5%BA%B7%E5%A8%81%E5%AE%9A%E5%BE%8B.html</url>
      
        <content type="html"><![CDATA[<p><strong>在设计系统时，应该多考虑 墨菲定律：</strong></p><ul><li>任何事物都没有表面看起来那么简单。</li><li>所有的事都会比你预计的时间长。</li><li>可能出错的事总会出错。</li><li>如果你担心某种情况发生，那么他就更有可能发生。</li></ul><p><strong>在划分系统时，应该多考虑 康威定律：</strong></p><ul><li>系统架构是公司组织架构的反映。</li><li>应该按照业务闭环进行系统拆分／组织架构划分，实现闭环／高内聚／低耦合，减少沟通成本。</li><li>如果沟通出现问题，那么应该考虑进行系统和组织架构的调整。</li><li>在合适时机进行系统拆分，不要一开始就把系统／服务拆的非常细，虽然闭环，但是每个人维护的系统多，维护成本高。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
          <category> 设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>研发工作方法论</title>
      <link href="/article/%E7%A0%94%E5%8F%91%E5%B7%A5%E4%BD%9C%E6%96%B9%E6%B3%95%E8%AE%BA.html"/>
      <url>/article/%E7%A0%94%E5%8F%91%E5%B7%A5%E4%BD%9C%E6%96%B9%E6%B3%95%E8%AE%BA.html</url>
      
        <content type="html"><![CDATA[<p>copy from: <a href="https://www.zybuluo.com/TryLoveCatch/note/1809593">https://www.zybuluo.com/TryLoveCatch/note/1809593</a></p><h2 id="研发工程师的基本功"><a href="#研发工程师的基本功" class="headerlink" title="研发工程师的基本功"></a>研发工程师的基本功</h2><ol><li>需求的交付能力；</li><li>系统的设计与架构能力；</li><li>行业对标与演化改进能力；</li></ol><p>想要系统化的提升基本功，首先要全面的对我们所接触到的技术要素做分解，站在全局进行思考。</p><h2 id="规划"><a href="#规划" class="headerlink" title="规划"></a>规划</h2><ul><li>为什么要做？<br>以客户为中心，从业务角度出发，业务最关心什么，我们不做会不会影响业务的核心指标</li><li>为什么现在做？<br>时间上 dead line</li><li>为什么是我们做？</li><li>怎么做<br>拆解</li></ul><p>一个规划应该主要分为：</p><ul><li>背景<br>业务理解，内部现状、业务影响、外部变化、背景总结</li><li>目标<br>根据背景要能推出来目标，也可分短期和长期目标，或者业务目标和技术目标，或者定性目标和定量目标</li><li>方案<br>方案是要解决背景中遇到的问题</li><li>指标<br>如果衡量结果的好坏呢</li><li>规划<br>具体的方案拆解，子任务拆解，具体到人和时间，每一个子任务应该是里程碑</li><li>风险以及应对<br>技术风险、资源风险、质量风险等或者业务维度（抓重点解决核心问题）、技术维度（难度）、组织维度（资源不足）、流程维度</li></ul><h2 id="技术要素拆分法（BeafQPS）"><a href="#技术要素拆分法（BeafQPS）" class="headerlink" title="技术要素拆分法（BeafQPS）"></a>技术要素拆分法（BeafQPS）</h2><h3 id="组成"><a href="#组成" class="headerlink" title="组成"></a>组成</h3><ol><li>行业对标 Benchmark</li><li>效率 Efficiency</li><li>架构 Architecture</li><li>功能 Feature</li><li>质量 Quality</li><li>性能 Performance</li><li>安全 Security</li></ol><span id="more"></span><h3 id="分解"><a href="#分解" class="headerlink" title="分解"></a>分解</h3><p><img src="/assets/20220831150438-bclw16n-image.png"></p><h3 id="联系"><a href="#联系" class="headerlink" title="联系"></a>联系</h3><p>设置技术维度指标上，发现各维度存在内在的关联关系：</p><ul><li>成功的交付 &#x3D; 行业对标是否充分 ？（（功能 + 质量 + 安全 + 性能）*（效率））^ 架构 ：0</li><li>行业对标：找国内甚至世界上最先进的公司进行对标，充分了解自身的优势和劣势，进行有效决策，否则盲目执行，无法有效评价我们工作的价值。</li><li>功能 + 质量 + 安全 + 性能 ：这个组合各维度缺一不可，否则将会出现：线上故障、安全漏洞、访问慢等伤害客户、伤害业务的问题</li><li>效率：特指研发效率，在业务和团队发展初期是非核心考虑的要素，可以粗放式发展。但是在业务和团队步入成熟期后，需要重点关注投入产出比，尤其是成本增速和业务增速的关系。</li><li>架构：好的架构是承载一切的基础，其优劣对以上 5 个维度是乘方的关系，有前瞻性的合理架构可以助力业务更快迭代、研发质量更好、系统更安全、性能更快、研发效率更高。</li></ul><h4 id="具体场景"><a href="#具体场景" class="headerlink" title="具体场景"></a>具体场景</h4><table><thead><tr><th>分类</th><th>场景</th><th>作用</th></tr></thead><tbody><tr><td>方案类</td><td>技术调研</td><td>1、多角度全面对标<br />2、统一优劣对比维度<br/>3、比对后标准可度量</td></tr><tr><td>方案类</td><td>技术方案设计</td><td>1、提供启发式的思维框架<br/>2、避免遗漏潜在的技术风险<br/>3、提供进阶式的参考标准</td></tr><tr><td>CheckList</td><td>发布前 CheckList</td><td>1、避免人为误操作导致线上问题<br/>2、前置依赖任务检查<br/>3、消除因经验不足造成的认知局限</td></tr><tr><td>复盘类</td><td>CaseStudy</td><td>1、清晰的表述发生了什么问题<br/>2、有效的分析原因和过程<br/>3、从技术角度来思考如何改进</td></tr></tbody></table><h3 id="研发交付标准"><a href="#研发交付标准" class="headerlink" title="研发交付标准"></a>研发交付标准</h3><p>了解到了如何拆解技术基础维度，就涉及落地执行的问题。落地必定有交付物。根据交付物的标准，我们制定出高、中、低三条基线。</p><p>总体思路是：坚守底线、控制中线、拔高上线。</p><ul><li>底线：守住基本交付要求（功能 + 质量 + 安全 + 性能 ），无硬伤、无疏漏；</li><li>中线：提质提效、从可用到好用、易用。架构设计上领先于业务发展。</li><li>上线：充分的行业对标，以全球领先的技术标准要求和实践。</li></ul><p><img src="/assets/20220831150635-wyqqe8z-image.png"></p><h3 id="WHWHORERE-工作法"><a href="#WHWHORERE-工作法" class="headerlink" title="WHWHORERE 工作法"></a>WHWHORERE 工作法</h3><ol><li>why：为什么做？现在有什么严重的问题亟待解决？</li><li>what：我们要解决的是什么问题？这件事情我们要做成什么样子？理想的情况是什么？要有理想，要高标准。</li><li>object: 要干到什么程度定什么样的目标？能定量的尽量定量，不能定量的先定性，逐步做到“<strong>定性 → 粗定量 → 细定量</strong>”。</li><li>roadmap：里程碑如何设置？做事的计划是什么？优先级是什么？</li><li>Evaluate：怎么评估做得好还是没做好？定义合理的指标比实现该指标更难。结果导向。</li><li>resource：需要多少资源？需要什么类型资源？人力资源，激励支持，权利支持等等有的话都提出来。</li></ol><p>WHWHORERE 对于研发线同学来说有些陌生，但是 2W1H 、PDCA 你一定听说过、甚至经常使用。</p><ul><li>2W1H 由：Why、What、How 三问结构构成，其中 Why 说明背景和目的、What 来提出方法和解决方案、How 部分解决怎么“干”的问题，Why、What 类比 WHWHORERE 中的 why、what 是相同的。</li><li>PDCA 由：Plan 计划、Do 实施、Check 检核、Action 改进计划， 四部分构成，用来保障“干”的效果。</li><li>对应到 WHWHORERE，Plan 可类比 object、Do 可类比 roadmap、Check 可类比 Evaluate 。 Action、resource 是各自方法论中独特的部分。</li></ul><p>通过类比两种大家比较熟悉的方法论，大家对 WHWHORERE 的理解会不会变得更容易些？</p><h3 id="工作价值判断二维表法"><a href="#工作价值判断二维表法" class="headerlink" title="工作价值判断二维表法"></a>工作价值判断二维表法</h3><p>结合 BeafQPS 和 WHWHORERE 的要求，我们在接到一个任务、项目、进行复盘、CaseStudy、Review 时，就可以拉出一个表格，运用正交分解的方式，从每一个技术维度和工作要点进行自问自答。</p><p>如果每一个问题，都能够有思考、有答案，才说明在这件事情上，我们把基本功做到位了。反之，则需要继续完善和补充。</p><h4 id="综合运用"><a href="#综合运用" class="headerlink" title="综合运用"></a>综合运用</h4><p><img src="/assets/20220831150708-5zpo4fx-image.png"></p><p>Tips：行业对标贯穿于工作的全周期，包括：前期的调研、优劣比对，中期的验证、找差距，后期的效果复盘和总结。</p><p>表格中，给到大家一些范例式的思考点和问题，我们需要结合具体的应用场景（可参考：下文第五部分），进行不同的思考与提问，来解决具体的问题。</p><p>二维表法的核心在于：纵向不重不漏的分析每一个技术维度，横向对于问题的思考能够逐级深入展开，横纵交叉后能够完整、可信和系统性给出结论。</p><h4 id="具体场景-1"><a href="#具体场景-1" class="headerlink" title="具体场景"></a>具体场景</h4><table><thead><tr><th>分类</th><th>场景</th><th>作用</th></tr></thead><tbody><tr><td>述职类</td><td>晋升述职</td><td>1、充分展现工作亮点<br/>2、拆解能力模型为具体可评估的技术维度<br/>3、结构化的组织汇报素材</td></tr><tr><td>复盘类</td><td>项目复盘</td><td>1、全面分析项目投入产出比<br/>2、回溯实施后的结果是否符合设计时的目标<br/>3、交付标准可横向对比</td></tr><tr><td>规划类</td><td>技术规划</td><td>1、清楚说明要解决问题的价值和评估手段<br/>2、不重不漏的覆盖潜在的技术风险；<br/>3、可分阶段落地的里程碑和资源评估；</td></tr><tr><td>其他</td><td>…</td><td></td></tr></tbody></table><h2 id="团队文化"><a href="#团队文化" class="headerlink" title="团队文化"></a>团队文化</h2><h3 id="第一原则"><a href="#第一原则" class="headerlink" title="第一原则"></a>第一原则</h3><p>Owner 意识：</p><p>认真负责是工作的底线。对交付结果负责，对自己负责的项目负责。</p><p>积极主动是“Owner 意识”更高一级的要求：对更多，更高，更大结果负责。</p><h3 id="第二原则"><a href="#第二原则" class="headerlink" title="第二原则"></a>第二原则</h3><p>时间观念：</p><p>工作有计划：计划越细致，交付越有保证。按时交付是可靠的保障。</p><p>事情分主次：按照四象限原则划分事情轻重缓急。</p><h3 id="第三原则"><a href="#第三原则" class="headerlink" title="第三原则"></a>第三原则</h3><p>以终为始：先确定目标，然后再行动。</p><p>既要埋头做事，又要抬头看天。</p><p>根据目标进行优化。</p><p>带着目标进行学习。</p><p>事情按照 PDAC(Plan Do Check Act)进行。</p><h3 id="第四原则"><a href="#第四原则" class="headerlink" title="第四原则"></a>第四原则</h3><p>闭环思维：</p><p>凡事有交代，件件有着落，事事有回音。（往往也可以用来回答靠谱的人具备什么特征）</p><p>即时反馈闭环：如果别人给我们分配了一个任务，不管完成的结果如何，一定要在规定的时间内给出明确的反馈。</p><p>沟通要有结论，通知要有反馈，To Do 要有验收。</p><p>定期主动进行阶段性的反馈。</p><h3 id="第五原则"><a href="#第五原则" class="headerlink" title="第五原则"></a>第五原则</h3><p>保持敬畏：</p><p>对组内规范，既定约定的敬畏。</p><p>让规范与约定与时俱进，也是另一种形式的敬畏。</p><p>对用户体验和线上服务的敬畏。</p><h3 id="第六原则"><a href="#第六原则" class="headerlink" title="第六原则"></a>第六原则</h3><p>事不过二：</p><p>所有评审和问题讨论，不超过 2 次。</p><p>同样问题不犯第二次。</p><h3 id="第七原则"><a href="#第七原则" class="headerlink" title="第七原则"></a>第七原则</h3><p>设计优先：</p><p>1.架构设计关于系统质量和团队效能。</p><ol><li>写别人看得懂的设计</li></ol><h3 id="第八原则"><a href="#第八原则" class="headerlink" title="第八原则"></a>第八原则</h3><p>P&#x2F;PC 平衡：产量、产能平衡。重视蛋也重视鹅。</p><p>业务产出和技术优化并重。</p><p>贡献和持续学习并重。</p><h3 id="第九原则"><a href="#第九原则" class="headerlink" title="第九原则"></a>第九原则</h3><p>善于提问：</p><p>勤于提问。</p><p>懂得如何提问。</p><p>批判性思维。</p><h3 id="第十原则"><a href="#第十原则" class="headerlink" title="第十原则"></a>第十原则</h3><p>空杯心态：</p><p>经常自我检视和反省。</p><p>多角度，批判看待自己</p>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 方法论 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>监控告警</title>
      <link href="/article/%E7%9B%91%E6%8E%A7%E5%91%8A%E8%AD%A6.html"/>
      <url>/article/%E7%9B%91%E6%8E%A7%E5%91%8A%E8%AD%A6.html</url>
      
        <content type="html"><![CDATA[<h1 id="1-监控"><a href="#1-监控" class="headerlink" title="1.监控"></a>1.监控</h1><h3 id="1-1-监控的目的"><a href="#1-1-监控的目的" class="headerlink" title="1.1 监控的目的"></a>1.1 监控的目的</h3><ul><li>了解业务量级增长</li><li>感知系统健康度</li><li>告警 -&gt; 及时发现问题</li></ul><p>可用性量化：  MTTF， MTTR，  SLA，  SLO</p><h3 id="1-2-好的监控体系应该做到哪些？"><a href="#1-2-好的监控体系应该做到哪些？" class="headerlink" title="1.2 好的监控体系应该做到哪些？"></a>1.2 好的监控体系应该做到哪些？</h3><ul><li>指标全面，但不冗余.</li><li>报警敏感，但不误报</li><li>自动发现问题，以及分析原因</li></ul><h3 id="1-3-监控指标"><a href="#1-3-监控指标" class="headerlink" title="1.3 监控指标"></a>1.3 监控指标</h3><p><strong>USE</strong>  (<strong>U</strong>tilization <strong>S</strong>aturation and <strong>E</strong>rrors）：  将注意力集中在处理工作负载的资源上。目标是了解这些资源在存在负载时的行为方式。</p><ul><li>使用率，表示资源用于服务的时间或容量百分比。100% 的使用率，表示容量已经用尽或者全部时间都用于服务。</li><li>饱和度，表示资源的繁忙程度，通常与等待队列的长度相关。100% 的饱和度，表示资源无法接受更多的请求。</li><li>错误数表示发生错误的事件个数。错误数越多，表明系统的问题越严重。</li></ul><p><strong>RED</strong>（<strong>R</strong>equest Throughput，<strong>E</strong>rror Rate, <strong>D</strong>uration Time）:    它是由资源提供服务的工作负载行为的外部可见视图</p><p><strong>四个黄金信号</strong>:  延迟（Latency），流量（Traffic），错误（Errors）和 饱和度（Saturation）</p><span id="more"></span><h3 id="1-4-监控体系"><a href="#1-4-监控体系" class="headerlink" title="1.4 监控体系"></a>1.4 监控体系</h3><p><img src="/assets/20220820164352-cyse3y3-image.png"></p><p>需要关注的点非常多（机器指标、数据库监控、接口性能、业务指标、异常日志等等），越想越多，越理越乱。   所以需要<strong>分层监控</strong>。</p><h1 id="2-告警"><a href="#2-告警" class="headerlink" title="2.告警"></a>2.告警</h1><p>目标:  避免误报、 漏报</p><h3 id="2-1-报警级别规范"><a href="#2-1-报警级别规范" class="headerlink" title="2.1 报警级别规范"></a>2.1 报警级别规范</h3><p>每一条告警都有自己的级别，大部分公司对告警分级都有设定，例如某司对告警的级别设定为： P0、P1、P2、P3。不同的告警级别代表通知范围不同、处理紧急度不同。</p><table><thead><tr><th>告警级别</th><th>告警含义</th><th>通知速度</th><th>响应速度</th><th>误报概率</th></tr></thead><tbody><tr><td>P0</td><td>大事故的发生，需马上处理</td><td>电话 + 短信 + ** + 邮件</td><td>第一时间做出响应并处理，响应时间 &lt;&#x3D;10 分钟</td><td>0 误报，告警意味着严重的事故 100% 发生</td></tr><tr><td>P1</td><td>核心路径有波动，需马上处理</td><td>短信 + **</td><td>收到报警之后立即响应，响应时间 &lt;&#x3D;30 分钟</td><td>0 误报，告警意味着核心接口服务不稳定，有事故或有抖动</td></tr><tr><td>P2</td><td>服务有波动，需关注</td><td>**</td><td>观察系统指标，快速处理，响应时间 &lt;&#x3D;1 小时</td><td>允许少量误报</td></tr><tr><td>P3</td><td>服务异常信息通知</td><td>**</td><td>尽快处理</td><td>允许少量误报</td></tr></tbody></table><p>对于不同级别的告警一般是这么进行区分：</p><ol><li>不同阈值相同持续时间。 比如一分钟内 500 次异常定为 P1、1000 次异常定为 P0</li><li>相同阈值不同持续时间。 比如 P2 报警持续 5 分钟升级为 P1、P1 报警持续 5 分钟升级为 P0</li></ol><h3 id="2-2-告警治理"><a href="#2-2-告警治理" class="headerlink" title="2.2 告警治理"></a>2.2 告警治理</h3><p>保证告警精准触达用户，通过技术手段、数据运营，减少冗余告警，提升告警有效性。</p><h3 id="2-3-最佳实践"><a href="#2-3-最佳实践" class="headerlink" title="2.3 最佳实践"></a>2.3 最佳实践</h3><ol><li>配置有效的告警，需要分析指标特征来对症下药，避免一刀切，千篇一律。</li><li>突增突降类指标的监控，需要先定义出“什么是异常？”，再针对异常进行监控，避免直接对原始的、不稳定的指标进行监控告警。</li><li>告警分优先级配置时，针对不同优先级侧重点不同，高优告警侧重于准确且及时，低优告警可接受一定的延迟，换取更低的误告警。</li><li><strong>告警分时段配置时，不同时段侧重点不同。低频时段阈值宽松处理（避免大量误告警）、高频时段调小检测窗口严格处理（强调灵敏性）。</strong></li><li><strong>对于普适性的指标（Host、中间件等）告警配置，尽可能使用模板进行批量配置</strong>，以减少工作量，提升配置可维护性</li><li>对于不稳定的指标需进行归一化处理，转换为稳定指标（错误量 → 错误率），提升告警配置的有效性。</li><li>对于告警配置项，尽可能使用相对类配置（如波动百分比、基于基线的百分比等等），避免直接以某个固定值为基础进行比较配置。</li><li><strong>监控做加法，告警做减法</strong>：监控开发是可以对系统从下而上，全面的进行监控，因为业务、系统是不断变化的，先期全面的监控能减少后续查漏补缺时的开发工作，并且更加全面丰富的监控指标有助于定位线上故障。但是在配置告警策略时，则应该提取当前关键核心的监控指标，来配置告警策略，减少无效告警数量。</li></ol><p>难点： 接口差异，很难通用</p>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 监控 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2021年回顾与感想</title>
      <link href="/article/2021%E6%80%BB%E7%BB%93.html"/>
      <url>/article/2021%E6%80%BB%E7%BB%93.html</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>翻开2020的总结，突然发现，这一年与之前计划变化较大，中途未能及时的根据规划进行调整。时间过得很快，一晃就是一年，很多直接目标，现在看来完成的都不尽人意。中途还有一些重大的变化，如去了另外一个事业部，做着和之前很不同的工作，回到了成都工作等。总结还是需要经常得回顾，不然就会忘却之前的计划。</p><h2 id="一、-2021年总结"><a href="#一、-2021年总结" class="headerlink" title="一、 2021年总结"></a><strong>一、 2021年总结</strong></h2><p>请重点回顾在本人在周期内的关键策略进展、重要进展、目标达成等。</p><h3 id="1、个人目标"><a href="#1、个人目标" class="headerlink" title="1、个人目标"></a><strong>1、个人目标</strong></h3><p>上阶段有什么个人目标</p><table><thead><tr><th><strong>阶段性目标</strong></th><th><strong>路径</strong></th></tr></thead><tbody><tr><td>工作能力的提升</td><td>1，根据公司的能力模型，制定各个能力的细致目标<br />2，根据模型，总结自己哪些已经达到，哪些还是短板</td></tr><tr><td>投资能力的提升</td><td>1，制定投资知识脑图，细化各阶段目标</td></tr><tr><td>开阔自己的思维</td><td>1，与不同行业优秀的人沟通<br /></td></tr><tr><td>总结输出</td><td>1，多总结输出文章，发表在博客上</td></tr></tbody></table><h3 id="2、目标完成情况及工作成果"><a href="#2、目标完成情况及工作成果" class="headerlink" title="2、目标完成情况及工作成果"></a><strong>2、目标完成情况及工作成果</strong></h3><p>上阶段目标完成情况，取得了什么亮点&#x2F;成果（如有对标情况，请列举），有什么认知迭代</p><table><thead><tr><th><strong>方向</strong></th><th><strong>目标</strong></th><th><strong>关键步骤</strong></th><th><strong>成果</strong></th></tr></thead><tbody><tr><td>工作能力的提升</td><td>1，根据公司的能力模型，制定各个能力的细致目标<br />2，根据模型，总结自己哪些已经达到，哪些还是短板</td><td>1，拆解能力模型，定各个方面目标<br /></td><td>未去根据能力模型去拆解<br /><br />技术方面深入的学习了RPC原理，ES原理，还有库存系统和秒杀系统的设计。</td></tr><tr><td>投资能力的提升</td><td>1，制定投资知识脑图，细化各阶段目标</td><td>1，提升投资性知识</td><td>在极客时间上学习了《程序员的个人财富课程》，比较完整性以及成熟性的看待财富</td></tr><tr><td>开阔自己的思维</td><td>1，与不同行业优秀的人沟通<br /></td><td>1，多走出去，接触优秀的人</td><td>没有走出去，疫情，加上今年工作和生活的变化。</td></tr><tr><td>总结输出</td><td>1，多总结输出文章，发表在博客上</td><td>需要自己多think，提炼</td><td>无自己think输出，只做了技术上的博客输出。</td></tr></tbody></table><p><strong>认知迭代</strong></p><p>工作上：换了一个事业部，工作从头开始，不能直接将原来团队的模式作用在这边，特别在对团队文化，节奏还未完全摸清，外加领导不怎么管事的情况下。如何处理好团队关系和领导关系，是接下来需要去摸索和学习的。</p><p>投资上：摒弃了频繁交易，做长期主义者，重点关注未来大趋势的行业。另外从这两个月就亏掉之前的盈利来看，长期主义要忍受回调带来的痛楚，另外也要关注估值，高估值一定会回调，但又担心错失后面的涨，如何把握这节奏，是后面需要去提炼的。</p><p>晋升答辩：今年参加了下美团的晋升答辩，最终结果不甚满意，其中暴露了自身很多问题，首先PPT思路，另外讲也没讲好，在内容上，未能做好调研和对标，工作细节不突出。</p><span id="more"></span><h3 id="3、总结分析"><a href="#3、总结分析" class="headerlink" title="3、总结分析"></a><strong>3、总结分析</strong></h3><p><strong>哪些做得好，哪些还可以再提升，哪些该做却没有推动以及原因分析，影响自己更进一步的障碍是什么</strong></p><p><strong>做的好的</strong></p><p>逼迫自己将学习的书籍或博客做个脑图或者博客，加强知识的吸收。</p><p>投资交易次数很少，投资耐心度在提升，机会很少，需要等待。</p><p>完成了回成都工作的阶段。</p><p><strong>该做却没做的</strong></p><p>能力模型未能细化，未能去锻炼提升自己弱的点。</p><p>鉴定了自己价值投资为主，以未来行业大趋势为主线的基调，但其中对于高估值，市场情绪等短期波动未进行针对性的投资管理，造成当前投资过山车。</p><p><strong>影响更进一步的障碍</strong></p><p>思考时间变少，太多时间浪费在b站和游戏去了。努力的动力不足，容易懈怠。</p><h2 id="三、-2022-年规划"><a href="#三、-2022-年规划" class="headerlink" title="三、 2022 年规划"></a><strong>三、 2022 年规划</strong></h2><p><strong>1. 策略</strong>: 抓住细节，坚持就是胜利</p><p>人的精力是有限的，需要更好的分配自身的精力，希望自己是70%时间在工作上（60%的时间上班，10%的时间在技术&#x2F;项目管理上学习），15%的时间学习财务投资类知识，剩下15%用来与亲人、朋友聊天娱乐+思考。</p><p><strong>2. 规划</strong>：明确阶段性目标，并阐述达成目标的路径和方法</p><table><thead><tr><th><strong>阶段性目标</strong></th><th><strong>路径</strong></th><th>目标期望</th></tr></thead><tbody><tr><td>工作能力的提升</td><td>1，提升自己写作基本功、表达、与人关系的能力<br />2，完善自身技术体系</td><td>完成一次“晋升”PPT，并进行自我演讲。</td></tr><tr><td>投资能力的提升</td><td>1，细化投资中的各项因素指标，根据指标构建投资策略</td><td>制定半年前的投资策略</td></tr><tr><td>开阔自己的思维</td><td>1，与不同行业优秀的人沟通</td><td>能够结实半导体行业，新能源，医生行业，教育行业的人</td></tr><tr><td>总结输出</td><td>多总结输出文章，发表在博客上</td><td>输出12篇博客</td></tr></tbody></table><p>投资长远看趋势，短期看指标。</p><h2 id="四、-个人成长"><a href="#四、-个人成长" class="headerlink" title="四、 个人成长"></a><strong>四、 个人成长</strong></h2><p>希望可以全面回顾你的个人成长，可以参考（定战略&#x2F;策略、拿结果、炼心志）以及<strong>个人管理</strong>（时间分配、个人成长等）这两个视角进行回顾。希望能够既包括<strong>成长（亮点），也包括反思（暗点）</strong>，<strong>阶段性的回顾和反思是为了更好的成长和进步。</strong></p><p><strong>1.     收获与成长</strong></p><p>投资上开始进行长期主义，关注业绩指标，屏蔽短期波动。</p><p>工作上对流程，管控更加看重，注重风险意识，不逞能。答应了未能完成远比自己提前说不能完成所带来的结果更严重，而且如果领导是个不太关注具体事务的人，就算加班加点完成，对自己也没有任何好处。</p><p><strong>2.     反思和不足</strong></p><p>执行力不足，对制定的计划，常常因为平时工作时长，累为由而未能坚持，需要逐渐去克服。</p><p>对于大且周期长的项目，中途项目管理可能会松懈，特别是没有人催的情况下。还是需要严格要求自己，项目管理，风险控制是职业化的表现。不要有侥幸心理，时刻提醒以高标准要求自己。</p><h2 id="五、-未来展望"><a href="#五、-未来展望" class="headerlink" title="五、 未来展望"></a><strong>五、 未来展望</strong></h2><p>这一年底，回到了家乡工作。二线城市相对于一线，岗位较少，上升空间更难，需要去适应这种变化，更提高自己的价值，才能让自己处于不怕之地。除此之外，多积累人脉，回来这段时间，发现在家这边人脉重要度大于在一线的时候。</p>]]></content>
      
      
      <categories>
          
          <category> 成长 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 总结 </tag>
            
            <tag> 规划 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>秒杀系统设计三</title>
      <link href="/article/%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E4%B8%89.html"/>
      <url>/article/%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E4%B8%89.html</url>
      
        <content type="html"><![CDATA[<p>前面两章，讲解了秒杀系统在性能上面的优化，以及如何处理瞬时流量巨大下系统的稳定性，但对于秒杀系统，还有一个核心问题：如何保障在秒杀时，不出现库存超卖的情况。</p><p>另外秒杀系统针对流量巨大的考验，我们也需要如果系统扛不住了，如何最低损失的去保障服务的可用，对于服务的高可用，需要考虑到系统建设的各个阶段。</p><h1 id="库存设计"><a href="#库存设计" class="headerlink" title="库存设计"></a>库存设计</h1><h2 id="减库存有哪几种方式"><a href="#减库存有哪几种方式" class="headerlink" title="减库存有哪几种方式"></a>减库存有哪几种方式</h2><p>在正常的电商平台购物场景中，用户的实际购买过程一般分为两步：下单和付款。你想买一个商品，在商品页面点了“立即购买”按钮，核对信息之后点击“提交订单”，这一步称为下单操作。下单之后，你只有真正完成付款操作才能算真正购买。</p><p>那么你会在哪个环节完成减库存的操作呢？总结来说，减库存操作一般有如下几个方式：</p><ul><li><strong>下单减库存</strong>，即当买家下单后，在商品的总库存中减去买家购买数量。下单减库存是最简单的减库存方式，也是控制最精确的一种，下单时直接通过数据库的事务机制控制商品库存，这样一定不会出现超卖的情况。但是你要知道，有些人下完单可能并不会付款。</li><li><strong>付款减库存</strong>，即买家下单后，并不立即减库存，而是等到有用户付款后才真正减库存，否则库存一直保留给其他买家。但因为付款时才减库存，如果并发比较高，有可能出现买家下单后付不了款的情况，因为可能商品已经被其他人买走了。</li><li><strong>预扣库存</strong>，这种方式相对复杂一些，买家下单后，库存为其保留一定的时间（如 10 分钟），超过这个时间，库存将会自动释放，释放后其他买家就可以继续购买。在买家付款前，系统会校验该订单的库存是否还有保留：如果没有保留，则再次尝试预扣；如果库存不足（也就是预扣失败）则不允许继续付款；如果预扣成功，则完成付款并实际地减去库存。</li></ul><p>以上这几种减库存的方式都会存在一些问题，下面我们一起来看下。</p><h2 id="减库存可能存在的问题"><a href="#减库存可能存在的问题" class="headerlink" title="减库存可能存在的问题"></a>减库存可能存在的问题</h2><p>由于购物过程中存在两步或者多步的操作，因此在不同的操作步骤中减库存，就会存在一些可能被恶意买家利用的漏洞，例如发生恶意下单的情况。</p><p>假如我们采用“下单减库存”的方式，即用户下单后就减去库存，正常情况下，买家下单后付款的概率会很高，所以不会有太大问题。但是有一种场景例外，就是当卖家参加某个活动时，此时活动的有效时间是商品的黄金售卖时间，如果有竞争对手通过恶意下单的方式将该卖家的商品全部下单，让这款商品的库存减为零，那么这款商品就不能正常售卖了。要知道，这些恶意下单的人是不会真正付款的，这正是“下单减库存”方式的不足之处。</p><span id="more"></span><p>既然“下单减库存”可能导致恶意下单，从而影响卖家的商品销售，那么有没有办法解决呢？你可能会想，采用“付款减库存”的方式是不是就可以了？的确可以。但是，“付款减库存”又会导致另外一个问题：库存超卖。</p><p>假如有 100 件商品，就可能出现 300 人下单成功的情况，因为下单时不会减库存，所以也就可能出现下单成功数远远超过真正库存数的情况，这尤其会发生在做活动的热门商品上。就会导致很多买家下单成功但是付不了款，<strong>买家的购物体验自然比较差</strong>。</p><p>可以看到，不管是“下单减库存”还是“付款减库存”，都会导致商品库存不能完全和实际售卖情况对应起来的情况，看来要把商品准确地卖出去还真是不容易啊！</p><p>那么，既然“下单减库存”和“付款减库存”都有缺点，我们能否把两者相结合，将两次操作进行前后关联起来，下单时先预扣，在规定时间内不付款再释放库存，即采用“预扣库存”这种方式呢？</p><p>这种方案确实可以在一定程度上缓解上面的问题。但是否就彻底解决了呢？其实没有！针对恶意下单这种情况，虽然把有效的付款时间设置为 10 分钟，但是恶意买家完全可以在 10 分钟后再次下单，或者采用一次下单很多件的方式把库存减完。针对这种情况，解决办法还是要结合安全和反作弊的措施来制止。</p><p>针对“库存超卖”这种情况，在 10 分钟时间内下单的数量仍然有可能超过库存数量，遇到这种情况我们只能区别对待：对普通的商品下单数量超过库存数量的情况，可以通过补货来解决；但是有些卖家完全不允许库存为负数的情况，那只能在买家付款时提示库存不足。</p><h2 id="大型秒杀中如何减库存？"><a href="#大型秒杀中如何减库存？" class="headerlink" title="大型秒杀中如何减库存？"></a>大型秒杀中如何减库存？</h2><p>目前来看，业务系统中最常见的就是预扣库存方案，像你在买机票、买电影票时，下单后一般都有个“有效付款时间”，超过这个时间订单自动释放，这都是典型的预扣库存方案。而具体到秒杀这个场景，应该采用哪种方案比较好呢？</p><p>由于参加秒杀的商品，一般都是“抢到就是赚到”，所以成功下单后却不付款的情况比较少，再加上卖家对秒杀商品的库存有严格限制，所以秒杀商品采用“下单减库存”更加合理。另外，理论上由于“下单减库存”比“预扣库存”以及涉及第三方支付的“付款减库存”在逻辑上更为简单，所以性能上更占优势。</p><p>“下单减库存”在数据一致性上，主要就是保证大并发请求时库存数据不能为负数，也就是要保证数据库中的库存字段值不能为负数，一般我们有多种解决方案：一种是在应用程序中通过事务来判断，即保证减后库存不能为负数，否则就回滚；另一种办法是直接设置数据库的字段数据为无符号整数，这样减后库存字段值小于零时会直接执行 SQL 语句来报错；再有一种就是使用 CASE WHEN 判断语句，例如这样的 SQL 语句：</p><p><code>UPDATE item SET inventory = CASE WHEN inventory &gt;= xxx THEN inventory-xxx ELSE inventory END</code></p><h2 id="秒杀减库存的极致优化"><a href="#秒杀减库存的极致优化" class="headerlink" title="秒杀减库存的极致优化"></a>秒杀减库存的极致优化</h2><p>在交易环节中，“库存”是个关键数据，也是个热点数据，因为交易的各个环节中都可能涉及对库存的查询。但是，我在前面介绍分层过滤时提到过，秒杀中并不需要对库存有精确的一致性读，把库存数据放到缓存（Cache）中，可以大大提升读性能。</p><p>解决大并发读问题，可以采用 LocalCache（即在秒杀系统的单机上缓存商品相关的数据）和对数据进行分层过滤的方式，但是像减库存这种大并发写无论如何还是避免不了，这也是秒杀场景下最为核心的一个技术难题。</p><p><strong>因此，这里我想专门来说一下秒杀场景下减库存的极致优化思路，包括如何在缓存中减库存以及如何在数据库中减库存</strong>。</p><p>秒杀商品和普通商品的减库存还是有些差异的，例如商品数量比较少，交易时间段也比较短，因此这里有一个大胆的假设，即能否把秒杀商品减库存直接放到缓存系统中实现，也就是直接在缓存中减库存或者在一个带有持久化功能的缓存系统（如 Redis）中完成呢？</p><p>如果你的秒杀商品的减库存逻辑非常单一，比如没有复杂的 SKU 库存和总库存这种联动关系的话，我觉得完全可以。但是如果有比较复杂的减库存逻辑，或者需要使用事务，你还是必须在数据库中完成减库存。</p><p>由于 MySQL 存储数据的特点，同一数据在数据库里肯定是一行存储（MySQL），因此会有大量线程来竞争 InnoDB 行锁，而并发度越高时等待线程会越多，TPS（Transaction Per Second，即每秒处理的消息数）会下降，响应时间（RT）会上升，数据库的吞吐量就会严重受影响。</p><p>这就可能引发一个问题，就是单个热点商品会影响整个数据库的性能， 导致 0.01% 的商品影响 99.99% 的商品的售卖，这是我们不愿意看到的情况。一个解决思路是遵循前面介绍的原则进行隔离，把热点商品放到单独的热点库中。但是这无疑会带来维护上的麻烦，比如要做热点数据的动态迁移以及单独的数据库等。</p><p>而分离热点商品到单独的数据库还是没有解决并发锁的问题，我们应该怎么办呢？要解决并发锁的问题，有两种办法：</p><ul><li><strong>应用层做排队</strong>。按照商品维度设置队列顺序执行，这样能减少同一台机器对数据库同一行记录进行操作的并发度，同时也能控制单个商品占用数据库连接的数量，防止热点商品占用太多的数据库连接。</li><li><strong>数据库层做排队</strong>。应用层只能做到单机的排队，但是应用机器数本身很多，这种排队方式控制并发的能力仍然有限，所以如果能在数据库层做全局排队是最理想的。</li></ul><p>另外，数据更新问题除了前面介绍的热点隔离和排队处理之外，还有些场景（如对商品的 lastmodifytime 字段的）更新会非常频繁，在某些场景下这些多条 SQL 是可以合并的，一定时间内只要执行最后一条 SQL 就行了，以便减少对数据库的更新操作。</p><h1 id="服务高可用"><a href="#服务高可用" class="headerlink" title="服务高可用"></a>服务高可用</h1><p>说到系统的高可用建设，它其实是一个系统工程，需要考虑到系统建设的各个阶段，也就是说它其实贯穿了系统建设的整个生命周期，如下图所示：</p><p><img src="/assets/20211201220823-nfauawx.jpe"></p><p>高可用系统建设具体来说，系统的高可用建设涉及架构阶段、编码阶段、测试阶段、发布阶段、运行阶段，以及故障发生时。接下来，我们分别看一下。</p><ol><li><strong>架构阶段</strong>：架构阶段主要考虑系统的可扩展性和容错性，要避免系统出现单点问题。例如多机房单元化部署，即使某个城市的某个机房出现整体故障，仍然不会影响整体网站的运转。</li><li><strong>编码阶段</strong>：编码最重要的是保证代码的健壮性，例如涉及远程调用问题时，要设置合理的超时退出机制，防止被其他系统拖垮，也要对调用的返回结果集有预期，防止返回的结果超出程序处理范围，最常见的做法就是对错误异常进行捕获，对无法预料的错误要有默认处理结果。</li><li><strong>测试阶段</strong>：测试主要是保证测试用例的覆盖度，保证最坏情况发生时，我们也有相应的处理流程。</li><li><strong>发布阶段</strong>：发布时也有一些地方需要注意，因为发布时最容易出现错误，因此要有紧急的回滚机制。</li><li><strong>运行阶段</strong>：运行时是系统的常态，系统大部分时间都会处于运行态，运行态最重要的是对系统的监控要准确及时，发现问题能够准确报警并且报警数据要准确详细，以便于排查问题。</li><li><strong>故障发生</strong>：故障发生时首先最重要的就是及时止损，例如由于程序问题导致商品价格错误，那就要及时下架商品或者关闭购买链接，防止造成重大资产损失。然后就是要能够及时恢复服务，并定位原因解决问题。</li></ol><p>为什么系统的高可用建设要放到整个生命周期中全面考虑？因为我们在每个环节中都可能犯错，而有些环节犯的错，你在后面是无法弥补的。例如在架构阶段，你没有消除单点问题，那么系统上线后，遇到突发流量把单点给挂了，你就只能干瞪眼，有时候想加机器都加不进去。所以高可用建设是一个系统工程，必须在每个环节都做好。</p><p>针对秒杀系统，也可以通过降级、限流和拒绝服务来保护我们的系统。针对降级、限流等知识，可以查看我之前<a href="PRC%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86%E5%9B%9B.html">PRC 核心原理四</a>文章中的讲解。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本文讲了在秒杀系统下对于减库存的方案抉择，从中我们可以看出，在系统架构方案选择时，业务需求也是很重要的，不同的业务对侧重点不同，就会选择不同的方案。但对于减库存的技术细节，本文没做太多讲解，后面打算对库存系统这个技术点，再写篇如何保证库存不出现超卖的情况以及如何保证减库存的准确性。</p><p>而服务可用性不仅对秒杀服务适用，各个服务都可以通过上面讲解的不同阶段去做，来提升系统的可用性。</p>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
          <category> 架构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 架构设计 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>秒杀系统设计二</title>
      <link href="/article/%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E4%BA%8C.html"/>
      <url>/article/%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E4%BA%8C.html</url>
      
        <content type="html"><![CDATA[<p>上一篇介绍了秒杀系统整体架构可以概括为“稳、准、快”几个关键字，其中讲解了通过动静分离来实现高性能。这一篇会讲解秒杀系统相对于其他系统很不同的特点，就是“热点”问题和瞬时请求量巨大问题。</p><h1 id="热点问题"><a href="#热点问题" class="headerlink" title="热点问题"></a>热点问题</h1><h2 id="热点带来的影响"><a href="#热点带来的影响" class="headerlink" title="热点带来的影响"></a>热点带来的影响</h2><p>首先，热点请求会大量占用服务器处理资源，虽然这个热点可能只占请求总量的亿分之一，然而却可能抢占 90% 的服务器资源，如果这个热点请求还是没有价值的无效请求，那么对系统资源来说完全是浪费。</p><p>其次，即使这些热点是有效的请求，我们也要识别出来做针对性的优化，从而用更低的代价来支撑这些热点请求。</p><h2 id="“热点”包含哪些"><a href="#“热点”包含哪些" class="headerlink" title="“热点”包含哪些"></a>“热点”包含哪些</h2><p>热点分为<strong>热点操作</strong>和<strong>热点数据</strong>。所谓“热点操作”，例如大量的刷新页面、大量的添加购物车、双十一零点大量的下单等都属于此类操作。对系统来说，这些操作可以抽象为“读请求”和“写请求”，这两种热点请求的处理方式大相径庭，读请求的优化空间要大一些，而写请求的瓶颈一般都在存储层，优化的思路需要根据 CAP 理论做平衡。</p><p>而“热点数据”比较好理解，那就是用户的热点请求对应的数据。而热点数据又分为“静态热点数据”和“动态热点数据”。</p><p>所谓“静态热点数据”，就是能够提前预测的热点数据。例如，我们可以通过卖家报名的方式提前筛选出来，通过报名系统对这些热点商品进行打标。另外，我们还可以通过大数据分析来提前发现热点商品，比如我们分析历史成交记录、用户的购物车记录，来发现哪些商品可能更热门、更好卖，这些都是可以提前分析出来的热点。</p><p>所谓“动态热点数据”，就是不能被提前预测到的，系统在运行过程中临时产生的热点。例如，卖家在抖音上做了广告，然后商品一下就火了，导致它在短时间内被大量购买。</p><p>由于热点操作是用户的行为，我们不好改变，但能做一些限制和保护，所以本文我主要针对热点数据来介绍如何进行优化。</p><span id="more"></span><h2 id="发现热点数据"><a href="#发现热点数据" class="headerlink" title="发现热点数据"></a>发现热点数据</h2><p>我们从发现静态热点和发现动态热点两个方面来看一下。</p><h3 id="发现静态热点数据"><a href="#发现静态热点数据" class="headerlink" title="发现静态热点数据"></a>发现静态热点数据</h3><p>如前面讲的，静态热点数据可以通过商业手段，例如强制让卖家通过报名参加的方式提前把热点商品筛选出来，实现方式是通过一个运营系统，把参加活动的商品数据进行打标，然后通过一个后台系统对这些热点商品进行预处理，如提前进行缓存。但是这种通过报名提前筛选的方式也会带来新的问题，即增加卖家的使用成本，而且实时性较差，也不太灵活。</p><p>不过，除了提前报名筛选这种方式，你还可以通过技术手段提前预测，例如对买家每天访问的商品进行大数据计算，然后统计出 TOP N 的商品，我们可以认为这些 TOP N 的商品就是热点商品。</p><h3 id="发现动态热点数据"><a href="#发现动态热点数据" class="headerlink" title="发现动态热点数据"></a>发现动态热点数据</h3><p>我们可以通过卖家报名或者大数据预测这些手段来提前预测静态热点数据，但这其中有一个痛点，就是实时性较差，如果我们的系统能在秒级内自动发现热点商品那就完美了。</p><p>能够动态地实时发现热点不仅对秒杀商品，对其他热卖商品也同样有价值，所以我们需要想办法实现热点的动态发现功能。</p><p>这里我给出一个动态热点发现系统的具体实现。</p><ol><li>构建一个异步的系统，它可以收集交易链路上各个环节中的中间件产品的热点 Key，如 Nginx、缓存、RPC 服务框架等这些中间件（一些中间件产品本身已经有热点统计模块）。</li><li>建立一个热点上报和可以按照需求订阅的热点服务的下发规范，主要目的是通过交易链路上各个系统（包括详情、购物车、交易、优惠、库存、物流等）访问的时间差，把上游已经发现的热点透传给下游系统，提前做好保护。比如，对于大促高峰期，详情系统是最早知道的，在统一接入层上 Nginx 模块统计的热点 URL。</li><li>将上游系统收集的热点数据发送到热点服务台，然后下游系统（如交易系统）就会知道哪些商品会被频繁调用，然后做热点保护。</li></ol><p>这里我给出了一个图，其中用户访问商品时经过的路径有很多，我们主要是依赖前面的导购页面（包括首页、搜索页面、商品详情、购物车等）提前识别哪些商品的访问量高，通过这些系统中的中间件来收集热点数据，并记录到日志中。</p><p><img src="/assets/20211205162052-oy77sxp.jpe"></p><p>一个动态热点发现系统我们通过部署在每台机器上的 Agent 把日志汇总到聚合和分析集群中，然后把符合一定规则的热点数据，通过订阅分发系统再推送到相应的系统中。你可以是把热点数据填充到 Cache 中，或者直接推送到应用服务器的内存中，还可以对这些数据进行拦截，总之下游系统可以订阅这些数据，然后根据自己的需求决定如何处理这些数据。</p><p>打造热点发现系统时，我根据以往经验总结了几点注意事项。</p><ol><li>这个热点服务后台抓取热点数据日志最好采用异步方式，因为“异步”一方面便于保证通用性，另一方面又不影响业务系统和中间件产品的主流程。</li><li>热点服务发现和中间件自身的热点保护模块并存，每个中间件和应用还需要保护自己。热点服务台提供热点数据的收集和订阅服务，便于把各个系统的热点数据透明出来。</li><li>热点发现要做到接近实时（3s 内完成热点数据的发现），因为只有做到接近实时，动态发现才有意义，才能实时地对下游系统提供保护。</li></ol><h2 id="处理热点数据"><a href="#处理热点数据" class="headerlink" title="处理热点数据"></a>处理热点数据</h2><p><strong>处理热点数据通常有几种思路：一是优化，二是限制，三是隔离</strong>。</p><p>先来说说优化。优化热点数据最有效的办法就是缓存热点数据，如果热点数据做了动静分离，那么可以长期缓存静态数据。但是，缓存热点数据更多的是“临时”缓存，即不管是静态数据还是动态数据，都用一个队列短暂地缓存数秒钟，由于队列长度有限，可以采用 LRU 淘汰算法替换。</p><p>再来说说限制。限制更多的是一种保护机制，限制的办法也有很多，例如对被访问商品的 ID 做一致性 Hash，然后根据 Hash 做分桶，每个分桶设置一个处理队列，这样可以把热点商品限制在一个请求队列里，防止因某些热点商品占用太多的服务器资源，而使其他请求始终得不到服务器的处理资源。</p><p>最后介绍一下隔离。秒杀系统设计的第一个原则就是将这种热点数据隔离出来，不要让 1% 的请求影响到另外的 99%，隔离出来后也更方便对这 1% 的请求做针对性的优化。</p><p>具体到“秒杀”业务，我们可以在以下几个层次实现隔离。</p><ol><li><strong>业务隔离</strong>。把秒杀做成一种营销活动，卖家要参加秒杀这种营销活动需要单独报名，从技术上来说，卖家报名后对我们来说就有了已知热点，因此可以提前做好预热。</li><li><strong>系统隔离</strong>。系统隔离更多的是运行时的隔离，可以通过分组部署的方式和另外 99% 分开。秒杀可以申请单独的域名，目的也是让请求落到不同的集群中。</li><li><strong>数据隔离</strong>。秒杀所调用的数据大部分都是热点数据，比如会启用单独的 Cache 集群或者 MySQL 数据库来放热点数据，目的也是不想 0.01% 的数据有机会影响 99.99% 数据。</li></ol><p>当然了，实现隔离有很多种办法。比如，你可以按照用户来区分，给不同的用户分配不同的 Cookie，在接入层，路由到不同的服务接口中；再比如，你还可以在接入层针对 URL 中的不同 Path 来设置限流策略。服务层调用不同的服务接口，以及数据层通过给数据打标来区分等等这些措施，其目的都是把已经识别出来的热点请求和普通的请求区分开。</p><h1 id="瞬时请求量巨大问题"><a href="#瞬时请求量巨大问题" class="headerlink" title="瞬时请求量巨大问题"></a>瞬时请求量巨大问题</h1><p>如果你看过秒杀系统的流量监控图的话，你会发现它是一条直线，就在秒杀开始那一秒是一条很直很直的线，这是因为秒杀请求在时间上高度集中于某一特定的时间点。这样一来，就会导致一个特别高的流量峰值，它对资源的消耗是瞬时的。</p><p>但是对秒杀这个场景来说，最终能够抢到商品的人数是固定的，也就是说 100 人和 10000 人发起请求的结果都是一样的，并发度越高，无效请求也越多，但对系统压力却是巨大的。所以我们需要设计一些规则，让并发的请求更多地延缓，而且我们甚至可以过滤掉一些无效请求。流量削峰的一些操作思路：<strong>排队、答题、分层过滤</strong>。这几种方式都是无损（即不会损失用户的发出请求）的实现方案。</p><h2 id="排队"><a href="#排队" class="headerlink" title="排队"></a>排队</h2><p>要对流量进行削峰，最容易想到的解决方案就是用消息队列来缓冲瞬时流量，把同步的直接调用转换成异步的间接推送，中间通过一个队列在一端承接瞬时的流量洪峰，在另一端平滑地将消息推送出去。在这里，消息队列就像“水库”一样， 拦蓄上游的洪水，削减进入下游河道的洪峰流量，从而达到减免洪水灾害的目的。</p><p>如下图所示：</p><p><img src="/assets/20211205163014-27rsobu.jpe"></p><p>用消息队列来缓冲瞬时流量但是，如果流量峰值持续一段时间达到了消息队列的处理上限，例如本机的消息积压达到了存储空间的上限，消息队列同样也会被压垮，这样虽然保护了下游的系统，但是和直接把请求丢弃也没多大的区别。就像遇到洪水爆发时，即使是有水库恐怕也无济于事。</p><p>除了消息队列，类似的排队方式还有很多，例如：</p><ol><li>利用线程池加锁等待也是一种常用的排队方式；</li><li>先进先出、先进后出等常用的内存排队算法的实现方式；</li><li>把请求序列化到文件中，然后再顺序地读文件（例如基于 MySQL binlog 的同步机制）来恢复请求等方式。</li></ol><p>可以看到，这些方式都有一个共同特征，就是把“一步的操作”变成“两步的操作”，其中增加的一步操作用来起到缓冲的作用。可能会有人觉得不合理，这增加了一个中间缓冲步骤，但如果不增加这个，那么在一些场景下系统很可能会直接崩溃，所以最终还是需要你做出妥协和平衡。</p><h2 id="答题"><a href="#答题" class="headerlink" title="答题"></a>答题</h2><p>答题主要是为了增加购买的复杂度，从而达到两个目的。</p><p>第一个目的是防止部分买家使用秒杀器在参加秒杀时作弊。</p><p>第二个目的其实就是延缓请求，起到对请求流量进行削峰的作用，从而让系统能够更好地支持瞬时的流量高峰。这个重要的功能就是把峰值的下单请求拉长，从以前的 1s 之内延长到 2s~10s。这样一来，请求峰值基于时间分片了。这个时间的分片对服务端处理并发非常重要，会大大减轻压力。而且，由于请求具有先后顺序，靠后的请求到来时自然也就没有库存了，因此根本到不了最后的下单步骤，所以真正的并发写就非常有限了。</p><p>下面重点说一下秒杀答题的设计思路。如下图所示：</p><p><img src="/assets/20211205163015-7q7ybzc.jpe"></p><p>整个秒杀答题的逻辑主要分为 3 部分。</p><ol><li><strong>题库生成模块</strong>，这个部分主要就是生成一个个问题和答案，其实题目和答案本身并不需要很复杂，重要的是能够防止由机器来算出结果，即防止秒杀器来答题。</li><li><strong>题库的推送模块</strong>，用于在秒杀答题前，把题目提前推送给详情系统和交易系统。题库的推送主要是为了保证每次用户请求的题目是唯一的，目的也是防止答题作弊。</li><li><strong>题目的图片生成模块</strong>，用于把题目生成为图片格式，并且在图片里增加一些干扰因素。这也同样是为防止机器直接来答题，它要求只有人才能理解题目本身的含义。这里还要注意一点，由于答题时网络比较拥挤，我们应该把题目的图片提前推送到 CDN 上并且要进行预热，不然的话当用户真正请求题目时，图片可能加载比较慢，从而影响答题的体验。</li></ol><p>其实真正答题的逻辑比较简单，很好理解：当用户提交的答案和题目对应的答案做比较，如果通过了就继续进行下一步的下单逻辑，否则就失败。我们可以把问题和答案用下面这样的 key 来进行 MD5 加密：</p><ul><li>问题 key：userId+itemId+question_Id+time+PK</li><li>答案 key：userId+itemId+answer+PK</li></ul><p>验证的逻辑如下图所示：</p><p><img src="/assets/20211205163014-axd4mre.jpe"></p><p>答题的验证逻辑注意，这里面的验证逻辑，除了验证问题的答案以外，还包括用户本身身份的验证，例如是否已经登录、用户的 Cookie 是否完整、用户是否重复频繁提交等。</p><p>除了做正确性验证，我们还可以对提交答案的时间做些限制，例如从开始答题到接受答案要超过 1s，因为小于 1s 是人为操作的可能性很小，这样也能防止机器答题的情况。</p><h2 id="分层过滤"><a href="#分层过滤" class="headerlink" title="分层过滤"></a>分层过滤</h2><p>前面介绍的排队和答题要么是少发请求，要么对发出来的请求进行缓冲，而针对秒杀场景还有一种方法，就是对请求进行分层过滤，从而过滤掉一些无效的请求。分层过滤其实就是采用“漏斗”式设计来处理请求的，如下图所示。</p><p><img src="/assets/20211205163014-nzob9qw.jpe"></p><p>分层过滤假如请求分别经过 CDN、前台读系统（如商品详情系统）、后台系统（如交易系统）和数据库这几层，那么：</p><ul><li>大部分数据和流量在用户浏览器或者 CDN 上获取，这一层可以拦截大部分数据的读取；</li><li>经过第二层（即前台系统）时数据（包括强一致性的数据）尽量得走 Cache，过滤一些无效的请求；</li><li>再到第三层后台系统，主要做数据的二次检验，对系统做好保护和限流，这样数据量和请求就进一步减少；</li><li>最后在数据层完成数据的强一致性校验。</li></ul><p>这样就像漏斗一样，尽量把数据量和请求量一层一层地过滤和减少了。</p><p><strong>分层过滤的核心思想是：在不同的层次尽可能地过滤掉无效请求，让“漏斗”最末端的才是有效请求</strong>。而要达到这种效果，我们就必须对数据做分层的校验。</p><p>分层校验的基本原则是：</p><ol><li>将动态请求的读数据缓存（Cache）在 Web 端，过滤掉无效的数据读；</li><li>对读数据不做强一致性校验，减少因为一致性校验产生瓶颈的问题；</li><li>对写数据进行基于时间的合理分片，过滤掉过期的失效请求；</li><li>对写请求做限流保护，将超出系统承载能力的请求过滤掉；</li><li>对写数据进行强一致性校验，只保留最后有效的数据。</li></ol><p>分层校验的目的是：在读系统中，尽量减少由于一致性校验带来的系统瓶颈，但是尽量将不影响性能的检查条件提前，如用户是否具有秒杀资格、商品状态是否正常、用户答题是否正确、秒杀是否已经结束、是否非法请求、营销等价物是否充足等；在写数据系统中，主要对写的数据（如“库存”）做一致性检查，最后在数据库层保证数据的最终准确性（如“库存”不能减为负数）。</p>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
          <category> 架构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 架构设计 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>秒杀系统设计一</title>
      <link href="/article/%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E4%B8%80.html"/>
      <url>/article/%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E4%B8%80.html</url>
      
        <content type="html"><![CDATA[<p>随着互联网流量的增大，秒杀瞬时流量达到百万甚至千万OPS，秒杀系统也从商品详情系统独立出来成为一个独立的系统。</p><p>那么，如何才能更好地理解秒杀系统呢？在我看来，<strong>秒杀其实主要解决两个问题，一个是并发读，一个是并发写</strong>。并发读的核心优化理念是尽量减少用户到服务端来“读”数据，或者让他们读更少的数据；并发写的处理原则也一样，它要求我们在数据库层面独立出来一个库，做特殊的处理。另外，我们还要针对秒杀系统做一些保护，针对意料之外的情况设计兜底方案，以防止最坏的情况发生。</p><p>而从一个架构师的角度来看，要想打造并维护一个超大流量并发读写、高性能、高可用的系统，在整个用户请求路径上从浏览器到服务端我们要遵循几个原则，就是要保证用户请求的数据尽量少、请求数尽量少、路径尽量短、依赖尽量少，并且不要有单点。</p><p><strong>其实，秒杀的整体架构可以概括为“稳、准、快”几个关键字。</strong></p><p>所谓“稳”，就是整个系统架构要满足高可用，流量符合预期时肯定要稳定，就是超出预期时也同样不能掉链子，你要保证秒杀活动顺利完成，即秒杀商品顺利地卖出去，这个是最基本的前提。</p><p>然后就是“准”，就是保证库存的准确。一旦库存不对，那平台就要承担损失，所以“准”就是要求保证数据的一致性。</p><p>最后再看“快”，“快”其实很好理解，它就是说系统的性能要足够高，否则你怎么支撑这么大的流量呢？不光是服务端要做极致的性能优化，而且在整个请求链路上都要做协同的优化，每个地方快一点，整个系统就完美了。</p><span id="more"></span><p>所以从技术角度上看“稳、准、快”，就对应了我们架构上的高可用、一致性和高性能的要求，我们的专栏也将主要围绕这几个方面来展开，具体如下。</p><ul><li><strong>高性能。</strong> 秒杀涉及大量的并发读和并发写，因此支持高并发访问这点非常关键。</li><li><strong>一致性。</strong> 秒杀中商品减库存的实现方式同样关键。有限数量的商品在同一时刻被很多倍的请求同时来减库存，在大并发更新的过程中都要保证数据的准确性，其难度可想而知。</li><li><strong>高可用。</strong> 虽然介绍了很多极致的优化思路，但现实中总难免出现一些我们考虑不到的情况，所以要保证系统的高可用和正确性，我们还要设计一个 PlanB 来兜底，以便在最坏情况发生时仍然能够从容应对。</li></ul><p>综述，<strong>秒杀系统本质上就是一个满足大并发、高性能和高可用的分布式系统</strong>。</p><h1 id="架构原则：“4-要-1-不要”"><a href="#架构原则：“4-要-1-不要”" class="headerlink" title="架构原则：“4 要 1 不要”"></a>架构原则：“4 要 1 不要”</h1><p>要构建一个超大流量并发读写、高性能，以及高可用的系统，这其中有哪些要素需要考虑。把这些要素总结为“4 要 1 不要”。</p><h2 id="数据要尽量少"><a href="#数据要尽量少" class="headerlink" title="数据要尽量少"></a>数据要尽量少</h2><p>所谓“数据要尽量少”，首先是指用户请求的数据能少就少。请求的数据包括上传给系统的数据和系统返回给用户的数据（通常就是网页）。</p><p>为啥“数据要尽量少”呢？因为首先这些数据在网络上传输需要时间，其次不管是请求数据还是返回数据都需要服务器做处理，而服务器在写网络时通常都要做压缩和字符编码，这些都非常消耗 CPU，所以减少传输的数据量可以显著减少 CPU 的使用。</p><p>其次，“数据要尽量少”还要求系统依赖的数据能少就少，包括系统完成某些业务逻辑需要读取和保存的数据，这些数据一般是和后台服务以及数据库打交道的。调用其他服务会涉及数据的序列化和反序列化，而这也是 CPU 的一大杀手，同样也会增加延时。而且，数据库本身也容易成为一个瓶颈，所以和数据库打交道越少越好，数据越简单、越小则越好。</p><h2 id="请求数要尽量少"><a href="#请求数要尽量少" class="headerlink" title="请求数要尽量少"></a>请求数要尽量少</h2><p>用户请求的页面返回后，浏览器渲染这个页面还要包含其他的额外请求。因为浏览器每发出一个请求都多少会有一些消耗，另外，如果不同请求的域名不一样的话，还涉及这些域名的 DNS 解析。所以减少请求数可以显著减少以上这些因素导致的资源消耗。</p><h2 id="路径要尽量短"><a href="#路径要尽量短" class="headerlink" title="路径要尽量短"></a>路径要尽量短</h2><p>所谓“路径”，就是用户发出请求到返回数据这个过程中，需求经过的中间的节点数。</p><p>通常，这些节点可以表示为一个系统或者一个新的 Socket 连接（比如代理服务器只是创建一个新的 Socket 连接来转发请求）。每经过一个节点，一般都会产生一个新的 Socket 连接。</p><p>然而，每增加一个连接都会增加新的不确定性。从概率统计上来说，假如一次请求经过 5 个节点，每个节点的可用性是 99.9% 的话，那么整个请求的可用性是：99.9% 的 5 次方，约等于 99.5%。</p><p>所以缩短请求路径不仅可以增加可用性，同样可以有效提升性能（减少中间节点可以减少数据的序列化与反序列化），并减少延时（可以减少网络传输耗时）。</p><p>要缩短访问路径有一种办法，就是多个相互强依赖的应用合并部署在一起，把远程过程调用（RPC）变成 JVM 内部之间的方法调用。</p><h2 id="依赖要尽量少"><a href="#依赖要尽量少" class="headerlink" title="依赖要尽量少"></a>依赖要尽量少</h2><p>所谓依赖，指的是要完成一次用户请求必须依赖的系统或者服务，这里的依赖指的是强依赖。</p><p>比如要展示秒杀页面，而这个页面必须强依赖商品信息、用户信息，还有其他如优惠券、成交列表等这些对秒杀不是非要不可的信息（弱依赖），这些弱依赖在紧急情况下就可以去掉。</p><p>要减少依赖，我们可以给系统进行分级，比如 0 级系统、1 级系统、2 级系统、3 级系统，0 级系统如果是最重要的系统，那么 0 级系统强依赖的系统也同样是最重要的系统，以此类推。</p><h2 id="不要有单点"><a href="#不要有单点" class="headerlink" title="不要有单点"></a>不要有单点</h2><p>系统中的单点可以说是系统架构上的一个大忌，因为单点意味着没有备份，风险不可控，我们设计分布式系统最重要的原则就是“消除单点”。</p><p>那如何避免单点呢？关键点是避免将服务的状态和机器绑定，即把服务无状态化，这样服务就可以在机器中随意移动。</p><p>但是<strong>架构是一种平衡的艺术，而最好的架构一旦脱离了它所适应的场景，一切都将是空谈</strong>。这里所说的几点都只是一个个方向，应该尽量往这些方向上去努力，但也要考虑平衡其他因素。</p><p>要让秒杀系统达到高性能，一方面是提高单次请求的效率，一方面是减少没必要的请求。下面通过动静分离和热点数据两方面讲解。</p><h1 id="动静分离"><a href="#动静分离" class="headerlink" title="动静分离"></a>动静分离</h1><p>“动静分离”，其实就是把用户请求的数据划分为“动态数据”和“静态数据”。</p><p>简单来说，<strong>“动态数据”和“静态数据”的主要区别就是看页面中输出的数据是否和 URL、浏览者、时间、地域相关，以及是否含有 Cookie 等私密数据</strong>。比如说：</p><ol><li>很多媒体类的网站，某一篇文章的内容不管是你访问还是我访问，它都是一样的。所以它就是一个典型的静态数据，但是它是个动态页面。</li><li>我们如果现在访问淘宝的首页，每个人看到的页面可能都是不一样的，淘宝首页中包含了很多根据访问者特征推荐的信息，而这些个性化的数据就可以理解为动态数据了。</li></ol><p>分离了动静数据，我们就可以对分离出来的静态数据做缓存，有了缓存之后，静态数据的“访问效率”自然就提高了。</p><p>如何对静态数据做缓存呢？我在这里总结了几个重点。</p><p><strong>第一，你应该把静态数据缓存到离用户最近的地方</strong>。静态数据就是那些相对不会变化的数据，因此我们可以把它们缓存起来。缓存到哪里呢？常见的就三种，用户浏览器里、CDN 上或者在服务端的 Cache 中。你应该根据情况，把它们尽量缓存到离用户最近的地方。</p><p><strong>第二，静态化改造就是要直接缓存 HTTP 连接</strong>。相较于普通的数据缓存而言，你肯定还听过系统的静态化改造。静态化改造是直接缓存 HTTP 连接而不是仅仅缓存数据，如下图所示，Web 代理服务器根据请求 URL，直接取出对应的 HTTP 响应头和响应体然后直接返回，这个响应过程简单得连 HTTP 协议都不用重新组装，甚至连 HTTP 请求头也不需要解析。</p><p><img src="/assets/20211205155944-m2wc16w.jpe"></p><p><strong>第三，让谁来缓存静态数据也很重要</strong>。不同语言写的 Cache 软件处理缓存数据的效率也各不相同。例如Web 服务器（如 Nginx、Apache、Varnish）也更擅长处理大并发的静态文件请求。</p><h2 id="动静分离的改造"><a href="#动静分离的改造" class="headerlink" title="动静分离的改造"></a>动静分离的改造</h2><p>从以下 5 个方面来分离出动态内容。</p><ol><li><strong>URL 唯一化</strong>。商品详情系统天然地就可以做到 URL 唯一化，比如每个商品都由 ID 来标识。</li><li><strong>分离浏览者相关的因素</strong>。浏览者相关的因素包括是否已登录，以及登录身份等，这些相关因素我们可以单独拆分出来，通过动态请求来获取。</li><li><strong>分离时间因素</strong>。服务端输出的时间也通过动态请求获取。</li><li><strong>异步化地域因素</strong>。详情页面上与地域相关的因素做成异步方式获取，当然你也可以通过动态请求方式获取，只是这里通过异步获取更合适。</li><li><strong>去掉 Cookie</strong>。服务端输出的页面包含的 Cookie 可以通过代码软件来删除。注意，这里说的去掉 Cookie 并不是用户端收到的页面就不含 Cookie 了，而是说，在缓存的静态数据中不含有 Cookie。</li></ol><p>前面我们介绍里用缓存的方式来处理静态数据。而动态内容的处理通常有两种方案：ESI（Edge Side Includes）方案和 CSI（Client Side Include）方案。</p><ol><li><strong>ESI 方案（或者 SSI）</strong>：即在 Web 代理服务器上做动态内容请求，并将请求插入到静态页面中，当用户拿到页面时已经是一个完整的页面了。这种方式对服务端性能有些影响，但是用户体验较好。</li><li><strong>CSI 方案</strong>。即单独发起一个异步 JavaScript 请求，以向服务端获取动态内容。这种方式服务端性能更佳，但是用户端页面可能会延时，体验稍差。</li></ol><h2 id="动静分离的几种架构方案"><a href="#动静分离的几种架构方案" class="headerlink" title="动静分离的几种架构方案"></a>动静分离的几种架构方案</h2><p>根据架构上的复杂度，有 3 种方案可选：</p><ol><li>实体机单机部署；</li><li>统一 Cache 层；</li><li>上 CDN。</li></ol><p><strong>方案 1：实体机单机部署</strong></p><p>这种方案是将虚拟机改为实体机，以增大 Cache 的容量，并且采用了一致性 Hash 分组的方式来提升命中率。这里将 Cache 分成若干组，是希望能达到命中率和访问热点的平衡。Hash 分组越少，缓存的命中率肯定就会越高，但短板是也会使单个商品集中在一个分组中，容易导致 Cache 被击穿，所以我们应该适当增加多个相同的分组，来平衡访问热点和命中率的问题。</p><p>这里我给出了实体机单机部署方案的结构图，如下：</p><p><img src="/assets/20211205155944-220vzwg.jpe"></p><p>Nginx+Cache+Java 结构实体机单机部署实体机单机部署有以下几个优点：</p><ol><li>没有网络瓶颈，而且能使用大内存；</li><li>既能提升命中率，又能减少 Gzip 压缩；</li><li>减少 Cache 失效压力，因为采用定时失效方式，例如只缓存 3 秒钟，过期即自动失效。</li></ol><p>这个方案中，虽然把通常只需要虚拟机或者容器运行的 Java 应用换成实体机，优势很明显，它会增加单机的内存容量，但是一定程度上也造成了 CPU 的浪费，因为单个的 Java 进程很难用完整个实体机的 CPU。</p><p>另外就是，一个实体机上部署了 Java 应用又作为 Cache 来使用，这造成了运维上的高复杂度，所以这是一个折中的方案。如果你的公司里，没有更多的系统有类似需求，那么这样做也比较合适，如果你们有多个业务系统都有静态化改造的需求，那还是建议把 Cache 层单独抽出来公用比较合理。</p><p><strong>方案 2：统一 Cache 层</strong></p><p>所谓统一 Cache 层，就是将单机的 Cache 统一分离出来，形成一个单独的 Cache 集群。统一 Cache 层是个更理想的可推广方案，该方案的结构图如下：</p><p><img src="/assets/20211205155944-47qsrsi.jpe"></p><p>统一 Cache将 Cache 层单独拿出来统一管理可以减少运维成本，同时也方便接入其他静态化系统。此外，它还有一些优点。</p><ol><li>单独一个 Cache 层，可以减少多个应用接入时使用 Cache 的成本。这样接入的应用只要维护自己的 Java 系统就好，不需要单独维护 Cache，而只关心如何使用即可。</li><li>统一 Cache 的方案更易于维护，如后面加强监控、配置的自动化，只需要一套解决方案就行，统一起来维护升级也比较方便。</li><li>可以共享内存，最大化利用内存，不同系统之间的内存可以动态切换，从而能够有效应对各种攻击。</li></ol><p>这种方案虽然维护上更方便了，但是也带来了其他一些问题，比如缓存更加集中，导致：</p><ol><li>Cache 层内部交换网络成为瓶颈；</li><li>缓存服务器的网卡也会是瓶颈；</li><li>机器少风险较大，挂掉一台就会影响很大一部分缓存数据。</li></ol><p>要解决上面这些问题，可以再对 Cache 做 Hash 分组，即一组 Cache 缓存的内容相同，这样能够避免热点数据过度集中导致新的瓶颈产生。</p><p><strong>方案 3：上 CDN</strong></p><p>在将整个系统做动静分离后，我们自然会想到更进一步的方案，就是将 Cache 进一步前移到 CDN 上，因为 CDN 离用户最近，效果会更好。</p><p>但是要想这么做，有以下几个问题需要解决。</p><ol><li><strong>失效问题</strong>。前面我们也有提到过缓存时效的问题，不知道你有没有理解，我再来解释一下。谈到静态数据时，我说过一个关键词叫“相对不变”，它的言外之意是“可能会变化”。比如一篇文章，现在不变，但如果你发现个错别字，是不是就会变化了？如果你的缓存时效很长，那用户端在很长一段时间内看到的都是错的。所以，这个方案中也是，我们需要保证 CDN 可以在秒级时间内，让分布在全国各地的 Cache 同时失效，这对 CDN 的失效系统要求很高。</li><li><strong>命中率问题</strong>。Cache 最重要的一个衡量指标就是“高命中率”，不然 Cache 的存在就失去了意义。同样，如果将数据全部放到全国的 CDN 上，必然导致 Cache 分散，而 Cache 分散又会导致访问请求命中同一个 Cache 的可能性降低，那么命中率就成为一个问题。</li><li><strong>发布更新问题</strong>。如果一个业务系统每周都有日常业务需要发布，那么发布系统必须足够简洁高效，而且你还要考虑有问题时快速回滚和排查问题的简便性。</li></ol><p>从前面的分析来看，将商品详情系统放到全国的所有 CDN 节点上是不太现实的，因为存在失效问题、命中率问题以及系统的发布更新问题。那么是否可以选择若干个节点来尝试实施呢？答案是“可以”，但是这样的节点需要满足几个条件：</p><ol><li>靠近访问量比较集中的地区；</li><li>离主站相对较远；</li><li>节点到主站间的网络比较好，而且稳定；</li><li>节点容量比较大，不会占用其他 CDN 太多的资源。</li><li><strong>节点不要太多</strong>。</li></ol><p>基于上面几个因素，选择 CDN 的二级 Cache 比较合适，因为二级 Cache 数量偏少，容量也更大，让用户的请求先回源的 CDN 的二级 Cache 中，如果没命中再回源站获取数据，部署方式如下图所示：</p><p><img src="/assets/20211205155944-7jsm556.jpe"></p><p>CDN 化部署方案使用 CDN 的二级 Cache 作为缓存，可以达到和当前服务端静态化 Cache 类似的命中率，因为节点数不多，Cache 不是很分散，访问量也比较集中，这样也就解决了命中率问题，同时能够给用户最好的访问体验，是当前比较理想的一种 CDN 化方案。</p><p>除此之外，CDN 化部署方案还有以下几个特点：</p><ol><li>把整个页面缓存在用户浏览器中；</li><li>如果强制刷新整个页面，也会请求 CDN；</li><li>实际有效请求，只是用户对“刷新抢宝”按钮的点击。</li></ol><p>这样就把 90% 的静态数据缓存在了用户端或者 CDN 上，当真正秒杀时，用户只需要点击特殊的“刷新抢宝”按钮，而不需要刷新整个页面。这样一来，系统只是向服务端请求很少的有效数据，而不需要重复请求大量的静态数据。</p>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
          <category> 架构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 架构设计 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PRC核心原理四</title>
      <link href="/article/PRC%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86%E5%9B%9B.html"/>
      <url>/article/PRC%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86%E5%9B%9B.html</url>
      
        <content type="html"><![CDATA[<p>RPC 是解决分布式系统通信问题的一大利器，而分布式系统的一大特点就是高并发，所以说 RPC 也会面临高并发的场景。在这样的情况下，我们提供服务的每个服务节点就都可能由于访问量过大而引起一系列的问题，比如业务处理耗时过长、CPU 飘高、频繁 Full GC 以及服务进程直接宕机等等。但是在生产环境中，我们要保证服务的稳定性和高可用性，这时我们就需要业务进行自我保护，从而保证在高访问量、高并发的场景下，应用系统依然稳定，服务依然高可用。</p><p><strong>那么在使用 RPC 时，业务又如何实现自我保护呢？</strong></p><p>我们可以将 RPC 框架拆开来分析，RPC 调用包括服务端和调用端，调用端向服务端发起调用。下面我就分享一下服务端与调用端分别是如何进行自我保护的。</p><h2 id="服务端的自我保护"><a href="#服务端的自我保护" class="headerlink" title="服务端的自我保护"></a>服务端的自我保护</h2><p>我们先看服务端，作为服务端接收调用端发送过来的请求，这时服务端的某个节点负载压力过高了，我们该如何保护这个节点？如下图所示例：</p><p><img src="/assets/20211127162249-14pxktu.jpe"></p><p>负载压力高，那就不让它再接收太多的请求就好了，等接收和处理的请求数量下来后，这个节点的负载压力自然就下来了。在 RPC 调用中服务端的自我保护策略就是<strong>限流</strong>。</p><span id="more"></span><h3 id="限流"><a href="#限流" class="headerlink" title="限流"></a>限流</h3><p>限流是一个比较通用的功能，我们可以在 RPC 框架中集成限流的功能，让使用方自己去配置限流阈值；我们还可以在服务端添加限流逻辑，当调用端发送请求过来时，服务端在执行业务逻辑之前先执行限流逻辑，如果发现访问量过大并且超出了限流的阈值，就让服务端直接抛回给调用端一个限流异常，否则就执行正常的业务逻辑。</p><p><img src="/assets/20211127162249-ptkrrgq.jpe"></p><h3 id="限流逻辑的实现"><a href="#限流逻辑的实现" class="headerlink" title="限流逻辑的实现"></a>限流逻辑的实现</h3><p>方式有很多，比如最简单的计数器，还有可以做到平滑限流的滑动窗口、漏斗算法以及令牌桶算法等等。其中令牌桶算法最为常用。</p><h4 id="令牌桶算法"><a href="#令牌桶算法" class="headerlink" title="令牌桶算法"></a>令牌桶算法</h4><p>下图是令牌桶算法流程图：</p><blockquote><p><img src="/assets/20211127164020-kcjy79q.png">   <img src="/assets/20211127164020-zadavyl.png"></p></blockquote><p><strong>系统会按照固定是速度生成令牌(可配置)，通过配置令牌生成速度的大小来起到对请求大小的限流作用。</strong></p><p><strong>生成的令牌放入桶中，如果桶中令牌满了，则令牌废弃。</strong></p><p><strong>每次请求来，都需要从桶中拿令牌，如果桶中有令牌，则进行业务处理，否则就会被拒绝。</strong></p><p>从这里看出，业务的请求速度，如果小于令牌的生成速度，那么业务都会拿到令牌，则不会被拒绝。如果业务的请求速度大于令牌的生成速度，则可能桶中没有了令牌，拿不到令牌而被拒绝。</p><p>所以令牌的生成速度大小可以起到对请求速度限流的调节作用。</p><h4 id="动态配置限流"><a href="#动态配置限流" class="headerlink" title="动态配置限流"></a>动态配置限流</h4><p>通常我们在做限流的时候要考虑应用级别的维度，甚至是 IP 级别的维度，这样做不仅可以让我们对一个应用下的调用端发送过来的请求流量做限流，还可以对一个 IP 发送过来的请求流量做限流。</p><p>RPC 框架真正强大的地方在于它的治理功能，而治理功能大多都需要依赖一个注册中心或者配置中心，我们可以通过 RPC 治理的管理端进行配置，再通过注册中心或者配置中心将限流阈值的配置下发到服务提供方的每个节点上，实现动态配置。</p><p>看到这儿，你有没有发现，在服务端实现限流，配置的限流阈值是作用在每个服务节点上的。比如说我配置的阈值是每秒 1000 次请求，那么就是指一台机器每秒处理 1000 次请求；如果我的服务集群拥有 10 个服务节点，那么我提供的服务限流阈值在最理想的情况下就是每秒 10000 次。</p><p>另外我们也可以让 RPC 框架自己去计算，当注册中心或配置中心将限流阈值配置下发的时候，我们可以将总服务节点数也下发给服务节点，之后由服务节点自己计算限流阈值。</p><p>我们还可以提供一个专门的限流服务，让每个节点都依赖一个限流服务，当请求流量打过来时，服务节点触发限流逻辑，调用这个限流服务来判断是否到达了限流阈值。我们甚至可以将限流逻辑放在调用端，调用端在发出请求时先触发限流逻辑，调用限流服务，如果请求量已经到达了限流阈值，请求都不需要发出去，直接返回给动态代理一个限流异常即可。</p><p>这种限流方式可以让整个服务集群的限流变得更加精确，但也由于依赖了一个限流服务，它在性能和耗时上与单机的限流方式相比是有很大劣势的。至于要选择哪种限流方式，就要结合具体的应用场景进行选择了。</p><p>这些方法都是为了让RPC框架能自我识别流量，自动调整限流策略，降低因人为预估的不准确而造成系统的稳定性降低。</p><h2 id="调用端的自我保护"><a href="#调用端的自我保护" class="headerlink" title="调用端的自我保护"></a>调用端的自我保护</h2><p>在微服务中由于多个服务的调用关系，当一个服务 A 来调用服务 B 时，服务 B 的业务逻辑调用服务 C，而这时服务 C 响应超时了，由于服务 B 依赖服务 C，C 超时直接导致 B 的业务逻辑一直等待，而这个时候服务 A 在频繁地调用服务 B，服务 B 就可能会因为堆积大量的请求而导致服务宕机。</p><p><img src="/assets/20211127162249-oziiv9m.jpe" title="服务异常示意图"></p><p>由此可见，服务 B 调用服务 C，服务 C 执行业务逻辑出现异常时，会影响到服务 B，甚至可能会引起服务 B 宕机。这还只是 A-&gt;B-&gt;C 的情况，试想一下 A-&gt;B-&gt;C-&gt;D-&gt;……呢？在整个调用链中，只要中间有一个服务出现问题，都可能会引起上游的所有服务出现一系列的问题，甚至会引起整个调用链的服务都宕机，<strong>这就是我们经常遇到的一种服务雪崩情况。</strong></p><p>所以说，在一个服务作为调用端调用另外一个服务时，为了防止被调用的服务出现问题而影响到作为调用端的这个服务，这个服务也需要进行自我保护。<strong>而最有效的自我保护方式就是熔断和降级。</strong></p><h3 id="熔断"><a href="#熔断" class="headerlink" title="熔断"></a>熔断</h3><p>通过熔断器的打开&#x2F;关闭来判断是否对下游进行服务的调用。</p><p><img src="/assets/20211127162249-uwydau0.jpe"></p><h4 id="熔断机制"><a href="#熔断机制" class="headerlink" title="熔断机制"></a>熔断机制</h4><p>而熔断器的打开和关闭由熔断机制决定。这个机制参考的是电路中保险丝的保护机制，当电路超负荷运转的时候，保险丝会断开电路，保证整体电路不受损害。而服务治理中的熔断机制指的是在发起服务调用的时候，如果返回错误或者超时的次数超过一定阈值，则后续的请求不再发向远程服务而是暂时返回错误。</p><p>这种实现方式在云计算领域又称为断路器模式，在这种模式下，服务调用方为每一个调用的服务维护一个有限状态机，在这个状态机中会有三种状态：关闭（调用远程服务）、半打开（尝试调用远程服务）和打开（返回错误）。这三种状态之间切换的过程是下面这个样子。</p><ul><li>当调用失败的次数累积到一定的阈值时，熔断状态从关闭态切换到打开态。一般在实现时，如果调用成功一次，就会重置调用失败次数。</li><li>当熔断处于打开状态时，我们会启动一个超时计时器，当计时器超时后，状态切换到半打开态。你也可以通过设置一个定时器，定期地探测服务是否恢复。</li><li>在熔断处于半打开状态时，请求可以达到后端服务，如果累计一定的成功次数后，状态切换到关闭态；如果出现调用失败的情况，则切换到打开态。</li></ul><p><img src="/assets/20211127170124-c4r7zps.jpe"></p><h3 id="降级"><a href="#降级" class="headerlink" title="降级"></a>降级</h3><p>除了熔断之外，我们听到最多的服务容错方式就是降级，那么降级又是怎么做的呢？它和熔断有什么关系呢？</p><p>其实在我看来，相比熔断来说，降级是一个更大的概念。因为它是站在整体系统负载的角度上，放弃部分非核心功能或者服务，保证整体的可用性的方法，是一种有损的系统容错方式。这样看来，熔断也是降级的一种。</p><p>开关降级指的是在代码中预先埋设一些“开关”，用来控制服务调用的返回值。比方说，开关关闭的时候正常调用远程服务，开关打开时则执行降级的策略。这些开关的值可以存储在配置中心中，当系统出现问题需要降级时，只需要通过配置中心动态更改开关的值，就可以实现不重启服务快速地降级远程服务了。</p><p>还是以电商系统为例，你的电商系统在商品详情页面除了展示商品数据以外，还需要展示评论的数据，但是主体还是商品数据，在必要时可以降级评论数据。所以，你可以定义这个开关为“degrade.comment”，写入到配置中心中，具体的代码也比较简单，就像下面这样：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">boolean</span> <span class="variable">switcherValue</span> <span class="operator">=</span> getFromConfigCenter(<span class="string">&quot;degrade.comment&quot;</span>); <span class="comment">//从配置中心获取开关的值</span></span><br><span class="line"><span class="keyword">if</span> (!switcherValue) &#123;</span><br><span class="line">  正常业务逻辑</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  降级逻辑</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当然了，我们在设计开关降级预案的时候，首先要区分哪些是核心服务，哪些是非核心服务。因为我们只能针对非核心服务来做降级处理，然后就可以针对具体的业务，制定不同的降级策略了。我给你列举一些常见场景下的降级策略，你在实际的工作中可以参考借鉴。</p><ul><li>针对读取数据的场景，我们一般采用的策略是直接返回降级数据。比如，如果数据库的压力比较大，我们在降级的时候，可以考虑只读取缓存的数据，而不再读取数据库中的数据；如果非核心接口出现问题，可以直接返回服务繁忙或者返回固定的降级数据。</li><li>对于一些轮询查询数据的场景，比如每隔 30 秒轮询获取未读数，可以降低获取数据的频率（将获取频率下降到 10 分钟一次）。</li><li>而对于写数据的场景，一般会考虑把同步写转换成异步写，这样可以牺牲一些数据一致性保证系统的可用性。</li></ul><p><strong>我想强调的是，只有经过演练的开关才是有用的开关，</strong>有些同学在给系统加了开关之后并不测试，结果出了问题真要使用的时候，却发现开关并不生效。因此，你在为系统增加降级开关时，一定要在流量低峰期的时候做验证演练，也可以在不定期的压力测试过程中演练，保证开关的可用性。</p><h2 id="RPC系列总结"><a href="#RPC系列总结" class="headerlink" title="RPC系列总结"></a>RPC系列总结</h2><p>通过这四章，讲解了RPC的核心原理，其中因为微服务架构的兴起，我们对RPC框架也有了更高的要求，如服务发现，服务治理，限流，熔断降级等。而微服务让服务拆分，一个请求调用关系可能会很复杂，所以在微服务架构中，通常还需要有分布式Trace链路跟踪、业务分组流量隔离机制等。这些因为对于RPC来说只是信息传递能力，所以在RPC章节就不再讲解，后续可能会在微服务中再重点讲解。</p>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
          <category> PRC </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RPC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PRC核心原理三</title>
      <link href="/article/RPC%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86%E4%B8%89.html"/>
      <url>/article/RPC%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86%E4%B8%89.html</url>
      
        <content type="html"><![CDATA[<p>通过前面两章，<strong>一个点对点（Point to Point）版本的 RPC 框架就完成了。</strong>我一般称这种模式的 RPC 框架为单机版本，因为它没有集群能力。所谓集群能力，就是针对同一个接口有着多个服务提供者，但这多个服务提供者对于我们的调用方来说是透明的，所以在 RPC 里面我们还需要给调用方找到所有的服务提供方，并需要在 RPC 里面维护好接口跟服务提供者地址的关系，这样调用方在发起请求的时候才能快速地找到对应的接收地址，这就是我们常说的“服务发现”。</p><p>另外对于PRC，还需要服务治理的功能，比如服务提供方权重的设置、调用授权等一些常规治理手段。而服务调用方需要额外做哪些事情呢？每次调用前，我们都需要根据服务提供方设置的规则，从集群中选择可用的连接用于发送请求。</p><p>那到这儿，一个比较完善的 RPC 框架基本就完成了，功能也差不多就是这些了。按照分层设计的原则，我将这些功能模块分为了四层，具体内容见图示：</p><p><img src="/assets/20211123222243-7o334it.jpe" title="架构图"></p><h1 id="服务发现"><a href="#服务发现" class="headerlink" title="服务发现"></a>服务发现</h1><p>在集群中，集群里面的这些节点随时可能变化，提供服务的节点增加或者减少，需要通知给调用方。这个过程叫做“服务发现”。</p><span id="more"></span><p>我们可以通过一个叫“注册中心”的模块，服务方注册到注册中心，调用方订阅服务接口，来实现监听服务的变更，并通知给客户端。这就是我要说的 PRC 框架的服务发现机制，如下图所示：</p><p><img src="/assets/20211123222916-yaqxa0f.jpe" title="RPC服务发现原理图"></p><ol><li>服务注册：在服务提供方启动的时候，将对外暴露的接口注册到注册中心之中，注册中心将这个服务节点的 IP 和接口保存下来。</li><li>服务订阅：在服务调用方启动的时候，去注册中心查找并订阅服务提供方的 IP，然后缓存到本地，并用于后续的远程调用。</li></ol><h2 id="基于-ZooKeeper-的服务发现"><a href="#基于-ZooKeeper-的服务发现" class="headerlink" title="基于 ZooKeeper 的服务发现"></a>基于 ZooKeeper 的服务发现</h2><p>整体的思路很简单，就是搭建一个 ZooKeeper 集群作为注册中心集群，服务注册的时候只需要服务节点向 ZooKeeper 节点写入注册信息即可，利用 ZooKeeper 的 Watcher 机制完成服务订阅与服务下发功能，整体流程如下图：</p><p><img src="/assets/20211123233504-6q7kgts.jpe" title="基于ZooKeeper服务发现结构图"></p><ol><li>服务平台管理端先在 ZooKeeper 中创建一个服务根路径，可以根据接口名命名（例如：&#x2F;service&#x2F;com.demo.xxService），在这个路径再创建服务提供方目录与服务调用方目录（例如：provider、consumer），分别用来存储服务提供方的节点信息和服务调用方的节点信息。</li><li>当服务提供方发起注册时，会在服务提供方目录中创建一个临时节点，节点中存储该服务提供方的注册信息。</li><li>当服务调用方发起订阅时，则在服务调用方目录中创建一个临时节点，节点中存储该服务调用方的信息，同时服务调用方 watch 该服务的服务提供方目录（&#x2F;service&#x2F;com.demo.xxService&#x2F;provider）中所有的服务节点数据。</li><li>当服务提供方目录下有节点数据发生变更时，ZooKeeper 就会通知给发起订阅的服务调用方。</li></ol><p>但随着微服务越来越多，当连接到 ZooKeeper 的节点数量特别多，对 ZooKeeper 读写特别频繁，且 ZooKeeper 存储的目录达到一定数量的时候，ZooKeeper 将不再稳定，CPU 持续升高，最终宕机。而宕机之后，由于各业务的节点还在持续发送读写请求，刚一启动，ZooKeeper 就因无法承受瞬间的读写压力，马上宕机。</p><h2 id="基于消息队列的注册中心"><a href="#基于消息队列的注册中心" class="headerlink" title="基于消息队列的注册中心"></a>基于消息队列的注册中心</h2><p>Zookeeper保证了集群的强一致性，这也就直接导致了 ZooKeeper 集群性能上的下降。而RPC节点变更和通知并不需要那么强的一致性，所以可以基于最终一致性，来换取整个注册中心集群的性能和稳定性。</p><p>因为要求最终一致性，我们可以考虑采用消息总线机制。注册数据可以全量缓存在每个注册中心内存中，通过消息总线来同步数据。当有一个注册中心节点接收到服务节点注册时，会产生一个消息推送给消息总线，再通过消息总线通知给其它注册中心节点更新数据并进行服务下发，从而达到注册中心间数据最终一致性，具体流程如下图所示：</p><p><img src="/assets/20211123233933-tak4nrf.jpe" title="流程图"></p><ul><li>当有服务上线，注册中心节点收到注册请求，服务列表数据发生变化，会生成一个消息，推送给消息总线，每个消息都有整体递增的版本。</li><li>消息总线会主动推送消息到各个注册中心，同时注册中心也会定时拉取消息。对于获取到消息的在消息回放模块里面回放，只接受大于本地版本号的消息，小于本地版本号的消息直接丢弃，从而实现最终一致性。</li><li>消费者订阅可以从注册中心内存拿到指定接口的全部服务实例，并缓存到消费者的内存里面。</li><li>采用推拉模式，消费者可以及时地拿到服务实例增量变化情况，并和内存中的缓存数据进行合并。</li></ul><p>为了性能，这里采用了两级缓存，注册中心和消费者的内存缓存，通过异步推拉模式来确保最终一致性。</p><h1 id="健康检查"><a href="#健康检查" class="headerlink" title="健康检查"></a>健康检查</h1><p>服务发现能够对机器的增加减少进行处理，但如果某个服务提供者突然发生了宕机，注册中心和调用方如何能够知道，从而不进行调用呢，这时候就需要进行健康检查。</p><p>通常方法是使用心跳机制，心跳机制说起来也不复杂，其实就是服务调用方每隔一段时间就问一下服务提供方目前的状态。</p><p>定义服务方三个状态就是：</p><ol><li>健康状态：建立连接成功，并且心跳探活也一直成功；</li><li>亚健康状态：建立连接成功，但是心跳请求连续失败；</li><li>死亡状态：建立连接失败。</li></ol><p>节点的状态并不是固定不变的，它会根据心跳或者重连的结果来动态变化，具体状态间转换图如下：</p><p><img src="/assets/20211123234626-259mvq7.jpe"></p><p>这里你可以关注下几个状态之间的转换剪头，我再给你解释下。首先，一开始初始化的时候，如果建立连接成功，那就是健康状态，否则就是死亡状态。这里没有亚健康这样的中间态。紧接着，如果健康状态的节点连续出现几次不能响应心跳请求的情况，那就会被标记为亚健康状态，也就是说，服务调用方会觉得它生病了。</p><h1 id="负载均衡和路由策略"><a href="#负载均衡和路由策略" class="headerlink" title="负载均衡和路由策略"></a>负载均衡和路由策略</h1><h3 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h3><p>RPC 的负载均衡完全由 RPC 框架自身实现，RPC 的服务调用者会与“注册中心”下发的所有服务节点建立长连接，在每次发起 RPC 调用时，服务调用者都会通过配置的负载均衡插件，自主选择一个服务节点，发起 RPC 调用请求。</p><p><img src="/assets/20211123235216-8f775qo.jpe" title="RPC框架负载均衡示意图"></p><p>RPC 负载均衡策略一般包括随机权重、Hash、轮询。当然，这还是主要看 RPC 框架自身的实现。其中的随机权重策略应该是我们最常用的一种了，通过随机算法，我们基本可以保证每个节点接收到的请求流量是均匀的；同时我们还可以通过控制节点权重的方式，来进行流量控制。比如我们默认每个节点的权重都是 100，但当我们把其中的一个节点的权重设置成 50 时，它接收到的流量就是其他节点的 1&#x2F;2。</p><h2 id="路由策略"><a href="#路由策略" class="headerlink" title="路由策略"></a>路由策略</h2><p>负载均衡是为了能够将流量比较均衡的打在各个服务节点上，起到多节点分担流量压力的作用。但有些场景，我们可能需要某些流量打到具体的节点上，这时候就需要使用路由策略。</p><p>其中比较场景的路由策略有IP路由和参数路由，前者根据IP对流量进行分流，后者根据调用中某个参数进行分流，例如按照城市id分流。</p><p>RPC框架往往也支持自定义路由策略，使用者通过实现抽象路由接口来自定义自己的路由策略。</p>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
          <category> PRC </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RPC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PRC核心原理二</title>
      <link href="/article/PRC%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86%E4%BA%8C.html"/>
      <url>/article/PRC%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86%E4%BA%8C.html</url>
      
        <content type="html"><![CDATA[<p>在<a href="RPC%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86%E4%B8%80.html">上一文</a>中介绍了什么是RPC，以及PRC的协议设计和对象序列化，详情可学习，本篇重点介绍PRC的网络通信和如何实现本地方法调用。</p><h1 id="网络通信"><a href="#网络通信" class="headerlink" title="网络通信"></a>网络通信</h1><h2 id="常见的网络-IO-模型"><a href="#常见的网络-IO-模型" class="headerlink" title="常见的网络 IO 模型"></a>常见的网络 IO 模型</h2><p>那说到网络通信，就不得不提一下网络 IO 模型。为什么要讲网络 IO 模型呢？因为所谓的两台 PC 机之间的网络通信，实际上就是两台 PC 机对网络 IO 的操作。</p><p>常见的网络 IO 模型分为四种：同步阻塞 IO（BIO）、同步非阻塞 IO（NIO）、IO 多路复用和异步非阻塞 IO（AIO）。在这四种 IO 模型中，只有 AIO 为异步 IO，其他都是同步 IO。</p><h3 id="阻塞-IO（blocking-IO）"><a href="#阻塞-IO（blocking-IO）" class="headerlink" title="阻塞 IO（blocking IO）"></a>阻塞 IO（blocking IO）</h3><p>同步阻塞 IO 是最简单、最常见的 IO 模型，在 Linux 中，默认情况下所有的 socket 都是 blocking 的，先看下操作流程。</p><p>首先，应用进程发起 IO 系统调用后，应用进程被阻塞，转到内核空间处理。之后，内核开始等待数据，等待到数据之后，再将内核中的数据拷贝到用户内存中，整个 IO 处理完毕后返回进程。最后应用的进程解除阻塞状态，运行业务逻辑。</p><p>这里我们可以看到，系统内核处理 IO 操作分为两个阶段——等待数据和拷贝数据。而在这两个阶段中，应用进程中 IO 操作的线程会一直都处于阻塞状态，如果是基于 Java 多线程开发，那么每一个 IO 操作都要占用线程，直至 IO 操作结束。</p><span id="more"></span><h3 id="IO-多路复用（IO-multiplexing）"><a href="#IO-多路复用（IO-multiplexing）" class="headerlink" title="IO 多路复用（IO multiplexing）"></a>IO 多路复用（IO multiplexing）</h3><p>多路复用 IO 是在高并发场景中使用最为广泛的一种 IO 模型，如 Java 的 NIO、Redis、Nginx 的底层实现就是此类 IO 模型的应用，经典的 Reactor 模式也是基于此类 IO 模型。</p><p>那么什么是 IO 多路复用呢？通过字面上的理解，多路就是指多个通道，也就是多个网络连接的 IO，而复用就是指多个通道复用在一个复用器上。</p><p>多个网络连接的 IO 可以注册到一个复用器（select）上，当用户进程调用了 select，那么整个进程会被阻塞。同时，内核会“监视”所有 select 负责的 socket，当任何一个 socket 中的数据准备好了，select 就会返回。这个时候用户进程再调用 read 操作，将数据从内核中拷贝到用户进程。</p><p>这里我们可以看到，当用户进程发起了 select 调用，进程会被阻塞，当发现该 select 负责的 socket 有准备好的数据时才返回，之后才发起一次 read，整个流程要比阻塞 IO 要复杂，似乎也更浪费性能。但它最大的优势在于，用户可以在一个线程内同时处理多个 socket 的 IO 请求。用户可以注册多个 socket，然后不断地调用 select 读取被激活的 socket，即可达到在同一个线程内同时处理多个 IO 请求的目的。而在同步阻塞模型中，必须通过多线程的方式才能达到这个目的。</p><h3 id="RPC-网络通信上倾向选择哪种网络-IO-模型"><a href="#RPC-网络通信上倾向选择哪种网络-IO-模型" class="headerlink" title="RPC 网络通信上倾向选择哪种网络 IO 模型"></a>RPC 网络通信上倾向选择哪种网络 IO 模型</h3><p>IO 多路复用更适合高并发的场景，可以用较少的进程（线程）处理较多的 socket 的 IO 请求，但使用难度比较高。当然高级的编程语言支持得还是比较好的，比如 Java 语言有很多的开源框架对 Java 原生 API 做了封装，如 Netty 框架，使用非常简便；而 GO 语言，语言本身对 IO 多路复用的封装就已经很简洁了。</p><p>而阻塞 IO 与 IO 多路复用相比，阻塞 IO 每处理一个 socket 的 IO 请求都会阻塞进程（线程），但使用难度较低。在并发量较低、业务逻辑只需要同步进行 IO 操作的场景下，阻塞 IO 已经满足了需求，并且不需要发起 select 调用，开销上还要比 IO 多路复用低。</p><p>RPC 调用在大多数的情况下，是一个高并发调用的场景，考虑到系统内核的支持、编程语言的支持以及 IO 模型本身的特点，在 RPC 框架的实现中，在网络通信的处理上，我们会选择 IO 多路复用的方式。开发语言的网络通信框架的选型上，我们最优的选择是基于 Reactor 模式实现的框架，如 Java 语言，首选的框架便是 Netty 框架（Java 还有很多其他 NIO 框架，但目前 Netty 应用得最为广泛）</p><h2 id="零拷贝"><a href="#零拷贝" class="headerlink" title="零拷贝"></a>零拷贝</h2><p>在阻塞IO中，系统内核处理 IO 操作分为两个阶段——等待数据和拷贝数据。等待数据，就是系统内核在等待网卡接收到数据后，把数据写到内核中；而拷贝数据，就是系统内核在获取到数据后，将数据拷贝到用户进程的空间中。以下是具体流程：</p><p><img src="/assets/20211121161520-lh2e29x.jpe" title="网络IO读写流程"></p><p>应用进程的每一次写操作，都会把数据写到用户空间的缓冲区中，再由 CPU 将数据拷贝到系统内核的缓冲区中，之后再由 DMA 将这份数据拷贝到网卡中，最后由网卡发送出去。这里我们可以看到，一次写操作数据要拷贝两次才能通过网卡发送出去，而用户进程的读操作则是将整个流程反过来，数据同样会拷贝两次才能让应用程序读取到数据。</p><p>应用进程的一次完整的读写操作，都需要在用户空间与内核空间中来回拷贝，并且每一次拷贝，都需要 CPU 进行一次上下文切换（由用户进程切换到系统内核，或由系统内核切换到用户进程）。而零拷贝技术就是取消用户空间与内核空间之间的数据拷贝操作，应用进程每一次的读写操作，都可以通过一种方式，让应用进程向用户空间写入或者读取数据，就如同直接向内核空间写入或者读取数据一样，再通过 DMA 将内核中的数据拷贝到网卡，或将网卡中的数据 copy 到内核。</p><p>那怎么做到零拷贝？是不是用户空间与内核空间都将数据写到一个地方，就没有了数据拷贝。</p><p><img src="/assets/20211121161715-6e9pp4o.jpe"></p><p>零拷贝有两种解决方式，分别是 mmap+write 方式和 sendfile 方式，mmap+write 方式的核心原理就是通过虚拟内存来解决的。</p><h2 id="Netty-中的零拷贝"><a href="#Netty-中的零拷贝" class="headerlink" title="Netty 中的零拷贝"></a>Netty 中的零拷贝</h2><p>刚才我讲的零拷贝是操作系统层面上的零拷贝，主要目标是避免用户空间与内核空间之间的数据拷贝操作，可以提升 CPU 的利用率。</p><p>而 Netty 的零拷贝则不大一样，他完全站在了用户空间上，也就是 JVM 上，它的零拷贝主要是偏向于数据操作的优化上。</p><p>上一文降到，在传输过程中，RPC 并不会把请求参数的所有二进制数据整体一下子发送到对端机器上，中间可能会拆分成好几个数据包，也可能会合并其他请求的数据包，所以消息都需要有边界。那么一端的机器收到消息之后，就需要对数据包进行处理，根据边界对数据包进行分割和合并，最终获得一条完整的消息。</p><p>那收到消息后，对数据包的分割和合并，是在用户空间完成，还是在内核空间完成的呢？</p><p>当然是在用户空间，因为对数据包的处理工作都是由应用程序来处理的，那么这里有没有可能存在数据的拷贝操作？可能会存在，当然不是在用户空间与内核空间之间的拷贝，是用户空间内部内存中的拷贝处理操作。Netty 的零拷贝就是为了解决这个问题，在用户空间对数据操作进行优化。</p><p>那么 Netty 是怎么对数据操作进行优化的呢？</p><ul><li>Netty 提供了 CompositeByteBuf 类，它可以将多个 ByteBuf 合并为一个逻辑上的 ByteBuf，避免了各个 ByteBuf 之间的拷贝。</li><li>ByteBuf 支持 slice 操作，因此可以将 ByteBuf 分解为多个共享同一个存储区域的 ByteBuf，避免了内存的拷贝。</li><li>通过 wrap 操作，我们可以将 byte[] 数组、ByteBuf、ByteBuffer 等包装成一个 Netty ByteBuf 对象, 进而避免拷贝操作。</li></ul><p>Netty 框架中很多内部的 ChannelHandler 实现类，都是通过 CompositeByteBuf、slice、wrap 操作来处理 TCP 传输中的拆包与粘包问题的。</p><p>那么 Netty 有没有解决用户空间与内核空间之间的数据拷贝问题的方法呢？</p><p>Netty 的 ByteBuffer 可以采用 Direct Buffers，使用堆外直接内存进行 Socket 的读写操作，最终的效果与我刚才讲解的虚拟内存所实现的效果是一样的。</p><p>Netty 还提供 FileRegion 中包装 NIO 的 FileChannel.transferTo() 方法实现了零拷贝，这与 Linux 中的 sendfile 方式在原理上也是一样的。</p><h1 id="本地方法调用"><a href="#本地方法调用" class="headerlink" title="本地方法调用"></a>本地方法调用</h1><p>我们如何实现调用远程服务方法像调用本地方法一样，在设计模式中，代理模式可以为我们的接口或者类实现方法增强。而Java提供的动态代理方式，可以让我们在RPC对本地接口进行代理，添加远程调用所需要的对象序列化，RPC协议包装，网络通信等功能，在调用端感知即只是本地的接口方法调用。</p><p>整体流程如下图所示：</p><p><img src="/assets/20211121162714-cd3oj17.jpe"></p><h2 id="动态代理"><a href="#动态代理" class="headerlink" title="动态代理"></a>动态代理</h2><p>在Java中Proxy类和InvocationHandler实现动态代理，我们还有很多其他的第三方框架也可以，比如像 Javassist、Byte Buddy 这样的框架。</p><p>JDK 默认的代理功能是有一定的局限性的，它要求被代理的类只能是接口。原因是因为生成的代理类会继承 Proxy 类，但 Java 是不支持多重继承的。另外最大的问题就是性能问题。它生成后的代理类是使用反射来完成方法调用的，而这种方式相对直接用编码调用来说，性能会降低，但好在 JDK8 及以上版本对反射调用的性能有很大的提升。</p><p>相对 JDK 自带的代理功能，Javassist 的定位是能够操纵底层字节码，所以使用起来并不简单，要生成动态代理类恐怕是有点复杂了。但好的方面是，通过 Javassist 生成字节码，不需要通过反射完成方法调用，所以性能肯定是更胜一筹的。在使用中，我们要注意一个问题，通过 Javassist 生成一个代理类后，此 CtClass 对象会被冻结起来，不允许再修改；否则，再次生成时会报错。</p><p>具体关于动态代理网上学习资料很多，这里不做过多赘述。</p>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
          <category> PRC </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RPC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PRC核心原理一</title>
      <link href="/article/RPC%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86%E4%B8%80.html"/>
      <url>/article/RPC%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86%E4%B8%80.html</url>
      
        <content type="html"><![CDATA[<h1 id="什么是-RPC？"><a href="#什么是-RPC？" class="headerlink" title="什么是 RPC？"></a>什么是 RPC？</h1><p>我知道你肯定不喜欢听概念，我也是这样，看书的时候一看到概念就直接略过。不过，到后来，我才发现，“定义”是一件多么伟大的事情。当我们能够用一句话把一个东西给定义出来的时候，侧面也说明你已经彻底理解这事了，不仅知道它要解决什么问题，还要知道它的边界。所以，你可以先停下来想想，什么是 RPC。</p><p>RPC 的全称是 Remote Procedure Call，即远程过程调用。简单解读字面上的意思，远程肯定是指要跨机器而非本机，所以需要用到网络编程才能实现，但是不是只要通过网络通信访问到另一台机器的应用程序，就可以称之为 RPC 调用了？显然并不够。</p><p>我理解的 RPC 是帮助我们屏蔽网络编程细节，实现调用远程方法就跟调用本地（同一个项目中的方法）一样的体验，我们不需要因为这个方法是远程调用就需要编写很多与业务无关的代码。</p><p>这就好比建在小河上的桥一样连接着河的两岸，如果没有小桥，我们需要通过划船、绕道等其他方式才能到达对面，但是有了小桥之后，我们就能像在路面上一样行走到达对面，并且跟在路面上行走的体验没有区别。所以<strong>我认为，RPC 的作用就是体现在这样两个方面：</strong></p><ul><li>屏蔽远程调用跟本地调用的区别，让我们感觉就是调用项目内的方法；</li><li>隐藏底层网络通信的复杂性，让我们更专注于业务逻辑。</li></ul><h1 id="RPC-通信流程"><a href="#RPC-通信流程" class="headerlink" title="RPC 通信流程"></a>RPC 通信流程</h1><p>理解了什么是 RPC，接下来我们讲下 RPC 框架的通信流程，方便我们进一步理解 RPC。</p><p>如前面所讲，RPC 能帮助我们的应用透明地完成远程调用，发起调用请求的那一方叫做调用方，被调用的一方叫做服务提供方。为了实现这个的目标，我们就需要在 RPC 框架里面对整个通信细节进行封装，<strong>那一个完整的 RPC 会涉及到哪些步骤呢？</strong></p><span id="more"></span><p>我们已经知道 RPC 是一个远程调用，那肯定就需要通过网络来传输数据，并且 RPC 常用于业务系统之间的数据交互，需要保证其可靠性，所以 RPC 一般默认采用 TCP 来传输。我们常用的 HTTP 协议也是建立在 TCP 之上的。</p><p>网络传输的数据必须是二进制数据，但调用方请求的出入参数都是对象。对象是肯定没法直接在网络中传输的，需要提前把它转成可传输的二进制，并且要求转换算法是可逆的，这个过程我们一般叫做“序列化”。</p><p>调用方持续地把请求参数序列化成二进制后，经过 TCP 传输给了服务提供方。服务提供方从 TCP 通道里面收到二进制数据，那如何知道一个请求的数据到哪里结束，是一个什么类型的请求呢？</p><p>在这里我们可以想想高速公路，它上面有很多出口，为了让司机清楚地知道从哪里出去，管理部门会在路上建立很多指示牌，并在指示牌上标明下一个出口是哪里、还有多远。那回到数据包识别这个场景，我们是不是也可以建立一些“指示牌”，并在上面标明数据包的类型和长度，这样就可以正确的解析数据了。确实可以，并且我们把数据格式的约定内容叫做“协议”。大多数的协议会分成两部分，分别是数据头和消息体。数据头一般用于身份识别，包括协议标识、数据大小、请求类型、序列化类型等信息；消息体主要是请求的业务参数信息和扩展属性等。</p><p>根据协议格式，服务提供方就可以正确地从二进制数据中分割出不同的请求来，同时根据请求类型和序列化类型，把二进制的消息体逆向还原成请求对象。这个过程叫作“反序列化”。</p><p>服务提供方再根据反序列化出来的请求对象找到对应的实现类，完成真正的方法调用，然后把执行结果序列化后，回写到对应的 TCP 通道里面。调用方获取到应答的数据包后，再反序列化成应答对象，这样调用方就完成了一次 RPC 调用。</p><p><strong>那上述几个流程就组成了一个完整的 RPC 吗？</strong></p><p>在我看来，还缺点东西。因为对于研发人员来说，这样做要掌握太多的 RPC 底层细节，需要手动写代码去构造请求、调用序列化，并进行网络调用，整个 API 非常不友好。</p><p>那我们有什么办法来简化 API，屏蔽掉 RPC 细节，让使用方只需要关注业务接口，像调用本地一样来调用远程呢？</p><p>如果你了解 Spring，一定对其 AOP 技术很佩服，其核心是采用动态代理的技术，通过字节码增强对方法进行拦截增强，以便于增加需要的额外处理逻辑。其实这个技术也可以应用到 RPC 场景来解决我们刚才面临的问题。</p><p>由服务提供者给出业务接口声明，在调用方的程序里面，RPC 框架根据调用的服务接口提前生成动态代理实现类，并通过依赖注入等技术注入到声明了该接口的相关业务逻辑里面。该代理实现类会拦截所有的方法调用，在提供的方法处理逻辑里面完成一整套的远程调用，并把远程调用结果返回给调用方，这样调用方在调用远程方法的时候就获得了像调用本地接口一样的体验。</p><p>到这里，一个简单版本的 RPC 框架就实现了。我把整个流程都画出来了，供你参考：</p><p><img src="/assets/20211121132026-2s2dm0r.jpe"></p><h1 id="RPC-协议"><a href="#RPC-协议" class="headerlink" title="RPC 协议"></a>RPC 协议</h1><p>我们知道只有二进制才能在网络中传输，所以 RPC 请求在发送到网络中之前，他需要把方法调用的请求参数转成二进制；转成二进制后，写入本地 Socket 中，然后被网卡发送到网络设备中。</p><p>但在传输过程中，RPC 并不会把请求参数的所有二进制数据整体一下子发送到对端机器上，中间可能会拆分成好几个数据包，也可能会合并其他请求的数据包（合并的前提是同一个 TCP 连接上的数据），至于怎么拆分合并，这其中的细节会涉及到系统参数配置和 TCP 窗口大小。对于服务提供方应用来说，他会从 TCP 通道里面收到很多的二进制数据，那这时候怎么识别出哪些二进制是第一个请求的呢？</p><p>这就好比让你读一篇没有标点符号的文章，你要怎么识别出每一句话到哪里结束呢？很简单啊，我们加上标点，完成断句就好了。</p><p>同理在 RPC 传输数据的时候，为了能准确地“断句”，我们也必须在应用发送请求的数据包里面加入“句号”，这样才能帮我们的接收方应用从数据流里面分割出正确的数据。这个数据包里面的句号就是消息的边界，用于标示请求数据的结束位置。举个具体例子，调用方发送 AB、CD、EF 3 个消息，如果没有边界的话，接收端就可能收到 ABCDEF 或者 ABC、DEF 这样的消息，这就会导致接收的语义跟发送的时候不一致了。</p><p>RPC 相对于 HTTP 的用处，RPC 更多的是负责应用间的通信，所以性能要求相对更高，所以 RPC 会选择设计更紧凑的私有协议。</p><p>对于服务提供方来说，他是不知道这个协议体里面的二进制数据是通过哪种序列化方式生成的。如果不能知道调用方用的序列化方式，即使服务提供方还原出了正确的语义，也并不能把二进制还原成对象，那服务提供方收到这个数据后也就不能完成调用了。因此我们需要把序列化方式单独拿出来，类似协议长度一样用固定的长度存放，这些需要固定长度存放的参数我们可以统称为“协议头”，这样整个协议就会拆分成两部分：协议头和协议体。</p><p>在协议头里面，我们除了会放协议长度、序列化方式，还会放一些像协议标示、消息 ID、消息类型这样的参数，而协议体一般只放请求接口方法、请求的业务参数值和一些扩展属性。这样一个完整的 RPC 协议大概就出来了，协议头是由一堆固定的长度参数组成，而协议体是根据请求接口和参数构造的，长度属于可变的，具体协议如下图所示：</p><p><img src="/assets/20211121132725-zxolcvc.jpe" title="定长协议"></p><h2 id="可扩展的协议"><a href="#可扩展的协议" class="headerlink" title="可扩展的协议"></a>可扩展的协议</h2><p>服务提供方收到一个过期请求，这个过期是说服务提供方收到的这个请求的时间大于调用方发送的时间和配置的超时时间，既然已经过期，就没有必要接着处理，直接返回一个超时就好了。那要实现这个功能，就要在协议里面传递这个配置的超时时间，那如果之前协议里面没有加超时时间参数的话，我们现在把这个超时时间加到协议体里面是不是就有点重了呢？显然，会加重 CPU 的消耗。</p><p>所以为了保证能平滑地升级改造前后的协议，我们有必要设计一种支持可扩展的协议。其关键在于让协议头支持可扩展，扩展后协议头的长度就不能定长了。那要实现读取不定长的协议头里面的内容，在这之前肯定需要一个固定的地方读取长度，所以我们需要一个固定的写入协议头的长度。整体协议就变成了三部分内容：固定部分、协议头内容、协议体内容，前两部分我们还是可以统称为“协议头”，具体协议如下：</p><p><img src="/assets/20211121132950-dccoi22.jpe" title="可扩展协议"></p><h1 id="序列化"><a href="#序列化" class="headerlink" title="序列化"></a>序列化</h1><p>网络传输的数据必须是二进制数据，但调用方请求的出入参数都是对象。对象是不能直接在网络中传输的，所以我们需要提前把它转成可传输的二进制，并且要求转换算法是可逆的，这个过程我们一般叫做“序列化”。反之，称为“反序列化”。</p><p>这两个过程如下图所示：</p><p><img src="/assets/20211121133122-pz6yyna.jpe" title="序列化与反序列化"></p><p><strong>总结来说，</strong>序列化就是将对象转换成二进制数据的过程，而反序列就是反过来将二进制转换为对象的过程。</p><h2 id="有哪些常用的序列化"><a href="#有哪些常用的序列化" class="headerlink" title="有哪些常用的序列化"></a>有哪些常用的序列化</h2><h3 id="JDK-原生序列化"><a href="#JDK-原生序列化" class="headerlink" title="JDK 原生序列化"></a>JDK 原生序列化</h3><p>那么 JDK 的序列化过程是怎样完成的呢？我们看下下面这张图：</p><p><img src="/assets/20211121133254-0ehh5fa.jpe" title="ObjectOutputStream序列化过程图"></p><p>序列化过程就是在读取对象数据的时候，不断加入一些特殊分隔符，这些特殊分隔符用于在反序列化过程中截断用。</p><ul><li>头部数据用来声明序列化协议、序列化版本，用于高低版本向后兼容</li><li>对象数据主要包括类名、签名、属性名、属性类型及属性值，当然还有开头结尾等数据，除了属性值属于真正的对象值，其他都是为了反序列化用的元数据</li><li>存在对象引用、继承的情况下，就是递归遍历“写对象”逻辑</li></ul><p><strong>实际上任何一种序列化框架，核心思想就是设计一种序列化协议</strong>，将对象的类型、属性类型、属性值一一按照固定的格式写到二进制字节流中来完成序列化，再按照固定的格式一一读出对象的类型、属性类型、属性值，通过这些信息重新创建出一个新的对象，来完成反序列化。</p><h3 id="Protobuf"><a href="#Protobuf" class="headerlink" title="Protobuf"></a>Protobuf</h3><p>Protobuf 是 Google 公司内部的混合语言数据标准，是一种轻便、高效的结构化数据存储格式，可以用于结构化数据序列化，支持 Java、Python、C++、Go 等语言。Protobuf 使用的时候需要定义 IDL（Interface description language），然后使用不同语言的 IDL 编译器，生成序列化工具类，它的优点是：</p><ul><li>序列化后体积小；</li><li>IDL 能清晰地描述语义，所以足以帮助并保证应用程序之间的类型不会丢失，无需类似 XML 解析器；</li><li>序列化反序列化速度很快，不需要通过反射获取类型；</li><li>消息格式升级和兼容性不错，可以做到向后兼容。</li></ul><h3 id="其他序列化协议"><a href="#其他序列化协议" class="headerlink" title="其他序列化协议"></a>其他序列化协议</h3><p>JSON、Hessian、thrift、kryo等</p><h2 id="序列化协议的选择"><a href="#序列化协议的选择" class="headerlink" title="序列化协议的选择"></a>序列化协议的选择</h2><p>首先你可能想到的是性能和效率，另外还有空间开销，也就是序列化之后的二进制数据的体积大小。序列化后的字节数据体积越小，网络传输的数据量就越小，传输数据的速度也就越快，由于 RPC 是远程调用，那么网络传输的速度将直接关系到请求响应的耗时。</p><p>序列化协议的通用性和兼容性也是我们需要考虑的。比如某个类型为集合类的入参服务调用者不能解析了，服务提供方将入参类加一个属性之后服务调用方不能正常调用，升级了 RPC 版本后发起调用时报序列化异常了。</p><p>下图是序列化协议选择维度优先级：</p><p><img src="/assets/20211121133926-0410u26.jpe"></p><h2 id="RPC-使用序列化时要注意的问题"><a href="#RPC-使用序列化时要注意的问题" class="headerlink" title="RPC 使用序列化时要注意的问题"></a>RPC 使用序列化时要注意的问题</h2><p>了解了在 RPC 框架中如何选择序列化，那么我们在使用过程中需要注意哪些序列化上的问题呢？</p><p>我刚才讲过，在 RPC 的运营中，我遇到的最多的问题就是序列化问题了，除了早期 RPC 框架本身出现的问题以外，大多数问题都是使用方使用不正确导致的，接下来我们就盘点下这些高频出现的人为问题。</p><p><strong>对象构造得过于复杂：</strong>属性很多，并且存在多层的嵌套，比如 A 对象关联 B 对象，B 对象又聚合 C 对象，C 对象又关联聚合很多其他对象，对象依赖关系过于复杂。序列化框架在序列化与反序列化对象时，对象越复杂就越浪费性能，消耗 CPU，这会严重影响 RPC 框架整体的性能；另外，对象越复杂，在序列化与反序列化的过程中，出现问题的概率就越高。</p><p><strong>对象过于庞大：</strong>我经常遇到业务过来咨询，为啥他们的 RPC 请求经常超时，排查后发现他们的入参对象非常得大，比如为一个大 List 或者大 Map，序列化之后字节长度达到了上兆字节。这种情况同样会严重地浪费了性能、CPU，并且序列化一个如此大的对象是很耗费时间的，这肯定会直接影响到请求的耗时。</p><p><strong>使用序列化框架不支持的类作为入参类：</strong>比如 Hessian 框架，他天然是不支持 LinkHashMap、LinkedHashSet 等，而且大多数情况下最好不要使用第三方集合类，如 Guava 中的集合类，很多开源的序列化框架都是优先支持编程语言原生的对象。因此如果入参是集合类，应尽量选用原生的、最为常用的集合类，如 HashMap、ArrayList。</p><p><strong>对象有复杂的继承关系：</strong>大多数序列化框架在序列化对象时都会将对象的属性一一进行序列化，当有继承关系时，会不停地寻找父类，遍历属性。就像问题 1 一样，对象关系越复杂，就越浪费性能，同时又很容易出现序列化上的问题。</p>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
          <category> PRC </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RPC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ES最佳实践</title>
      <link href="/article/ES%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5.html"/>
      <url>/article/ES%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5.html</url>
      
        <content type="html"><![CDATA[<h2 id="集群配置最佳实践"><a href="#集群配置最佳实践" class="headerlink" title="集群配置最佳实践"></a>集群配置最佳实践</h2><h3 id="1-磁盘选择"><a href="#1-磁盘选择" class="headerlink" title="1.磁盘选择"></a>1.磁盘选择</h3><ul><li>尽可能使用使用 SSD，ES 最大的瓶颈往往是磁盘读写性能，SSD 要比 SATA 查询快 5-10 倍，所以查询要求高的业务建议选择 SSD 或者 PCIE，查询要求不那么高的业务可以选择 SATA</li><li>对于数据节点建议使用单机器 500G 以上的磁盘</li><li>对于协调节点，200G 足矣，协调节点不存数据，只做转发和聚合</li></ul><h3 id="2-内存选择"><a href="#2-内存选择" class="headerlink" title="2.内存选择"></a>2.内存选择</h3><ul><li>尽可能选择 16G 以上，由于 ES 的段文件(索引文件)存储在缓存中，尽量满足所有的段文件都存在缓存中，提高查询的效率</li><li>ES JVM 配置机器一半的内存，但是不要超过 32G</li><li>内存和磁盘 1：10</li></ul><h3 id="3-集群角色配置"><a href="#3-集群角色配置" class="headerlink" title="3.集群角色配置"></a>3.集群角色配置</h3><ul><li>数据节点和协调节点隔离，避免协调节点因数据问题 down 机之后导致整个集群崩溃</li><li>集群尽量配置固定数量的协调节点（一般 3 个足矣），数据节点可以扩展</li></ul><h3 id="4-分片和副本设置"><a href="#4-分片和副本设置" class="headerlink" title="4.分片和副本设置"></a>4.分片和副本设置</h3><ul><li>每个数据节点上都尽量分配某个索引的一个分片，使数据足够均匀</li><li>每个索引分片不要超过 30G</li><li>单节点数据控制再 2T 以内<span id="more"></span></li></ul><h3 id="5-调大-refresh-interval-调高"><a href="#5-调大-refresh-interval-调高" class="headerlink" title="5.调大 refresh interval 调高"></a>5.调大 refresh interval 调高</h3><p>ES 的 refresh 操作：是将 index-buffer 中文档（document）解析完成的 segment 写到 filesystem cache 中的过程</p><ol><li><p>ES 默认每个分片每秒钟都会进行一次 refresh，刷新的过程其实就是文档从索引到被搜索的过程，刷新后会生成新的段，这会产生大量的段文件</p></li><li><p>如果业务对数据的实时性要求不高，可以调高</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">PUT /twitter/_settings</span><br><span class="line"></span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;index&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;refresh_interval&quot;</span><span class="punctuation">:</span><span class="string">&quot;1s&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure></li></ol><h3 id="6-translog-同步改异步"><a href="#6-translog-同步改异步" class="headerlink" title="6.translog 同步改异步"></a>6.translog 同步改异步</h3><p>translog 的作用是用于恢复数据，数据在被索引之前会被先加入至 translog 中，默认情况下 translog 是每写一次就刷盘一次，可以改成异步刷新</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">PUT /my_index/_settings</span><br><span class="line"></span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;index.translog.durability&quot;</span><span class="punctuation">:</span><span class="string">&quot;async&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;index.translog.sync_interval&quot;</span><span class="punctuation">:</span><span class="string">&quot;5s&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><h3 id="7-定期进行段文件合并"><a href="#7-定期进行段文件合并" class="headerlink" title="7.定期进行段文件合并"></a>7.定期进行段文件合并</h3><p>注意 ES 得索引倒排索引文件是存在 segment 中，segment 是存在内存中，由于每次 refresh 都会生产新的 segment，如果 segment 过多会消耗较大内存，定期进行段合并有几个好处</p><ol><li>减少内存消耗</li><li>加快查询性能，每次搜索请求都需要依次检查每个段。段越多，查询越慢。</li><li>合并段的同时会把释放已删除的索引空间，业务如果使用 delete by id 进行索引删除，es 只是把数据标记为已删除，并没有释放空间，在segment 合并时会把这些数据进行清理<br>如下：这里的max_num_segments 是希望最终合并成多少个段<br>POST &#x2F;twitter&#x2F;_forcemerge&#x2F;max_num_segments&#x3D;1</li></ol><h3 id="8-使用索引模板"><a href="#8-使用索引模板" class="headerlink" title="8.使用索引模板"></a>8.使用索引模板</h3><p>如果索引未来的增长比较快，并且存在明显的 冷热区分(旧索引访问热度低或者无访问)，那烦请使用索引模板，按日期方式创建，索引，这样对应旧索引可以方便的删除或者隔离</p><h2 id="写入配置最佳实践"><a href="#写入配置最佳实践" class="headerlink" title="写入配置最佳实践"></a>写入配置最佳实践</h2><h3 id="一、索引模板的使用"><a href="#一、索引模板的使用" class="headerlink" title="一、索引模板的使用"></a>一、索引模板的使用</h3><h4 id="1-1-评估是否需要模板"><a href="#1-1-评估是否需要模板" class="headerlink" title="1.1 评估是否需要模板"></a>1.1 评估是否需要模板</h4><p>在新建一个索引之前，要判断索引未来的数据变化趋势，如果索引数据量是固定的，那可以不使用模板，如果未来数据会不断增加，那强烈建议使用模板定期创建索引</p><ul><li>模板的使用可以减少每次创建索引的成本</li><li>定期创建索引可以有效减少单个索引的大小，利于后续对历史数据清理和归档，以及做数据冷热隔离</li><li>同时小索引比较容易迁移数据</li></ul><h4 id="1-2-基于时间创建索引"><a href="#1-2-基于时间创建索引" class="headerlink" title="1.2 基于时间创建索引"></a>1.2 基于时间创建索引</h4><ul><li>按照月份或者年份或者天来创建索引</li><li>确保单个分片不要超过 20G，一半单个索引 5 个分片，也就是最好索引不要超过 100G，业务根据数据增量情况确定创建索引的时间周期</li></ul><h3 id="二、索引-Mapping-设计"><a href="#二、索引-Mapping-设计" class="headerlink" title="二、索引 Mapping 设计"></a>二、索引 Mapping 设计</h3><h4 id="2-1-Schema-设计"><a href="#2-1-Schema-设计" class="headerlink" title="2.1 Schema 设计"></a>2.1 Schema 设计</h4><ol><li>尽管 Elasticsearch 支持半结构化数据，但是在实际使用中还是应该尽最大可能对数据结构加以控制。</li><li>因为 Elasticsearch 不支持 JOIN 操作，所以 Schema 应该尽量扁平化，减少嵌套。</li><li>对于只需要做精确匹配的字段，应该设置为不做分词，避免使用 text 类型，5.5 以上得版本中通过 type&#x3D;keyword 来设定。</li><li>如果字段类型无需排序以及分词，使用 keyword 性能更好</li></ol><h4 id="2-2-参数设定"><a href="#2-2-参数设定" class="headerlink" title="2.2 参数设定"></a>2.2 参数设定</h4><ol><li><p><strong>index.mapping.total_fields.limit</strong>：一个索引中能定义的字段的最大数量，默认是 1000</p></li><li><p><strong>index.mapping.depth.limit</strong>：字段的最大深度，以内部对象的数量来计算，默认是 20</p></li><li><p><strong>index.mapping.nested_fields.limit</strong>：索引中嵌套字段的最大数量，默认是 50</p></li><li><p><strong>_source 字段：</strong>如果_source&#x3D;true，Elasticsearch 会将整个 JSON 数据也存储下来。如果你的业务中，不需要查询原始数据，只需要根据索引来过滤然后做聚合查询，那么可以将其设置为 false，同样可以节省磁盘空间、提高性能。</p></li><li><p><strong>dynamic 字段：strict，true，false</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">PUT /my_index</span><br><span class="line">&#123;</span><br><span class="line">    &quot;mappings&quot;:&#123;</span><br><span class="line">        &quot;my_type&quot;:&#123;</span><br><span class="line">            &quot;dynamic&quot;:&quot;strict&quot;,</span><br><span class="line">            &quot;properties&quot;:&#123;</span><br><span class="line">                &quot;title&quot;:&#123;</span><br><span class="line">                    &quot;type&quot;:&quot;string&quot;</span><br><span class="line">                &#125;,</span><br><span class="line">                &quot;stash&quot;:&#123;</span><br><span class="line">                    &quot;type&quot;:&quot;object&quot;,</span><br><span class="line">                    &quot;dynamic&quot;:true</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h3 id="三、别名用法"><a href="#三、别名用法" class="headerlink" title="三、别名用法"></a>三、别名用法</h3><h4 id="3-1-无缝切换索引"><a href="#3-1-无缝切换索引" class="headerlink" title="3.1 无缝切换索引"></a>3.1 无缝切换索引</h4><p>在查询数据时，Elasticsearch 会自动检测请求的 Path 是否是 Alias，是的话就会从其关联的 Index 中查询数据，并且做到无缝切换，客户端无感知，对于新老索引的切换非常适用</p><h4 id="3-2-良好的数据扩展性"><a href="#3-2-良好的数据扩展性" class="headerlink" title="3.2 良好的数据扩展性"></a>3.2 良好的数据扩展性</h4><p>一个别名可以对应多个索引，指定别名查询便可以满足多个索引中的数据查询，对于按时间创建索引得场景非常试用</p><p><img src="/assets/20210103221825-fk9qb3g-es_alias.png"></p><h3 id="四、数据写入磁盘过程"><a href="#四、数据写入磁盘过程" class="headerlink" title="四、数据写入磁盘过程"></a>四、数据写入磁盘过程</h3><p><img src="/assets/20210103221851-eromhq0-es_insert.png"></p><h3 id="五、写入索引配置建议"><a href="#五、写入索引配置建议" class="headerlink" title="五、写入索引配置建议"></a>五、写入索引配置建议</h3><ol><li><p>bulk 写入，但是要控制写入的量，一次性不能过多，尽量先压测，建议每批提交 5-15M 的数据</p></li><li><p>尽量使用 es 自动生成的document id，</p></li><li><p>增加 refresh 间隔，如果在写入期间对实时性要求不高，可以增加 refresh 的间隔</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">PUT /twitter/_settings</span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;index&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;refresh_interval&quot;</span><span class="punctuation">:</span><span class="string">&quot;1s&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure></li></ol><p>4.写入期间将副本数设置为 0，写完后再修改副数可以提高写入效率</p><p>5.适当增加 index buffer 的值，如上图，写入期间，数据会先缓存在 index buffer 中，然后再定期 flush 到磁盘，所以适当增加这个 buffer 得值，也能提高写入效率，indices.memory.index_buffer_size:15%，该值在 elasticsearch.yml 中设置</p><p>6.副本数量不建议太大，因为写入数据后，主分片要同步数据至副本会消耗大量 IO，影响写的性能。</p><h2 id="查询配置最佳实践"><a href="#查询配置最佳实践" class="headerlink" title="查询配置最佳实践"></a>查询配置最佳实践</h2><h3 id="1、字段类型选择"><a href="#1、字段类型选择" class="headerlink" title="1、字段类型选择"></a>1、字段类型选择</h3><ol><li>字符串类型，如果需要分词则选择 text，会对每个词建立倒排索引，存储成本较高，所以无需分词得情况请使用 keyword</li><li>数值类型，尽量选择贴合实际数值大小得类型，比如价格，使用 float 或者 double,不需要范围查询尽量使用可我、yword</li></ol><h3 id="2、查询语句使用"><a href="#2、查询语句使用" class="headerlink" title="2、查询语句使用"></a>2、查询语句使用</h3><ol><li><p>避免使用嵌套类型,nested 或者 object，使用嵌套类型性能会慢 10 几倍，尽量把逻辑处理放在客户端代码</p></li><li><p>避免使用父子关系，parent-child，使用父子类型性能会慢百倍以上</p></li><li><p>控制返回结果集，size 不要超过 1000，这是引发 full gc 常见得原因</p></li><li><p>严禁使用通配符，比如<em>es</em></p></li><li><p>避免使用查询时的 script 计算</p></li><li><p>尽量使用 query-bool-filter， filter 的缓存机制会使的检索更快</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;query&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;filtered&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;query&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;match&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;email&quot;</span><span class="punctuation">:</span><span class="string">&quot;business opportunity&quot;</span></span><br><span class="line">                <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;filter&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;term&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;folder&quot;</span><span class="punctuation">:</span><span class="string">&quot;inbox&quot;</span></span><br><span class="line">                <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure></li><li><p>控制聚合的数量，减少内存的开销</p></li><li><p>控制返回字段，_source 过滤,只返回业务相关的字段，减少 IO 开销，如下，搜索返回结果中希望包含 obj1 核 obj2 开头得字段</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;query&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;filtered&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;query&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;match&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;email&quot;</span><span class="punctuation">:</span><span class="string">&quot;business opportunity&quot;</span></span><br><span class="line">                <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;filter&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;term&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;folder&quot;</span><span class="punctuation">:</span><span class="string">&quot;inbox&quot;</span></span><br><span class="line">                <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>9.避免在高峰期进行段文件合并，段文件合并会消耗大量 IO，影响查询和读写</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 数据工程 </category>
          
          <category> ES </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ES </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ES搜索原理剖析</title>
      <link href="/article/ES%E6%90%9C%E7%B4%A2%E5%8E%9F%E7%90%86%E5%89%96%E6%9E%90.html"/>
      <url>/article/ES%E6%90%9C%E7%B4%A2%E5%8E%9F%E7%90%86%E5%89%96%E6%9E%90.html</url>
      
        <content type="html"><![CDATA[<h2 id="一、索引建立"><a href="#一、索引建立" class="headerlink" title="一、索引建立"></a>一、索引建立</h2><h3 id="1-1-数据类型"><a href="#1-1-数据类型" class="headerlink" title="1.1 数据类型"></a>1.1 数据类型</h3><p>搜索的前提是索引已经建立好，ES 中的数据分为 2 类</p><ul><li>精确值：如 id，ip 等，精确值只能精确匹配，适用于 term 查询，查询的时候是根据二进制来比较</li><li>全文：指文本内容，比如日志，邮件内容，url 等，适用于 match 查询，只能查出看起来像的结果</li></ul><p>以下对五条 doc 建立索引</p><table><thead><tr><th>Name</th><th>Age</th><th>Address</th></tr></thead><tbody><tr><td>Alan</td><td>33</td><td>West Street Ca USA</td></tr><tr><td>Alice</td><td>13</td><td>East Street La  USA</td></tr><tr><td>Brad</td><td>19</td><td>Suzhou JiangSu China</td></tr><tr><td>Alice</td><td>15</td><td>Nanjing JiangSu China</td></tr><tr><td>Alan</td><td>11</td><td>Changning Shanghai China</td></tr></tbody></table><h3 id="1-2-索引建立流程"><a href="#1-2-索引建立流程" class="headerlink" title="1.2 索引建立流程"></a><strong>1.2 索引建立流程</strong></h3><span id="more"></span><p><img src="/assets/20210124120810-o5g3uxu-search.png"></p><p><strong>索引结构如下：</strong></p><p><img src="/assets/20210124120912-etcz3c3-doc_index.png"></p><h2 id="二、执行搜索"><a href="#二、执行搜索" class="headerlink" title="二、执行搜索"></a>二、执行搜索</h2><ul><li>如果是精确值搜索，比如搜索 Id 为 20002，直接去正排和倒排索引中查找匹配的文档</li><li>如果是全文查询，则需要先对检索内容进行分析，产生 token 词条，再根据 token 词条去正排和倒排索引中匹配相应的文档</li></ul><p><img src="/assets/20210124120948-zked4jg-query_search.png"></p><h2 id="三、分布式搜索"><a href="#三、分布式搜索" class="headerlink" title="三、分布式搜索"></a>三、分布式搜索</h2><p>上述讲了索引是如何建立以及数据是如何被检索的，下面看看，一个分布式集群中，用户发起一次检索请求，如何得到结果的</p><h3 id="3-1-分布式集群组成"><a href="#3-1-分布式集群组成" class="headerlink" title="3.1 分布式集群组成"></a>3.1 分布式集群组成</h3><p>先看下一个集群的组成如下：一个集群有三个节点，集群上的索引有 3 个分片，每个分片有一个副本，</p><p><img src="/assets/20210124121007-j4sgycq-es_node.png"></p><h3 id="3-2-分片组成"><a href="#3-2-分片组成" class="headerlink" title="3.2 分片组成"></a>3.2 分片组成</h3><p>如图，一个分片的主要组成如下</p><p><img src="/assets/20210124121027-snzblex-es_shard.png"></p><p><strong>以一个 40G 索引为例子，如下：</strong></p><table><thead><tr><th>文件类型</th><th>文件意义</th><th>磁盘占比</th></tr></thead><tbody><tr><td>.tim</td><td>倒排索引的数据文件，索引具体内容，包含词项词典，存储术语信息</td><td>较大 3G</td></tr><tr><td>.tip</td><td>倒排索引的索引文件</td><td>8M</td></tr><tr><td>.fdx</td><td>正排存储文件的元数据信息</td><td>1.2M</td></tr><tr><td>.fdt</td><td>存储了正排索引的数据，写入的原文件在这里</td><td>较大，1.5G</td></tr><tr><td>.pos</td><td>全文索引的字段，会有该文件，保存了 term 在 doc 中的位置</td><td>800M</td></tr><tr><td>.dvd，.dvm</td><td>lucene 的 docvalues 文件，即数据的列式存储，用作聚合和排序</td><td>42M</td></tr><tr><td>.doc</td><td>保存了每个 term 的 doc id 列表和 term 在 doc 中的词频</td><td>占比较大 300M</td></tr><tr><td>.nvd，.nvm</td><td>文件保存索引字段加权数据</td><td>特别小 8M</td></tr><tr><td>segments_N</td><td>保存了索引包含的多少段，每个段包含多少文档</td><td></td></tr><tr><td>.cfs</td><td>在 segment 小的时候，segment 的所有文件内容都保存在 cfs 文件中，cfe 文件保存了 lucene 各文件在 cfs 文件的位置信息</td><td></td></tr></tbody></table><p>最核心的文件</p><ul><li>fdx,fdt 存储正排索引数据，即 FiledData</li></ul><table><thead><tr><th>Doc</th><th>Terms（Address）</th></tr></thead><tbody><tr><td>Doc1</td><td>USA</td></tr><tr><td>Doc1</td><td>CA</td></tr><tr><td>Doc1</td><td>WestStreet</td></tr><tr><td>Doc2</td><td>USA</td></tr><tr><td>Doc2</td><td>LA</td></tr><tr><td>Doc3</td><td>China</td></tr><tr><td>Doc3</td><td>Jiangsu</td></tr><tr><td>Doc3</td><td>Suzhou</td></tr><tr><td>Doc4</td><td>China</td></tr><tr><td>Doc4</td><td>Jiangsu</td></tr><tr><td>Doc4</td><td>Nanjing</td></tr></tbody></table><ul><li>.dvd,.dvm 存储列文件，即 docValue，如下为一个列式存储结构</li></ul><table><thead><tr><th>Doc</th><th>Terms（Age）</th></tr></thead><tbody><tr><td>Doc1</td><td>33</td></tr><tr><td>Doc2</td><td>13</td></tr><tr><td>Doc3</td><td>19</td></tr><tr><td>Doc4</td><td>15</td></tr><tr><td>Doc5</td><td>11</td></tr></tbody></table><ul><li>tim,tip 存储倒排索引数据根据，结构如下：</li></ul><p><img src="/assets/20210124121053-axsixam-es_tim.png"></p><h3 id="3-3-分布式搜索过程"><a href="#3-3-分布式搜索过程" class="headerlink" title="3.3 分布式搜索过程"></a>3.3 分布式搜索过程</h3><p>默认 ES 的搜索过程分为两阶段 Query 阶段和 Fetch 阶段，当然还有 Query And Fetch 查询，两种方式优缺点如下：</p><h4 id="3-3-1-query-then-fetch（默认的搜索方式）"><a href="#3-3-1-query-then-fetch（默认的搜索方式）" class="headerlink" title="3.3.1 query then fetch（默认的搜索方式）"></a><strong>3.3.1 query then fetch</strong>（默认的搜索方式）</h4><p>如果你搜索时，没有指定搜索方式，就是使用的这种搜索方式。这种搜索方式，大概分两个步骤，第一步，先向所有的 shard 发出请求，各分片只返回排序和排名相关的信息（注意，不包括文档 document)，然后按照各分片返回的分数进行重新排序和排名，取前 size 个文档。</p><p>然后进行第二步，去相关的 shard 取 document。这种方式返回的 document 与用户要求的 size 是相等的。</p><ul><li>Query 阶段：得到目标结果对应的 doc Id 和排序信息，并且做聚合</li><li>Fetch 阶段：根据 doc Id 列表查找对应的数据内容</li></ul><h4 id="3-3-2-query-and-fetch"><a href="#3-3-2-query-and-fetch" class="headerlink" title="3.3.2 query and fetch"></a><strong>3.3.2 query and fetch</strong></h4><p>向索引的所有分片（shard）都发出查询请求，各分片返回的时候把查询时指定的 size 元素文档（document）和计算后的排名信息一起返回。这种搜索方式是最快的。因为相比下面的几种搜索方式，这种查询方法只需要去 shard 查询一次。但是各个 shard 返回的结果的数量之和可能是用户要求的 size 的 n 倍。</p><h4 id="3-3-3-搜索流程图"><a href="#3-3-3-搜索流程图" class="headerlink" title="3.3.3 搜索流程图"></a>3.3.3 搜索流程图</h4><p>以下为 Query Then Fetch 流程图：</p><p><img src="/assets/20210124121332-x6qqblq-query_fetch.png"></p><p>如上图，Query 阶段只是确定了要取哪些数据，但是并没有取具体的数据，Fetch 阶段才会去抓取具体的数据，最关键的一部调用 lucene 查询做了些什么呢？</p><p><img src="/assets/20210124122335-ygxej3j-lucene_fetch.png"></p><h2 id="四、ES-内存组成"><a href="#四、ES-内存组成" class="headerlink" title="四、ES 内存组成"></a>四、ES 内存组成</h2><p>我们看到 ES 查询会优先查询 Cache 模块，那 ES Cache 模块中到底有哪些数据呢？如图是 ES Heap 的主要组成部分，其中 Lucene 的段文件会存在堆外内存，所以 ES 节点建议 50% 的内存给 ES JVM，前提是不超过 32G，剩下 50% 留给 Lucene 作为堆外内存</p><p><img src="/assets/20210124122356-94h98sl-es_jvm.png"></p><h3 id="4-1-Query-Cache（Filter-Cache）"><a href="#4-1-Query-Cache（Filter-Cache）" class="headerlink" title="4.1 Query Cache（Filter Cache）"></a>4.1 Query Cache（Filter Cache）</h3><p>顾名思义，就是查询缓存，在 2.x 版本的 ES 中叫做 Filter Cache，就是使用 <strong>filter 过滤器</strong>进行查询的结果会被缓存在这里，常用的 terms，range 过滤器都会被缓存，说明如下：</p><ul><li>Query Cache 采用 LRU 缓存失效策略</li><li>Query Cache 是节点级别的，每个节点上的所有分片共享一份缓存</li><li>Query Cache 实际缓存的是 Bitset（位图），一个 Query clause 对应一个 Bitset</li></ul><p>注意！缓存要生效，必须满足两个条件：</p><pre><code>a）查询对应的 segments 所持有的文档数必须大于 10000b）查询对应的 segments 所持有的文档数必须大于整个索引 size 的 3%</code></pre><h3 id="4-2-Request-Cache"><a href="#4-2-Request-Cache" class="headerlink" title="4.2 Request Cache"></a>4.2 Request Cache</h3><p>上述讲到的 QueryCache 是节点级别的，而这里 Request Cache 实际上<strong>分片级别</strong>的缓存，一次查询，会遍历多个多个节点上的分片，并且会在每个分片上执行查询，最终查询的结果会被汇总发送至协调节点，这里在分片上的结果集也会有被缓存，说明如下：</p><ul><li>默认 Request Cache 是关闭的</li><li>目前只会缓存查询中参数 size&#x3D;0 的请求，所以就不会缓存 hits 而是缓存 hits.total，aggregations 和 suggestions</li><li>每次索引 refresh 并且分片数据确实有改动，那 Request Cache 会自动失效</li><li>缓存的 Key 是整个 DSL 语句，只有 DSL 一样才能命中缓存</li></ul><h3 id="4-3-Index-Buffer"><a href="#4-3-Index-Buffer" class="headerlink" title="4.3 Index Buffer"></a>4.3 Index Buffer</h3><p>这个理解起来简单些，主要在索引写入的时候需要，索引写入的时候不会直接写到磁盘，而是先写到 Index Buffer，当其满了或者 refresh&#x2F;flush interval 到了，就会以 segment file 的形式写入到磁盘。</p><h3 id="4-4-Field-Data-Cache"><a href="#4-4-Field-Data-Cache" class="headerlink" title="4.4 Field Data Cache"></a>4.4 Field Data Cache</h3><h4 id="4-4-1-Field-的来源"><a href="#4-4-1-Field-的来源" class="headerlink" title="4.4.1 Field 的来源"></a>4.4.1 Field 的来源</h4><p>先引用 ES 官网的一段话如下：</p><p>Search needs to answer the question <em>“Which documents contain this term?”</em>, while sorting and aggregations need to answer a different question: <em>“What is the value of this field for <strong>this</strong> document?”</em>.</p><p>Most fields can use index-time, on-disk <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/doc-values.html">doc_values</a> for this data access pattern, but <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/text.html">text</a> fields do not support doc_values.</p><p>Instead, text fields use a query-time <strong>in-memory</strong> data structure called fielddata. This data structure is built on demand the first time that a field is used for aggregations, sorting, or in a script. It is built by reading the entire inverted index for each segment from disk, inverting the term ↔︎ document relationship, and storing the result in memory, in the JVM heap.</p><p>这里表达的意思：普通查询只需要知道目标文档在哪儿，而聚合或者排序查询还需要知道文档中某个字段的值是多少，对于部分词的字段，docValue 中会存储 docId_Value 的映射关系，这能满足聚合或排序，但是对于分词的字段(<strong>分词字段不支持 docValue</strong>)，要实现这种字段和 Value 的缓存，便有了 Filed Data</p><h4 id="4-4-2-Filed-Data-结构"><a href="#4-4-2-Filed-Data-结构" class="headerlink" title="4.4.2 Filed Data 结构"></a>4.4.2 Filed Data 结构</h4><p>Field Data 也是 DocId–Term 的映射，如图，当我们需要对 <strong>age 做平均</strong>的时候，只需要遍历 docId，根据 docId 找到对应的 age，然后求个平均，效率会很高</p><table><thead><tr><th><strong>Document</strong></th><th><strong>age</strong></th><th><strong>salary</strong></th></tr></thead><tbody><tr><td>doc1</td><td>22</td><td>3232</td></tr><tr><td>doc2</td><td>33</td><td>32323</td></tr><tr><td>doc3</td><td>32</td><td>32323</td></tr></tbody></table><h4 id="4-4-3-Field-Data-对比-Doc-Value"><a href="#4-4-3-Field-Data-对比-Doc-Value" class="headerlink" title="4.4.3 Field Data 对比 Doc Value"></a>4.4.3 Field Data 对比 Doc Value</h4><p>Doc Value 和 Field Data 实现的功能一直，不过 doc_value 不支持 text 类型，并且 doc_valu 在索引创建的时候就已经生成好了，具体对比如下：</p><table><thead><tr><th><strong>维度</strong></th><th><strong>doc_values</strong></th><th><strong>fielddata</strong></th></tr></thead><tbody><tr><td>创建时间</td><td>index 时创建</td><td>使用时动态创建，默认不开启</td></tr><tr><td>创建位置</td><td>磁盘</td><td>内存(jvm heap)</td></tr><tr><td>优点</td><td>不占用内存空间</td><td>不占用磁盘空间</td></tr><tr><td>缺点</td><td>索引速度稍低</td><td>文档很多时，动态创建开销比较大，而且占内存</td></tr></tbody></table><h3 id="4-5-Segment-Memory"><a href="#4-5-Segment-Memory" class="headerlink" title="4.5 Segment Memory"></a>4.5 Segment Memory</h3><p>我们知道一个索引是由多个分片组成的，而一个分片又是由多个段文件组成的，一个段文件就是一个完整的倒排索引，倒排索引如果想要全部存储到内存里，这不太现实，太大了，但是 ES 为词典做了一层前缀索引，这个前缀索引默认会被加载到内存中，Lucene 的前缀索引使用 FST 来实现</p><h4 id="4-5-1-FST-结构"><a href="#4-5-1-FST-结构" class="headerlink" title="4.5.1 FST 结构"></a>4.5.1 FST 结构</h4><ul><li>FST 全名：Finite Satae Transducer，实际上是一颗 TRIE 树，具体 TRIE 树的创建自行参考，这里不多讲</li><li>FST 结构优点：存储空间小，所以可以被加载到内存，其次查询效率高，远高于 HashMap，Binary Tree 等数据结构，如下为一个 FST 数据结构参考</li></ul><p><img src="/assets/20210124122428-pa76644-fst.png"></p><h4 id="4-5-2-控制段文件数量"><a href="#4-5-2-控制段文件数量" class="headerlink" title="4.5.2 控制段文件数量"></a>4.5.2 控制段文件数量</h4><ul><li>如上所说，每个段文件都会有 FST 前缀索引，这个索引会被存储到内存中，如果段文件越多，那么占用的内存越大，所以我们要定期合并段文件，同时集群的分片不能过多，因为分片越多，段文件也就越多了</li></ul><h2 id="五、引用"><a href="#五、引用" class="headerlink" title="五、引用"></a>五、引用</h2><ol><li>ES 内存参考：<a href="https://www.elastic.co/cn/blog/found-dive-into-elasticsearch-storage#lucene-index-files">https://www.elastic.co/cn/blog/found-dive-into-elasticsearch-storage#lucene-index-files</a></li><li>FST 数据结构参考：<a href="https://www.shenyanchao.cn/blog/2018/12/04/lucene-fst/">https://www.shenyanchao.cn/blog/2018/12/04/lucene-fst/</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> 数据工程 </category>
          
          <category> ES </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ES </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2020年回顾与感想</title>
      <link href="/article/2020%E6%80%BB%E7%BB%93.html"/>
      <url>/article/2020%E6%80%BB%E7%BB%93.html</url>
      
        <content type="html"><![CDATA[<h2 id="一、前言"><a href="#一、前言" class="headerlink" title="一、前言"></a>一、前言</h2><p>在想以何种样式来写年度总结，之前<strong>2018年的总结</strong>以挑出各个维度的几件事来总结，通过此来反思做的好的，做的差的，以及来年目标，这种挺新颖，但目标量化性不够，聚焦性不足。正好最终工作上要进行季度述职，所以打算用比较枯燥但深刻的述职模板来承载2020年总结吧。</p><h2 id="二、2020年总结"><a href="#二、2020年总结" class="headerlink" title="二、2020年总结"></a><strong>二、2020年总结</strong></h2><p>请重点回顾在本人在周期内的关键策略进展、重要进展、目标达成等。</p><h3 id="1、个人目标"><a href="#1、个人目标" class="headerlink" title="1、个人目标"></a><strong>1、个人目标</strong></h3><p>上阶段有什么个人目标</p><table><thead><tr><th><strong>阶段性目标</strong></th><th><strong>路径</strong></th></tr></thead><tbody><tr><td>技术能力</td><td>1，提升系统架构能力，能够通用性、易用性、扩展性延伸<br />2，提升技术决策能力，多调研，多总结</td></tr><tr><td>表达能力</td><td>1，提升自我沟通表达能力</td></tr><tr><td>经济知识能力</td><td>1，增加自己以经济视角看待问题能力，尝试不同的投资类型<br /></td></tr></tbody></table><h3 id="2、目标完成情况及工作成果"><a href="#2、目标完成情况及工作成果" class="headerlink" title="2、目标完成情况及工作成果"></a><strong>2、目标完成情况及工作成果</strong></h3><p>上阶段目标完成情况，取得了什么亮点&#x2F;成果（如有对标情况，请列举），有什么认知迭代</p><span id="more"></span><table><thead><tr><th><strong>方向</strong></th><th><strong>目标</strong></th><th><strong>关键步骤</strong></th><th><strong>成果</strong></th></tr></thead><tbody><tr><td>技术能力</td><td>1，提升系统架构能力，能够通用性、易用性、扩展性延伸<br />2，提升技术决策能力，多调研，多总结</td><td>1，通过多维度学习和总结<br />2，多调研和学习业界开源项目</td><td>技术思维开始打开，但知识不够，架构知识面未总结<br />总结不同项目间共性，和各种亮点</td></tr><tr><td>表达能力</td><td>1，提升自我沟通表达能力</td><td>1，工作中增加对外沟通，负责某次需求<br />2，多走出去，与不同职业的人聊天</td><td>在工作上沟通表达和项目管理能力有所提升，argue能力、说服能力(理论知识还不够)还需提升</td></tr><tr><td>金融知识能力</td><td>1，增加自己以经济视角看待问题能力，尝试不同的投资类型</td><td>1，提升经济的全局观，主要通过书籍<br />2，提升投资性知识</td><td>没有制定学习脑图，总是走马观花，比较失败<br />尝试了基金，A股，港股，未能摸索出一个策略，盈收低于股民平均</td></tr></tbody></table><p><strong>认知迭代</strong></p><p>2020年全球新冠疫情大爆发，各个国家都很恐慌，我国也从恐慌中逐渐恢复秩序，国内物价，资产价格有所提升。但因欧美疫情严重，其政府开启了大印钞时代，在这一年里，各个国家的股市都在涨，而美帝疫情如此严重，股市还新高了。受美帝印钞影响，中概股和在港股上市的各大互联网公司都涨了几倍。表现为在这些公司有股票的员工package都涨了很多，今年应届生还戏称在学校得到了升职加薪。纵观过去，每次印钞后，都会出现强者恒强，有钱的更有钱情况，这种时候如果没能跟上印钞速度，便会被抛弃。为此需要提高这种经济趋势的敏锐性，提高自己的金融知识，其他的就交给运气吧。（美帝这么印钞，不怕遭天谴么，预估有生之年，美帝会改朝换代~~）</p><h3 id="3、总结分析"><a href="#3、总结分析" class="headerlink" title="3、总结分析"></a><strong>3、总结分析</strong></h3><p><strong>哪些做得好，哪些还可以再提升，哪些该做却没有推动以及原因分析，影响自己更进一步的障碍是什么</strong></p><p><strong>做的好的</strong></p><p>开始对知识以脑图形式汇总，之前自己也看了很多东西，但很散很乱，没有以一种框架式的去抽取核心知识，吸收很少。脑图是个好东西，让你有层次，抓重点形式去吸取知识。这其实和写文章一样，需要有层次，有思路。</p><p>知道人生需要目标，每个阶段也需要目标，并去细化目标，按照目标去执行。开始觉得工作是个开心的事情，而不是为了谋生的工具。</p><p>意识到思考的重要性，看到兴哥在饭否写的，每天都要思考。这并不一定要去思考很深刻复杂的问题，而是去培养思考的能力，让其成为自身的习惯。</p><p><strong>该做却没做的</strong></p><p>今年因为疫情，自己与朋友聚的时间变少了，自己走出去也越来越少，提升自己希望有优秀的人沟通交流。</p><p><strong>影响更进一步的障碍</strong></p><p>目标定了，执行力不够，因为自己制定的有些目标，需要自己用自己余暇时间去完成。目标需要根据执行去变更，并时刻关注目标，鞭笞自己。</p><h2 id="三、-2021-年规划"><a href="#三、-2021-年规划" class="headerlink" title="三、 2021 年规划"></a><strong>三、 2021 年规划</strong></h2><p><strong>1. 策略</strong>: 不要以战术上的勤奋掩盖战略上的懒惰</p><p>人的精力是有限的，需要更好的分配自身的精力，希望自己是70%时间在工作上（60%的时间上班，10%的时间在技术&#x2F;项目管理上学习），15%的时间学习财务投资类知识，剩下15%用来与亲人、朋友聊天娱乐+思考。</p><p><strong>2. 规划</strong>：明确阶段性目标，并阐述达成目标的路径和方法</p><table><thead><tr><th><strong>阶段性目标</strong></th><th><strong>路径</strong></th><th>目标期望</th></tr></thead><tbody><tr><td>工作能力的提升</td><td>1，根据公司的能力模型，制定各个能力的细致目标<br />2，根据模型，总结自己哪些已经达到，哪些还是短板</td><td></td></tr><tr><td>投资能力的提升</td><td>1，制定投资知识脑图，细化各阶段目标</td><td>投资收益率在20%及以上</td></tr><tr><td>开阔自己的思维</td><td>1，与不同行业优秀的人沟通</td><td>与自己比较相关的四个行业人沟通交流</td></tr><tr><td>总结输出</td><td>多总结输出文章，发表在博客上</td><td>输出12篇博客</td></tr></tbody></table><p>每个都需要进行细化，太大的话，需要制定里程碑。</p><h2 id="四、-个人成长"><a href="#四、-个人成长" class="headerlink" title="四、 个人成长"></a><strong>四、 个人成长</strong></h2><p>希望可以全面回顾你的个人成长，可以参考（定战略&#x2F;策略、拿结果、炼心志）以及<strong>个人管理</strong>（时间分配、个人成长等）这两个视角进行回顾。希望能够既包括<strong>成长（亮点），也包括反思（暗点）</strong>，<strong>阶段性的回顾和反思是为了更好的成长和进步。</strong></p><p><strong>1.     收获与成长</strong></p><p>在女朋友的push下，我们都一致认为需要制定目标，并能够去量化，目标感明确会让自己成长更快，也更有动力。</p><p>自己心境的转变，原来遇到困难会有畏惧心理和推脱心理。现在虽然也有，但会更自信，也想去挑战的勇气。另外工作上不再以事情繁琐层面考虑，而已合理性层面考虑，在合理性上去寻求资源。另外项目管理能力和沟通能力有很大提升。</p><p><strong>2.     反思和不足</strong></p><p>执行力不足，对制定的计划，常常因为平时工作时长，累为由而未能坚持，需要逐渐去克服。</p><p>思考不够，原来看的多，但是现在看来意义不大，因为看的没成为自己的养料，需要在自己思考的情况下再去看。</p><p>做事细致度不够，缺少点完美主义，需要减少自己的想当然，各种事情都需要亲自去确认。</p><p>PS：具体案例并不想写，2333</p><h2 id="五、-她"><a href="#五、-她" class="headerlink" title="五、 她"></a><strong>五、 她</strong></h2><p>今年疫情，其实我们相聚的次数很少，我们都戏称只是网友。她人很好，总是默默的付出很多，无论对于我，还是在工作中，而我是个给多少钱干多少事的人。如果类比投资，我就是短线的投机份子，而她是长线投资。我开始学习她的多付出，并开始投入热情在工作中；而我也劝导她，不要一味的付出，也要考虑考虑回报。</p><p>她运气不好。专业不算好，也没能赶上买房的好时机，并且总是要在自己快要有优势选择权的时候，政策变化。最近一次已经进入三分之一决赛圈了，摇号也处于末尾。而我运气一直可以，大学选了成电，她调侃说，要不是你选好了专业，可能你找不到女朋友 &#x3D;。&#x3D; 除此，之前在有年会抽奖的公司时，年年中奖，曾经还出现过部门未中奖的同事，就是在我东南西北四位同事。摇号买房，也在几千人中过第18号。我们需要用努力去提升我们下限，上限就交给老天吧！</p><p>希望接下来一起努力，一起进步，在以后能够回望曾经那个傻乎乎的我们。</p>]]></content>
      
      
      <categories>
          
          <category> 成长 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 总结 </tag>
            
            <tag> 规划 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>doris介绍</title>
      <link href="/article/doris.html"/>
      <url>/article/doris.html</url>
      
        <content type="html"><![CDATA[<h1 id="1-基本概念"><a href="#1-基本概念" class="headerlink" title="1.基本概念"></a>1.基本概念</h1><h2 id="1-1Doris-Palo-简介"><a href="#1-1Doris-Palo-简介" class="headerlink" title="1.1Doris(Palo) 简介"></a>1.1Doris(Palo) 简介</h2><p><strong>Doris 是一个 MPP 的在线 OLAP 系统，主要整合了 Google Mesa （数据模型），Apache Impala （MPP query engine) 和 ORCFile &#x2F; Parquet (存储格式，编码和压缩) 的技术。</strong></p><p>Doris 具有以下特点：</p><ul><li>无外部系统依赖</li><li>高可靠，高可用，高可扩展</li><li>同时支持 高并发点查询和高吞吐的 Ad-hoc 查询</li><li>同时支持 批量导入和近实时 mini-batch 导入</li><li>兼容 MySQL 协议</li><li>支持 Rollup Table 和 Rollup Table 的智能查询路由</li><li>支持多表 Join</li><li>支持 Schema 在线变更</li><li>支持存储分级，旧的冷数据用 SATA，新的热数据用 SSD</li></ul><p>Doris 的系统架构如下:</p><p><strong>Doris 主要分为 FE 和 BE 两种角色，FE 主要负责查询的编译，分发和元数据管理（基于内存，类似 HDFS NN）；BE 主要负责查询的执行和存储系统。</strong></p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/doris/20201228001916-r6dgky4-doris-fe.png"></p><span id="more"></span><h2 id="1-2Doris-数据模型"><a href="#1-2Doris-数据模型" class="headerlink" title="1.2Doris 数据模型"></a>1.2Doris 数据模型</h2><p>Doris 的数据模型主要分为 3 类:</p><ul><li>Aggregate</li><li>Uniq</li><li>Duplicate</li></ul><h3 id="Aggregate-模型（聚合模型）"><a href="#Aggregate-模型（聚合模型）" class="headerlink" title="Aggregate 模型（聚合模型）"></a>Aggregate 模型（聚合模型）</h3><p>Doris 的聚合模型主要用于固定模式的报表类查询场景，实现原理和Mesa 完全一致。</p><p>维度列作为 Key, 指标列作为 Value，存储时会按照 <strong>Key 列进行排序</strong>，相同 Key 的 Value 会按照聚合函数 F(Sum, Min, Max, Replace,HLL)进行聚合。</p><p><strong>示例 1：导入数据聚合</strong></p><p>假设业务有如下数据表模式：</p><table><thead><tr><th><strong>ColumnName</strong></th><th><strong>Type</strong></th><th><strong>AggregationType</strong></th><th><strong>Comment</strong></th></tr></thead><tbody><tr><td>user_id</td><td>LARGEINT</td><td></td><td>用户 id</td></tr><tr><td>date</td><td>DATE</td><td></td><td>数据灌入日期</td></tr><tr><td>city</td><td>VARCHAR(20)</td><td></td><td>用户所在城市</td></tr><tr><td>age</td><td>SMALLINT</td><td></td><td>用户年龄</td></tr><tr><td>sex</td><td>TINYINT</td><td></td><td>用户性别</td></tr><tr><td>last_visit_date</td><td>DATETIME</td><td>REPLACE</td><td>用户最后一次访问时间</td></tr><tr><td>cost</td><td>BIGINT</td><td>SUM</td><td>用户总消费</td></tr><tr><td>max_dwell_time</td><td>INT</td><td>MAX</td><td>用户最大停留时间</td></tr><tr><td>min_dwell_time</td><td>INT</td><td>MIN</td><td>用户最小停留时间</td></tr></tbody></table><p>如果转换成建表语句则如下（省略建表语句中的 Partition 和 Distribution 信息）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">CREATE TABLE IF NOT EXISTS example_db.expamle_tbl</span><br><span class="line">(</span><br><span class="line">  `user_id` LARGEINT NOT NULL COMMENT &quot;用户id&quot;,</span><br><span class="line">  `date` DATE NOT NULL COMMENT &quot;数据灌入日期时间&quot;,</span><br><span class="line">  `city` VARCHAR(20) COMMENT &quot;用户所在城市&quot;,</span><br><span class="line">  `age` SMALLINT COMMENT &quot;用户年龄&quot;,</span><br><span class="line">  `sex` TINYINT COMMENT &quot;用户性别&quot;,</span><br><span class="line">  `last_visit_date` DATETIME REPLACE DEFAULT &quot;1970-01-01 00:00:00&quot; COMMENT &quot;用户最后一次访问时间&quot;,</span><br><span class="line">  `cost` BIGINT SUM DEFAULT &quot;0&quot; COMMENT &quot;用户总消费&quot;,</span><br><span class="line">  `max_dwell_time` INT MAX DEFAULT &quot;0&quot; COMMENT &quot;用户最大停留时间&quot;,</span><br><span class="line">  `min_dwell_time` INT MIN DEFAULT &quot;99999&quot; COMMENT &quot;用户最小停留时间&quot;,</span><br><span class="line">)</span><br><span class="line">AGGREGATE KEY(`user_id`, `date`, `timestamp`, `city`, `age`, `sex`)</span><br><span class="line">... /* 省略 Partition 和 Distribution 信息 */</span><br><span class="line">；</span><br></pre></td></tr></table></figure><p>可以看到，这是一个典型的用户信息和访问行为的事实表。<br>在一般星型模型中，用户信息和访问行为一般分别存放在维度表和事实表中。这里我们为了更加方便的解释 Doris 的数据模型，将两部分信息统一存放在一张表中。</p><p>表中的列按照是否设置了 AggregationType，分为 Key (维度列) 和 Value（指标列）。没有设置 AggregationType 的，如 user_id、date、age … 等称为 <strong>Key</strong>，而设置了 AggregationType 的称为 <strong>Value</strong>。</p><p>当我们导入数据时，对于 Key 列相同的行和聚合成一行，而 Value 列会按照设置的 AggregationType 进行聚合。 AggregationType 目前有以下四种聚合方式：</p><ol><li>SUM：求和，多行的 Value 进行累加。</li><li>REPLACE：替代，下一批数据中的 Value 会替换之前导入过的行中的 Value。</li><li>MAX：保留最大值。</li><li>MIN：保留最小值。</li></ol><p>假设我们有以下导入数据（原始数据）：</p><table><thead><tr><th><strong>user_id</strong></th><th><strong>date</strong></th><th><strong>city</strong></th><th><strong>age</strong></th><th><strong>sex</strong></th><th><strong>last_visit_date</strong></th><th><strong>cost</strong></th><th><strong>max_dwell_time</strong></th><th><strong>min_dwell_time</strong></th></tr></thead><tbody><tr><td>10000</td><td>2017-10-01</td><td>北京</td><td>20</td><td>0</td><td>2017-10-01 06:00:00</td><td>20</td><td>10</td><td>10</td></tr><tr><td>10000</td><td>2017-10-01</td><td>北京</td><td>20</td><td>0</td><td>2017-10-01 07:00:00</td><td>15</td><td>2</td><td>2</td></tr><tr><td>10001</td><td>2017-10-01</td><td>北京</td><td>30</td><td>1</td><td>2017-10-01 17:05:45</td><td>2</td><td>22</td><td>22</td></tr><tr><td>10002</td><td>2017-10-02</td><td>上海</td><td>20</td><td>1</td><td>2017-10-02 12:59:12</td><td>200</td><td>5</td><td>5</td></tr><tr><td>10003</td><td>2017-10-02</td><td>广州</td><td>32</td><td>0</td><td>2017-10-02 11:20:00</td><td>30</td><td>11</td><td>11</td></tr><tr><td>10004</td><td>2017-10-01</td><td>深圳</td><td>35</td><td>0</td><td>2017-10-01 10:00:15</td><td>100</td><td>3</td><td>3</td></tr><tr><td>10004</td><td>2017-10-03</td><td>深圳</td><td>35</td><td>0</td><td>2017-10-03 10:20:22</td><td>11</td><td>6</td><td>6</td></tr></tbody></table><p>我们假设这是一张记录用户访问某商品页面行为的表。我们以第一行数据为例，解释如下：</p><table><thead><tr><th><strong>数据</strong></th><th><strong>说明</strong></th></tr></thead><tbody><tr><td>10000</td><td>用户 id，每个用户唯一识别 id</td></tr><tr><td>2017-10-01</td><td>数据入库时间，精确到日期</td></tr><tr><td>北京</td><td>用户所在城市</td></tr><tr><td>20</td><td>用户年龄</td></tr><tr><td>0</td><td>性别男（1 代表女性）</td></tr><tr><td>2017-10-01 06:00:00</td><td>用户本次访问该页面的时间，精确到秒</td></tr><tr><td>20</td><td>用户本次访问产生的消费</td></tr><tr><td>10</td><td>用户本次访问，驻留该页面的时间</td></tr><tr><td>10</td><td>用户本次访问，驻留该页面的时间（冗余）</td></tr></tbody></table><p>那么当这批数据正确导入到 Doris 中后，Doris 中最终存储如下：</p><table><thead><tr><th><strong>user_id</strong></th><th><strong>date</strong></th><th><strong>city</strong></th><th><strong>age</strong></th><th><strong>sex</strong></th><th><strong>last_visit_date</strong></th><th><strong>cost</strong></th><th><strong>max_dwell_time</strong></th><th><strong>min_dwell_time</strong></th></tr></thead><tbody><tr><td>10000</td><td>2017-10-01</td><td>北京</td><td>20</td><td>0</td><td>2017-10-01 07:00:00</td><td>35</td><td>10</td><td>2</td></tr><tr><td>10001</td><td>2017-10-01</td><td>北京</td><td>30</td><td>1</td><td>2017-10-01 17:05:45</td><td>2</td><td>22</td><td>22</td></tr><tr><td>10002</td><td>2017-10-02</td><td>上海</td><td>20</td><td>1</td><td>2017-10-02 12:59:12</td><td>200</td><td>5</td><td>5</td></tr><tr><td>10003</td><td>2017-10-02</td><td>广州</td><td>32</td><td>0</td><td>2017-10-02 11:20:00</td><td>30</td><td>11</td><td>11</td></tr><tr><td>10004</td><td>2017-10-01</td><td>深圳</td><td>35</td><td>0</td><td>2017-10-01 10:00:15</td><td>100</td><td>3</td><td>3</td></tr><tr><td>10004</td><td>2017-10-03</td><td>深圳</td><td>35</td><td>0</td><td>2017-10-03 10:20:22</td><td>11</td><td>6</td><td>6</td></tr></tbody></table><p>可以看到，用户 10000 只剩下了一行<strong>聚合后</strong>的数据。而其余用户的数据和原始数据保持一致。这里先解释下用户 10000 聚合后的数据：</p><p>前 5 列没有变化，从第 6 列 last_visit_date 开始：</p><ul><li>2017-10-01 07:00:00：因为 last_visit_date 列的聚合方式为 REPLACE，所以 2017-10-01 07:00:00 替换了 2017-10-01 06:00:00 保存了下来。<blockquote><p>注：在同一个导入批次中的数据，对于 REPLACE 这种聚合方式，替换顺序不做保证。如在这个例子中，最终保存下来的，也有可能是 2017-10-01 06:00:00。而对于不同导入批次中的数据，可以保证，后一批次的数据会替换前一批次。</p></blockquote></li><li>35：因为 cost 列的聚合类型为 SUM，所以由 20 + 15 累加获得 35。</li><li>10：因为 max_dwell_time 列的聚合类型为 MAX，所以 10 和 2 取最大值，获得 10。</li><li>2：因为 min_dwell_time 列的聚合类型为 MIN，所以 10 和 2 取最小值，获得 2。</li></ul><p>经过聚合，Doris 中最终只会存储聚合后的数据。换句话说，即明细数据会丢失，用户不能够再查询到聚合前的明细数据了。</p><h3 id="Uniq-模型（唯一主键）"><a href="#Uniq-模型（唯一主键）" class="headerlink" title="Uniq 模型（唯一主键）"></a><strong>Uniq 模型（唯一主键）</strong></h3><p>在某些多维分析场景下，用户更关注的是如何保证 Key 的唯一性，即如何获得 Primary Key 唯一性约束。因此，我们引入了 Uniq 的数据模型。该模型本质上是聚合模型的一个特例，也是一种简化的表结构表示方式。我们举例说明。</p><table><thead><tr><th><strong>ColumnName</strong></th><th><strong>Type</strong></th><th><strong>IsKey</strong></th><th><strong>Comment</strong></th></tr></thead><tbody><tr><td>user_id</td><td>BIGINT</td><td>Yes</td><td>用户 id</td></tr><tr><td>username</td><td>VARCHAR(50)</td><td>Yes</td><td>用户昵称</td></tr><tr><td>city</td><td>VARCHAR(20)</td><td>No</td><td>用户所在城市</td></tr><tr><td>age</td><td>SMALLINT</td><td>No</td><td>用户年龄</td></tr><tr><td>sex</td><td>TINYINT</td><td>No</td><td>用户性别</td></tr><tr><td>phone</td><td>LARGEINT</td><td>No</td><td>用户电话</td></tr><tr><td>address</td><td>VARCHAR(500)</td><td>No</td><td>用户住址</td></tr><tr><td>register_time</td><td>DATETIME</td><td>No</td><td>用户注册时间</td></tr></tbody></table><p>这是一个典型的用户基础信息表。这类数据没有聚合需求，只需保证主键唯一性。（这里的主键为 user_id + username）。那么我们的建表语句如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE IF NOT EXISTS example_db.expamle_tbl(</span><br><span class="line">  `user_id` LARGEINT NOT NULL COMMENT &quot;用户id&quot;,</span><br><span class="line">  `username` VARCHAR(50) NOT NULL COMMENT &quot;用户昵称&quot;,</span><br><span class="line">  `city` VARCHAR(20) COMMENT &quot;用户所在城市&quot;,</span><br><span class="line">  `age` SMALLINT COMMENT &quot;用户年龄&quot;,</span><br><span class="line">  `sex` TINYINT COMMENT &quot;用户性别&quot;,</span><br><span class="line">  `phone` LARGEINT COMMENT &quot;用户电话&quot;,</span><br><span class="line">  `address` VARCHAR(500) COMMENT &quot;用户地址&quot;,</span><br><span class="line">  `register_time` DATETIME COMMENT &quot;用户注册时间&quot;</span><br><span class="line">) UNIQUE KEY(`user_id`, `user_name`)</span><br><span class="line">... /* 省略 Partition 和 Distribution 信息 */</span><br><span class="line">；</span><br></pre></td></tr></table></figure><p>而这个表结构，完全同等于以下使用聚合模型描述的表结构：</p><table><thead><tr><th><strong>ColumnName</strong></th><th><strong>Type</strong></th><th><strong>AggregationType</strong></th><th><strong>Comment</strong></th></tr></thead><tbody><tr><td>user_id</td><td>BIGINT</td><td></td><td>用户 id</td></tr><tr><td>username</td><td>VARCHAR(50)</td><td></td><td>用户昵称</td></tr><tr><td>city</td><td>VARCHAR(20)</td><td>REPLACE</td><td>用户所在城市</td></tr><tr><td>age</td><td>SMALLINT</td><td>REPLACE</td><td>用户年龄</td></tr><tr><td>sex</td><td>TINYINT</td><td>REPLACE</td><td>用户性别</td></tr><tr><td>phone</td><td>LARGEINT</td><td>REPLACE</td><td>用户电话</td></tr><tr><td>address</td><td>VARCHAR(500)</td><td>REPLACE</td><td>用户住址</td></tr><tr><td>register_time</td><td>DATETIME</td><td>REPLACE</td><td>用户注册时间</td></tr></tbody></table><p>及建表语句：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE IF NOT EXISTS example_db.expamle_tbl(</span><br><span class="line">  `user_id` LARGEINT NOT NULL COMMENT &quot;用户id&quot;,</span><br><span class="line">  `username` VARCHAR(50) NOT NULL COMMENT &quot;用户昵称&quot;,</span><br><span class="line">  `city` VARCHAR(20) REPLACE COMMENT &quot;用户所在城市&quot;,</span><br><span class="line">  `age` SMALLINT REPLACE COMMENT &quot;用户年龄&quot;,</span><br><span class="line">  `sex` TINYINT REPLACE COMMENT &quot;用户性别&quot;,</span><br><span class="line">  `phone` LARGEINT REPLACE COMMENT &quot;用户电话&quot;,</span><br><span class="line">  `address` VARCHAR(500) REPLACE COMMENT &quot;用户地址&quot;,</span><br><span class="line">  `register_time` DATETIME REPLACE COMMENT &quot;用户注册时间&quot;</span><br><span class="line">)</span><br><span class="line">AGGREGATE KEY(`user_id`, `user_name`)</span><br><span class="line">... /* 省略 Partition 和 Distribution 信息 */</span><br><span class="line">；</span><br></pre></td></tr></table></figure><p>即 Uniq 模型完全可以用聚合模型中的 REPLACE 方式替代。其内部的实现方式和数据存储方式也完全一样。这里不再继续举例说明。</p><h3 id="Duplicate-模型（冗余模型）"><a href="#Duplicate-模型（冗余模型）" class="headerlink" title="Duplicate 模型（冗余模型）"></a>Duplicate 模型（冗余模型）</h3><p>由于聚合模型存在下面的缺陷，Doris 引入了非聚合模型。</p><ul><li>必须区分维度列和指标列</li><li>维度列很多时，Sort 的成本很高。</li><li>Count 成本很高，需要读取所有维度列（可以参考 Kylin 的解决方法进行优化）</li></ul><p>非聚合模型主要用于Ad-hoc 查询，不会有任何聚合，不区分维度列和指标列，但是在建表时<strong>需要指定 Sort Columns</strong>，<strong>数据导入时会根据 Sort Columns 进行排序</strong>，查询时根据 Sort Column 过滤会比较高效。</p><p><img src="https://km.sankuai.com/api/file/387029494/387077330"></p><table><thead><tr><th><strong>ColumnName</strong></th><th><strong>Type</strong></th><th><strong>SortKey</strong></th><th><strong>Comment</strong></th></tr></thead><tbody><tr><td>timestamp</td><td>DATETIME</td><td>Yes</td><td>日志时间</td></tr><tr><td>type</td><td>INT</td><td>Yes</td><td>日志类型</td></tr><tr><td>error_code</td><td>INT</td><td>Yes</td><td>错误码</td></tr><tr><td>error_msg</td><td>VARCHAR(1024)</td><td>No</td><td>错误详细信息</td></tr><tr><td>op_id</td><td>BIGINT</td><td>No</td><td>负责人 id</td></tr><tr><td>op_time</td><td>DATETIME</td><td>No</td><td>处理时间</td></tr></tbody></table><p>建表语句如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE IF NOT EXISTS example_db.expamle_tbl</span><br><span class="line">(</span><br><span class="line">  `timestamp` DATETIME NOT NULL COMMENT &quot;日志时间&quot;,</span><br><span class="line">  `type` INT NOT NULL COMMENT &quot;日志类型&quot;,</span><br><span class="line">  `error_code` INT COMMENT &quot;错误码&quot;,</span><br><span class="line">  `error_msg` VARCHAR(1024) COMMENT &quot;错误详细信息&quot;,</span><br><span class="line">  `op_id` BIGINT COMMENT &quot;负责人id&quot;,</span><br><span class="line">  `op_time` DATETIME COMMENT &quot;处理时间&quot;</span><br><span class="line">)</span><br><span class="line">DUPLICATE KEY(`timestamp`, `type`)</span><br><span class="line">... /* 省略 Partition 和 Distribution 信息 */</span><br><span class="line">；</span><br></pre></td></tr></table></figure><h3 id="ROLLUP"><a href="#ROLLUP" class="headerlink" title="ROLLUP"></a>ROLLUP</h3><p>ROLLUP 在多维分析中是“上卷”的意思，即将数据按某种指定的粒度进行进一步聚合。</p><p>基本概念</p><p>在 Doris 中，我们将用户通过建表语句创建出来的表成为 Base 表（Base Table）。Base 表中保存着按用户建表语句指定的方式存储的基础数据。</p><p>在 Base 表（同一个分区内）之上，我们可以创建任意多个 ROLLUP 表。这些 ROLLUP 的数据是基于 Base 表产生的，并且在物理上是<strong>独立存储</strong>的。</p><p>ROLLUP 表的基本作用，在于在 Base 表的基础上，获得更粗粒度的聚合数据。</p><p>在 Kylin 中，我们把每一种维度组合称之为 Cuboid,在 Doris 中与之等价的概念是 RollUp 表。实际上，<strong>Kylin 的 Cuboid 和 Doris 的 RollUp 表都可以认为是一种 Materialized Views 或者 Index。</strong></p><p>Doris 的 RollUp 表 和 Kylin 的 Cuboid 一样，<strong>在查询时不需要显示指定</strong>，系统内部会根据查询条件进行智能路由。下图是个 RollUp 表的示意。</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/doris/20201228001950-0tz07wg-rollup.png"></p><p><strong>Doris RollUp 表的路由规则</strong>如下：</p><ol><li>选择包含所有查询列的 RollUp 表</li><li>按照过滤和排序的 column 筛选最符合的 RollUp 表</li><li>按照 Join 的 column 筛选最符合的 RollUp 表</li><li>行数最小的</li><li>列数最小的</li></ol><table><thead><tr><th></th><th>Doris RollUp</th><th>Kylin Cuboid</th></tr></thead><tbody><tr><td>定义的成本</td><td>需要手动逐个定义</td><td>系统根据 Web 上维度，聚集组的设置自动定义出所有 Cuboid</td></tr><tr><td>定义的灵活性</td><td>维度列和指标列可以自由选择</td><td>只可以选择维度列，每个 Cuboid 都必须包含所有指标列</td></tr><tr><td>计算方式</td><td>从原始数据直接生成每个 RollUp 表的数据</td><td>根据 Cuboid Tree 分层构建 Cuboid，每个 Cuboid 的输入是 Parent cuboid，不是原始数据。</td></tr><tr><td>物理存储</td><td>每个 RollUp 表是独立存储的</td><td>多个 Cuboid 会存储到 1 个 HFile 中(按照大小)</td></tr><tr><td>查询路由</td><td>会根据过滤列，排序列，Join 列，行数，列数进行路由</td><td>仅会根据维度列进行路由</td></tr></tbody></table><p>下面我们用示例详细说明在不同数据模型中的 ROLLUP 表及其作用。</p><p>示例 1：获得每个用户的总消费</p><p>接 <strong>Aggregate 模型</strong>小节的<strong>示例 2</strong>，Base 表结构如下：</p><table><thead><tr><th><strong>ColumnName</strong></th><th><strong>Type</strong></th><th><strong>AggregationType</strong></th><th><strong>Comment</strong></th></tr></thead><tbody><tr><td>user_id</td><td>LARGEINT</td><td></td><td>用户 id</td></tr><tr><td>date</td><td>DATE</td><td></td><td>数据灌入日期</td></tr><tr><td>timestamp</td><td>DATETIME</td><td></td><td>数据灌入时间，精确到秒</td></tr><tr><td>city</td><td>VARCHAR(20)</td><td></td><td>用户所在城市</td></tr><tr><td>age</td><td>SMALLINT</td><td></td><td>用户年龄</td></tr><tr><td>sex</td><td>TINYINT</td><td></td><td>用户性别</td></tr><tr><td>last_visit_date</td><td>DATETIME</td><td>REPLACE</td><td>用户最后一次访问时间</td></tr><tr><td>cost</td><td>BIGINT</td><td>SUM</td><td>用户总消费</td></tr><tr><td>max_dwell_time</td><td>INT</td><td>MAX</td><td>用户最大停留时间</td></tr><tr><td>min_dwell_time</td><td>INT</td><td>MIN</td><td>用户最小停留时间</td></tr></tbody></table><p>存储的数据如下：</p><table><thead><tr><th><strong>user_id</strong></th><th><strong>date</strong></th><th><strong>timestamp</strong></th><th><strong>city</strong></th><th><strong>age</strong></th><th><strong>sex</strong></th><th><strong>last_visit_date</strong></th><th><strong>cost</strong></th><th><strong>max_dwell_time</strong></th><th><strong>min_dwell_time</strong></th></tr></thead><tbody><tr><td>10000</td><td>2017-10-01</td><td>2017-10-01 08:00:05</td><td>北京</td><td>20</td><td>0</td><td>2017-10-01 06:00:00</td><td>20</td><td>10</td><td>10</td></tr><tr><td>10000</td><td>2017-10-01</td><td>2017-10-01 09:00:05</td><td>北京</td><td>20</td><td>0</td><td>2017-10-01 07:00:00</td><td>15</td><td>2</td><td>2</td></tr><tr><td>10001</td><td>2017-10-01</td><td>2017-10-01 18:12:10</td><td>北京</td><td>30</td><td>1</td><td>2017-10-01 17:05:45</td><td>2</td><td>22</td><td>22</td></tr><tr><td>10002</td><td>2017-10-02</td><td>2017-10-02 13:10:00</td><td>上海</td><td>20</td><td>1</td><td>2017-10-02 12:59:12</td><td>200</td><td>5</td><td>5</td></tr><tr><td>10003</td><td>2017-10-02</td><td>2017-10-02 13:15:00</td><td>广州</td><td>32</td><td>0</td><td>2017-10-02 11:20:00</td><td>30</td><td>11</td><td>11</td></tr><tr><td>10004</td><td>2017-10-01</td><td>2017-10-01 12:12:48</td><td>深圳</td><td>35</td><td>0</td><td>2017-10-01 10:00:15</td><td>100</td><td>3</td><td>3</td></tr><tr><td>10004</td><td>2017-10-03</td><td>2017-10-03 12:38:20</td><td>深圳</td><td>35</td><td>0</td><td>2017-10-03 10:20:22</td><td>11</td><td>6</td><td>6</td></tr></tbody></table><p>在此基础上，我们创建一个 ROLLUP：</p><table><thead><tr><th><strong>ColumnName</strong></th></tr></thead><tbody><tr><td>user_id</td></tr><tr><td>cost</td></tr></tbody></table><p>该 ROLLUP 只包含两列：user_id 和 cost。则创建完成后，该 ROLLUP 中存储的数据如下：</p><table><thead><tr><th><strong>user_id</strong></th><th><strong>cost</strong></th></tr></thead><tbody><tr><td>10000</td><td>35</td></tr><tr><td>10001</td><td>2</td></tr><tr><td>10002</td><td>200</td></tr><tr><td>10003</td><td>30</td></tr><tr><td>10004</td><td>111</td></tr></tbody></table><p>可以看到，ROLLUP 中仅保留了每个 user_id，在 cost 列上的 SUM 的结果。那么当我们进行如下查询时:</p><p>SELECT user_id, sum(cost) FROM table GROUP BY user_id;</p><p>Doris 会自动命中这个 ROLLUP 表，从而只需扫描极少的数据量，即可完成这次聚合查询</p><h3 id="多版本"><a href="#多版本" class="headerlink" title="多版本"></a>多版本</h3><p>为了获得更高的导入吞吐量，Doris 的数据更新是按照 batch 来更新的。为了在<strong>数据更新时不影响数据查询</strong>以及<strong>保证更新的原子性</strong>，Doris 采用了 <strong>MVCC</strong> 的方式，所以在数据更新时每个 batch 都需要指定一个 verison。</p><p>数据的版本化虽然可以解决读写冲突和更新的原子性，但是也带来了以下问题：</p><ol><li><strong>存储成本</strong>。 多版本意味着我们需要存储多份数据，但是由于聚合后的数据一般比较小，所以这个问题还好。</li><li><strong>查询时延</strong>。 如果有很多版本，那么查询时需要遍历的版本数据就会很多，查询时延自然就会增大。</li></ol><p>为了解决这两个问题，常见的思路就是及时删除不需要的、过期的数据，以及将小的文件 Merge 为大的文件。</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/doris/20201228002026-7l9ng8w-merge.png"></p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/doris/20201228002106-csq5fmi-delta-compaction.png"></p><p>如上图所示，Mesa 的 Merge 策略和 HBase 很像。</p><p>类似 HBase 的 minor compaction 和 major compaction，Mesa 中引入了<em><strong>cumulative compaction</strong></em>和<em><strong>base compaction</strong></em>的概念。</p><p>Mesa 中将包含了一定版本的数据称为<em><strong>deltas</strong></em>, 表示为[V1, V2]，刚实时写入的小 deltas， 称之为<em><strong>singleton deltas</strong></em>，然后每到一定的版本数(图中是 10)，就通过 cumulative compaction 将 10 个 singleton deltas 合并为 1 个 cumulative deltas，最终每天会通过 base compaction 将一定周期内所有的 deltas 都合并为<em><strong>base deltas</strong></em>。</p><p>所以查询时一般只需要查询 1 个 base deltas， 1 个 cumulative deltas 和少数 singleton deltas 即可。</p><p>注意，compaction 是在<strong>后台并发和异步执行</strong>的，此外由于 Mesa 的存储是按照 key 有序存储的，所以 deltas 的 merge 是<strong>线性时间</strong>的。</p><h3 id="前缀索引"><a href="#前缀索引" class="headerlink" title="前缀索引"></a>前缀索引</h3><p>不同于传统的数据库设计，Doris 不支持在任意列上创建索引。Doris 这类 MPP 架构的 OLAP 数据库，通常都是通过提高并发，来处理大量数据的。<br>本质上，Doris 的数据存储在类似 SSTable（Sorted String Table）的数据结构中。该结构是一种有序的数据结构，可以按照指定的列进行排序存储。在这种数据结构上，以排序列作为条件进行查找，会非常的高效。</p><p>在 Aggregate、Uniq 和 Duplicate 三种数据模型中。底层的数据存储，是按照各自建表语句中，AGGREGATE KEY、UNIQ KEY 和 DUPLICATE KEY 中指定的列进行排序存储的。</p><p>而前缀索引，即在排序的基础上，实现的一种根据给定前缀列，快速查询数据的索引方式。</p><p>我们将一行数据的前 <strong>36 个字节</strong> 作为这行数据的前缀索引。当遇到 VARCHAR 类型时，前缀索引会直接截断。我们举例说明：</p><ol><li>以下表结构的前缀索引为 user_id(8Byte) + age(8Bytes) + message(prefix 20 Bytes)。</li></ol><table><thead><tr><th><strong>ColumnName</strong></th><th><strong>Type</strong></th></tr></thead><tbody><tr><td>user_id</td><td>BIGINT</td></tr><tr><td>age</td><td>INT</td></tr><tr><td>message</td><td>VARCHAR(100)</td></tr><tr><td>max_dwell_time</td><td>DATETIME</td></tr><tr><td>min_dwell_time</td><td>DATETIME</td></tr><tr><td>2. 以下表结构的前缀索引为 user_name(20 Bytes)。即使没有达到 36 个字节，因为遇到VARCHAR，所以直接截断，不再往后继续。</td><td></td></tr></tbody></table><table><thead><tr><th><strong>ColumnName</strong></th><th><strong>Type</strong></th></tr></thead><tbody><tr><td>user_name</td><td>VARCHAR(20)</td></tr><tr><td>age</td><td>INT</td></tr><tr><td>message</td><td>VARCHAR(100)</td></tr><tr><td>max_dwell_time</td><td>DATETIME</td></tr><tr><td>min_dwell_time</td><td>DATETIME</td></tr></tbody></table><p>当我们的查询条件，是<strong>前缀索引的前缀</strong>时，可以极大的加快查询速度。比如在第一个例子中，我们执行如下查询：</p><p>SELECT * FROM table WHERE user_id&#x3D;1829239 and age&#x3D;20；</p><p>该查询的效率会<strong>远高于</strong>如下查询：</p><p>SELECT * FROM table WHERE age&#x3D;20；</p><p>所以在建表时，<strong>正确的选择列顺序，能够极大地提高查询效率</strong>。</p><p>ROLLUP 调整前缀索引</p><p>因为建表时已经指定了列顺序，所以一个表只有一种前缀索引。这对于使用其他不能命中前缀索引的列作为条件进行的查询来说，效率上可能无法满足需求。因此，我们可以通过创建 ROLLUP 来人为的调整列顺序。举例说明。</p><p>Base 表结构如下：</p><table><thead><tr><th><strong>ColumnName</strong></th><th><strong>Type</strong></th></tr></thead><tbody><tr><td>user_id</td><td>BIGINT</td></tr><tr><td>age</td><td>INT</td></tr><tr><td>message</td><td>VARCHAR(100)</td></tr><tr><td>max_dwell_time</td><td>DATETIME</td></tr><tr><td>min_dwell_time</td><td>DATETIME</td></tr></tbody></table><p>我们可以在此基础上创建一个 ROLLUP 表：</p><table><thead><tr><th><strong>ColumnName</strong></th><th><strong>Type</strong></th></tr></thead><tbody><tr><td>age</td><td>INT</td></tr><tr><td>user_id</td><td>BIGINT</td></tr><tr><td>message</td><td>VARCHAR(100)</td></tr><tr><td>max_dwell_time</td><td>DATETIME</td></tr><tr><td>min_dwell_time</td><td>DATETIME</td></tr></tbody></table><p>可以看到，ROLLUP 和 Base 表的列完全一样，只是将 user_id 和 age 的顺序调换了。那么当我们进行如下查询时：</p><p>SELECT * FROM table where age&#x3D;20 and massage LIKE &quot;%error%&quot;;</p><p>会优先选择 ROLLUP 表，因为 ROLLUP 的前缀索引匹配度更高。</p><h3 id="聚合模型的局限性"><a href="#聚合模型的局限性" class="headerlink" title="聚合模型的局限性"></a>聚合模型的局限性</h3><p>这里我们针对 Aggregate 模型（包括 Uniq 模型），来介绍下聚合模型的局限性。</p><p>在聚合模型中，模型对外展现的，是<strong>最终聚合后的</strong>数据。也就是说，任何还未聚合的数据（比如说两个不同导入批次的数据），必须通过某种方式，以保证对外展示的一致性。我们举例说明。</p><p>假设表结构如下：</p><table><thead><tr><th><strong>ColumnName</strong></th><th><strong>Type</strong></th><th><strong>AggregationType</strong></th><th><strong>Comment</strong></th></tr></thead><tbody><tr><td>user_id</td><td>LARGEINT</td><td></td><td>用户 id</td></tr><tr><td>date</td><td>DATE</td><td></td><td>数据灌入日期</td></tr><tr><td>cost</td><td>BIGINT</td><td>SUM</td><td>用户总消费</td></tr></tbody></table><p>假设存储引擎中有如下两个已经导入完成的批次的数据：</p><p><strong>batch 1</strong></p><table><thead><tr><th><strong>user_id</strong></th><th><strong>date</strong></th><th><strong>cost</strong></th></tr></thead><tbody><tr><td>10001</td><td>2017-11-20</td><td>50</td></tr><tr><td>10002</td><td>2017-11-21</td><td>39</td></tr></tbody></table><p><strong>batch 2</strong></p><table><thead><tr><th><strong>user_id</strong></th><th><strong>date</strong></th><th><strong>cost</strong></th></tr></thead><tbody><tr><td>10001</td><td>2017-11-20</td><td>1</td></tr><tr><td>10001</td><td>2017-11-21</td><td>5</td></tr><tr><td>10003</td><td>2017-11-22</td><td>22</td></tr></tbody></table><p>可以看到，用户 10001 分属在两个导入批次中的数据还没有聚合。但是为了保证用户只能查询到如下最终聚合后的数据：</p><table><thead><tr><th><strong>user_id</strong></th><th><strong>date</strong></th><th><strong>cost</strong></th></tr></thead><tbody><tr><td>10001</td><td>2017-11-20</td><td>51</td></tr><tr><td>10001</td><td>2017-11-21</td><td>5</td></tr><tr><td>10002</td><td>2017-11-21</td><td>39</td></tr><tr><td>10003</td><td>2017-11-22</td><td>22</td></tr></tbody></table><p>我们在查询引擎中加入了聚合算子，来保证数据对外的一致性。</p><p>另外，在聚合列（Value）上，执行与聚合类型不一致的聚合类查询时，要注意语意。比如我们在如上示例中执行如下查询：</p><p>SELECT MIN(cost) FROM table;</p><p>得到的结果是 5，而不是 1。</p><p>同时，这种一致性保证，在某些查询中，会极大的降低查询效率。</p><p>我们以最基本的 count(*) 查询为例：</p><p>SELECT COUNT(*) FROM table;</p><p>在其他数据库中，这类查询都会很快的返回结果。因为在实现上，我们可以通过如“导入时对行进行计数，保存 count 的统计信息”，或者在查询时“仅扫描某一列数据，获得 count 值”的方式，只需很小的开销，即可获得查询结果。但是在 Doris 的聚合模型中，这种查询的开销<strong>非常大</strong>。</p><p>我们以刚才的数据为例：</p><p><strong>batch 1</strong></p><table><thead><tr><th><strong>user_id</strong></th><th><strong>date</strong></th><th><strong>cost</strong></th></tr></thead><tbody><tr><td>10001</td><td>2017-11-20</td><td>50</td></tr><tr><td>10002</td><td>2017-11-21</td><td>39</td></tr></tbody></table><p><strong>batch 2</strong></p><table><thead><tr><th><strong>user_id</strong></th><th><strong>date</strong></th><th><strong>cost</strong></th></tr></thead><tbody><tr><td>10001</td><td>2017-11-20</td><td>1</td></tr><tr><td>10001</td><td>2017-11-21</td><td>5</td></tr><tr><td>10003</td><td>2017-11-22</td><td>22</td></tr></tbody></table><p>因为最终的聚合结果为：</p><table><thead><tr><th><strong>user_id</strong></th><th><strong>date</strong></th><th><strong>cost</strong></th></tr></thead><tbody><tr><td>10001</td><td>2017-11-20</td><td>51</td></tr><tr><td>10001</td><td>2017-11-21</td><td>5</td></tr><tr><td>10002</td><td>2017-11-21</td><td>39</td></tr><tr><td>10003</td><td>2017-11-22</td><td>22</td></tr></tbody></table><p>所以，select count(*) from table; 的正确结果应该为 <strong>4</strong>。但如果我们只扫描 user_id 这一列，如果加上查询时聚合，最终得到的结果是 <strong>3</strong>（10001, 10002, 10003）。而如果不加查询时聚合，则得到的结果是 <strong>5</strong>（两批次一共 5 行数据）。可见这两个结果都是不对的。</p><p>为了得到正确的结果，我们必须同时读取 user_id 和 date 这两列的数据，<strong>再加上查询时聚合</strong>，才能返回 <strong>4</strong> 这个正确的结果。也就是说，在 count(<em>) 查询中，Doris 必须扫描所有的 AGGREGATE KEY 列（这里就是 user_id 和 date），并且聚合后，才能得到语意正确的结果。当聚合列非常多时，count(</em>) 查询需要扫描大量的数据。</p><p>因此，当业务上有频繁的 count(<em>) 查询时，我们建议用户通过增加一个**值衡为 1 的，聚合类型为 SUM 的列来模拟 count(</em>)**。如刚才的例子中的表结构，我们修改如下：</p><table><thead><tr><th><strong>ColumnName</strong></th><th><strong>Type</strong></th><th><strong>AggreateType</strong></th><th><strong>Comment</strong></th></tr></thead><tbody><tr><td>user_id</td><td>BIGINT</td><td></td><td>用户 id</td></tr><tr><td>date</td><td>DATE</td><td></td><td>数据灌入日期</td></tr><tr><td>cost</td><td>BIGINT</td><td>SUM</td><td>用户总消费</td></tr><tr><td>count</td><td>BIGINT</td><td>SUM</td><td>用于计算 count</td></tr></tbody></table><p>增加一个 count 列，并且导入数据中，该列值<strong>衡为 1</strong>。则 select count(<em>) from table; 的结果等价于 select sum(count) from table;。而后者的查询效率将远高于前者。不过这种方式也有使用限制，就是用户需要自行保证，不会重复导入 AGGREGATE KEY 列都相同的行。否则，select sum(count) from table; 只能表述原始导入的行数，而不是 select count(</em>) from table; 的语义。</p><p>另一种方式，就是 <strong>将如上的 count 列的聚合类型改为 REPLACE，且依然值衡为 1</strong>。那么 select sum(count) from table; 和 select count(*) from table; 的结果将是一致的。并且这种方式，没有导入重复行的限制。</p><h3 id="Duplicate-模型"><a href="#Duplicate-模型" class="headerlink" title="Duplicate 模型"></a>Duplicate 模型</h3><p>Duplicate 模型没有聚合模型的这个局限性。因为该模型不涉及聚合语意，在做 count(*) 查询时，任意选择一列查询，即可得到语意正确的结果。</p><h3 id="数据模型的选择建议"><a href="#数据模型的选择建议" class="headerlink" title="数据模型的选择建议"></a>数据模型的选择建议</h3><p>因为数据模型在建表时就已经确定，且<strong>无法修改</strong>。所以，选择一个合适的数据模型<strong>非常重要</strong>。</p><ol><li>Aggregate 模型可以通过预聚合，极大地降低聚合查询时所需扫描的数据量和查询的计算量，非常适合有固定模式的报表类查询场景。但是该模型对 count(*) 查询很不友好。同时因为固定了 Value 列上的聚合方式，在进行其他类型的聚合查询时，需要考虑语意正确性。</li><li>Uniq 模型针对需要唯一主键约束的场景，可以保证主键唯一性约束。但是无法利用 ROLLUP 等预聚合带来的查询优势（因为本质是 REPLACE，没有 SUM 这种聚合方式）。</li><li>Duplicate 适合任意维度的 Ad-hoc 查询。虽然同样无法利用预聚合的特性，但是不受聚合模型的约束，可以发挥列存模型的优势（只读取相关列，而不需要读取所有 Key 列）</li></ol><h2 id="1-3Doris-存储模型"><a href="#1-3Doris-存储模型" class="headerlink" title="1.3Doris 存储模型"></a>1.3Doris 存储模型</h2><p>Doris 的存储模型主要整合了 Meda 的数据模型和 ORCFile &#x2F; Parquet 的存储格式，编码和压缩。</p><p><strong>Doris 存储相关的基本概念</strong></p><p>Doris 元数据上的逻辑概念有 Table，Partition，Tablet，Replica。</p><p>Doris 的 Table 支持二级分区，可以先按照日期列进行一级分区，再按照指定列进行 Hash 分桶。</p><p>首先 1 个 Table 可以按照日期列分为多个 Partition， 每个 Partition 可以包含多个 Tablet，每个 Table 的数据被水平划分为多个 Tablet，</p><p>每个 Tablet 包含若干数据行，<em><strong>Tablet 是数据移动、复制等操作的最小物理存储单元</strong></em>，各个 Tablet 之间的数据没有交集，并且在物理上是独立存储的。</p><p><em><strong>Partition 可以视为逻辑上最小的管理单元，数据的导入与删除，仅能针对一个 Partition 进行</strong></em>。</p><p>1 个 Table 的 Tablet 数量&#x3D; Partition num * Bucket num。</p><p>Tablet 会按照一定大小（<strong>256M</strong>）拆分为多个 segment 文件， segment 是列存的，但是会按行（<strong>1024 行，可配置</strong>）拆分为多个 rowblock。</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/doris/20201228002138-akghkdf-storage-file.png"></p><p><strong>Doris 的数据文件</strong></p><p>Doris 的数据文件如下图所示：</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/doris/20201228002150-eolrbk7-file.png"></p><p>Doris 数据文件 Stream 的例子：</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/doris/20201228002202-jypfdh1-stream.png"></p><p><strong>前缀索引</strong></p><p>本质上，Doris 的数据存储是类似 SSTable（Sorted String Table）的数据结构。该结构是一种有序的数据结构，可以按照指定的列进行排序存储。</p><p>在这种数据结构上，以排序列作为条件进行查找，会非常的高效。而前缀索引，即在排序的基础上，实现的一种根据给定前缀列，快速查询数据的索引方式。</p><p>前缀索引文件的格式如下图所示，索引的 Key 是<strong>每个 rowblock 第一行记录的 Sort Key 的前 36 个字节</strong>，Value 是 <strong>rowblock 在 segment 文件的偏移量</strong>。</p><p>有了前缀索引后，我们查询特定 key 的过程就是<strong>两次二分查找</strong>：</p><ol><li>先加载 index 文件，二分查找 index 文件获取包含特定 key 的 row blocks 的 offest,然后从 data files 中获取指定的 row blocks；</li><li>在 row blocks 中二分查询特定的 key</li></ol><p>Index 文件：</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/doris/20201228002214-j9xyxca-index.png"></p><p><strong>Min，Max 索引和 Bloomfilter</strong></p><p>在利用前缀索引过滤 block 之前， Doris 也会根据 Min,Max 索引和 bloomfilter（可选）过滤掉不匹配的 block。</p><p><strong>编码和压缩</strong></p><p><strong>编码</strong></p><p>Doris 中整形的编码方式：（以下几种编码方式的细节具体可以参考 <a href="https://orc.apache.org/docs/run-length.html">HIve ORC</a>）</p><ol><li>SHORT_REPEAT</li><li>DIRECT</li><li>PATCHED_BASE</li><li>DELTA</li></ol><p>具体选择哪种编码方式会根据数据特点进行选择。</p><p>String 会使用字典编码 和 DIRECT 编码，使用哪种方式取决于列的基数。</p><p><strong>压缩</strong></p><p>索引文件和 BF 不会压缩。</p><p>数据文件会使用 LZO 或者 LZ4 算法压缩。</p><p><strong>Doris 针对网络传输，硬盘数据，存储有不同的压缩算法</strong>：</p><ul><li>网络传输时会使用 LZO1X 算法，该算法压缩率低，CPU 开销低</li><li>硬盘数据会使用 LZO1C_99 算法，该算法压缩率高，CPU 开销大</li><li>储存会使用 LZ4 算法，压缩率低，CPU 开销低</li></ul>]]></content>
      
      
      <categories>
          
          <category> 数据工程 </category>
          
          <category> OLAP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据 </tag>
            
            <tag> OLAP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Flink：什么是 Watermark？</title>
      <link href="/article/Flink-Watermark.html"/>
      <url>/article/Flink-Watermark.html</url>
      
        <content type="html"><![CDATA[<h1 id="1、什么是-watermark"><a href="#1、什么是-watermark" class="headerlink" title="1、什么是 watermark"></a>1、什么是 watermark</h1><p>watermark 网上有翻译成水印，但更应该是水位线，即 <strong>Flink 接受的数据就相当于浮在水面的物体， 基于物理知识，水位线的高度只会升高不会降低，那么每当新数据进来，会重新计算水位线的时间，计算结果小于当前水位线时间，则不会更新现有的水位线。 当水位线到达窗口触发时间时才会触发窗口的计算</strong>。watermark 的意义在于数据无序传递的时候有一定容错率，如果晚来的数据在容错范围之内，会当做正常传递来处理。</p><p>乍一看还是懵逼，那么就看下面的分析。</p><h1 id="2、什么是流处理"><a href="#2、什么是流处理" class="headerlink" title="2、什么是流处理"></a>2、什么是流处理</h1><p>Flink 被称为真正的流式实时计算框架，其批处理中是流处理的特殊情况。而所谓的流处理，本质特点是在处理数据时，接受一条处理一条。而批处理则是累积数据到一定程度在处理。这是他们本质的区别。</p><p>假如我们自己写一个流式框架。我们该如何处理消息。如下，我们看到消息按照顺序一个个发送，接受后按照顺序处理，这是没有什么问题的。</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/flink/watermark/shunxu.png"></p><p>如果消息不按照顺序发送，产生了乱序，这时候该怎么处理？</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/flink/watermark/luanxu.png"></p><p>其实水位线 Watermark 就是其中的解决方案之一。</p><span id="more"></span><h1 id="3、水位线怎么解决乱序"><a href="#3、水位线怎么解决乱序" class="headerlink" title="3、水位线怎么解决乱序"></a>3、水位线怎么解决乱序</h1><p>要理解：水位线和 Flink 窗口（window ）机制是一起用的，不可分割来看。先看前置基础——Flink 窗口，时间机制</p><h2 id="3-1、Flink-窗口机制简单概括"><a href="#3-1、Flink-窗口机制简单概括" class="headerlink" title="3.1、Flink 窗口机制简单概括"></a>3.1、Flink 窗口机制简单概括</h2><p>对于 Flink，如果来一条消息计算一条。。。这样搞，计算非常频繁而且消耗资源，如果想做一些统计这是不可能的。所以对于 Spark 和 Flink 都产生了窗口计算的概念。</p><p>下面详细分析，简单粗暴的说：如果我们想看到过去一分钟，过去半小时。。。访问数据，这时候我们就需要窗口。<strong>即：翻滚窗口（Tumbling Window，无重叠），滚动窗口（Sliding Window，有重叠），和会话窗口（Session Window，活动间隙）。</strong></p><h3 id="滚动窗口"><a href="#滚动窗口" class="headerlink" title="滚动窗口"></a><strong>滚动窗口</strong></h3><p>将每个元素分配给固定窗口大小的窗口。滚动窗口大小固定且不重叠。例如，指定大小为 5 分钟的滚动窗口，则将执行当前窗口，并且每五分钟将启动一个新窗口，如下图所示:<br><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/flink/watermark/tumb-window.png"></p><h3 id="滑动窗口"><a href="#滑动窗口" class="headerlink" title="滑动窗口"></a><strong>滑动窗口</strong></h3><p>将每个元素分配给固定窗口大小的窗口。类似于滚动窗口分配器，窗口的大小由窗口大小参数配置。另外一个滑动参数控制滑动窗口的启动频率 (how frequently a sliding window is started)。因此如果滑动参数的大小，小于窗口大小，滑动窗口就可以重叠。在这种情况下，元素被分配到多个窗口。</p><p>例如，可以使用窗口大小为 10 分钟的窗口，滑动参数为 5 分钟。这样，每 5 分钟会生成一个滑动窗口，包含最后 10 分钟内到达的事件，如下图所示。<br><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/flink/watermark/slid-window.png"></p><h3 id="会话窗口"><a href="#会话窗口" class="headerlink" title="会话窗口"></a><strong>会话窗口</strong></h3><p>通过活动会话分组元素。与滑动窗口相比，会话窗口不会重叠，也没有固定的开始和结束时间。相反，当会话窗口在一段时间内没有接收到元素时会关闭。</p><p>例如，不活动的间隙，会话窗口分配器配置会话间隙，定义所需的不活动时间长度(defines how long is the required period of inactivity)。当此时间段到期时，当前会话关闭，后续元素被分配到新的会话窗口。<br><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/flink/watermark/session-window.png"></p><h3 id="窗口自定义"><a href="#窗口自定义" class="headerlink" title="窗口自定义"></a><strong>窗口自定义</strong></h3><p>这是 flink 灵活的地方，<strong>基本操作：</strong><br>window：创建自定义窗口<br>trigger：自定义触发器<br>evictor：自定义 evictor<br>apply：自定义 window function</p><h2 id="3-2、Flink-时间机制简单概述"><a href="#3-2、Flink-时间机制简单概述" class="headerlink" title="3.2、Flink 时间机制简单概述"></a>3.2、Flink 时间机制简单概述</h2><p>一个事件发生了，肯定是有时间概念的，这个时间，在 Flink 中被称之为事件时间，也就是 Event Time，也就是事件时间，除此之外，还有处理时间 Processing Time，和提取时间 Ingestion Time 。这三个时间区别和联系看下图，分别列出了事件时间、处理时间、提取时间的先后顺序。</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/flink/watermark/time-type.png"></p><h3 id="Event-Time"><a href="#Event-Time" class="headerlink" title="Event Time"></a>Event Time</h3><p>大白话就是这个事儿发生的真实时间（源头）。举个例子，产生日志，其中日志的时间戳就是发生时间，即事件时间。</p><p>严谨的说，事件时间是每个事件在其设备上发生的时间。在进入 Flink 之前就已经存在，此时间通常在进入 Flink 之前嵌入记录中，并且可以从每个记录中提取该事件时间。事件时间程序必须指定如何生成事件时间水位线，这是表示事件时间进度的机制，<strong>下一小节细说水位线，先知道有这个概念</strong>。</p><p>在一个理想的情况下，无论事件何时到达或如何排序，事件时间的处理将产生完全一致的和确定的结果。但是，除非事件严格的按时间戳顺序到达 Flink，否则事件时间处理会在等待无序事件时产生一些延迟。由于只能等待一段有限的时间，因此限制了确定性事件时间应用程序的可能性。</p><p>假设所有数据都已到达，事件时间操作将按预期运行，即使在处理无序或延迟事件或重新处理历史数据时也会产生正确且一致的结果。例如，每小时事件时间窗口将包含带有落入该小时的事件时间戳的所有记录，无论它们到达的顺序如何，或者何时处理它们。</p><p>注意，有时当事件时间程序实时处理实时数据时，它们将使用一些处理时间操作，以确保它们及时进行。</p><h3 id="Ingestion-Time"><a href="#Ingestion-Time" class="headerlink" title="Ingestion Time"></a>Ingestion Time</h3><p>大白话就是事件进入 Flink 的时间，即<strong>提取时间</strong>。每个记录在 source 操作里获取当前系统的时间作为提取时间，后续操作统一使用该时间。</p><p>严格的说：提取时间在概念上位于事件时间和处理时间之间。</p><ol><li>与处理时间相比，它早一些，但可以提供更可预测的结果。因为提取时间使用稳定的时间戳（在源 source 处分配一次，后续操作一直用），所以对记录的不同窗口操作将引用相同的时间戳，而在处理时间中，每个窗口 operate 可以将记录分配给不同的窗口（基于本地系统时钟和任何运输延误）。</li><li>与事件时间相比，提取时间程序无法处理任何无序事件或后期数据，但程序不必指定如何生成水位线。在内部，提取时间与事件时间非常相似，但具有自动时间戳分配和自动水印生成功能。</li></ol><h3 id="Processing-Time"><a href="#Processing-Time" class="headerlink" title="Processing Time"></a>Processing Time</h3><p>大白话就是做这个事情的时间，即处理时间。它也是执行操作的机器的当前系统时间(每个算子都不一样)，图里这个事件已经进入了 Flink。</p><p>严谨的说：当流程序在处理时间运行时，所有基于时间的操作（如时间窗口）将使用相应 operator（算子，以下都简称为 operator）所在的机器的<strong>系统时钟</strong>。每小时处理时间窗口将包括在系统时钟指示整个小时之间到达特定 operator 的所有记录。例如，如果应用程序在上午 9:15 开始运行，则第一个每小时处理时间窗口将包括在上午 9:15 到上午 10:00 之间处理的事件，下一个窗口将包括在上午 10:00 到 11:00 之间处理的事件。</p><p>处理时间是最简单的时间概念，不需要流和机器之间的协调。它提供最佳性能和最低延迟。但是，在分布式和异步环境中，处理时间不提供确定性，因为它容易受到记录到达系统的速度（例如从消息队列）到记录在系统内的 operator 之间流动的速度的影响,和停电（调度或其他）。</p><h3 id="三类时间的区别总结"><a href="#三类时间的区别总结" class="headerlink" title="三类时间的区别总结"></a>三类时间的区别总结</h3><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/flink/watermark/watermark.png"></p><table><thead><tr><th></th><th>EventTime</th><th>IngestTime</th><th>ProcessingTime</th></tr></thead><tbody><tr><td>概念</td><td>事件生成时的时间，在进入 Flink 之前就已经存在，可以从 event 的字段中抽取。</td><td>事件进入 Flink 的时间，即在 source 里获取的当前系统的时间，后续操作统一使用该时间。</td><td>执行操作的机器的当前系统时间(每个算子都不一样)</td></tr><tr><td>水位线</td><td>必须指定 watermarks（水位线）的生成方式。</td><td>不需要指定 watermarks 的生成方式(自动生成)</td><td>不需要流和机器之间的协调</td></tr><tr><td>优点</td><td>确定性，乱序、延时、或者数据重放等情况，都能给出正确的结果</td><td></td><td>最佳的性能和最低的延迟</td></tr><tr><td>缺点</td><td>处理无序事件时性能和延迟受到影响</td><td>不能处理无序事件和延迟数据</td><td>不确定性 ，容易受到各种因素影像(event 产生的速度、到达 flink 的速度、在算子之间传输速度等)，压根就不管顺序和延迟</td></tr></tbody></table><p>性能： ProcessingTime&gt; IngestTime&gt; EventTime</p><p>延迟： ProcessingTime&lt; IngestTime&lt; EventTime</p><p>确定性： EventTime&gt; IngestTime&gt; ProcessingTime</p><h2 id="3-3、对于水位线的用处终极解释"><a href="#3-3、对于水位线的用处终极解释" class="headerlink" title="3.3、对于水位线的用处终极解释"></a>3.3、对于<strong>水位线的用处终极解释</strong></h2><p>前面提到了 watermark 是用于处理乱序事件的，而正确的处理乱序事件，通常用 watermark 机制结合 window 来实现。前面的时间机制已经提到，流处理从事件产生，到 source，再到 operator，中间是有一个过程的，并不是严格的实时。虽然大部分情况下，流到 operator 的数据都是按照事件产生的时间顺序进入 Flink 的，但是也不排除由于网络、背压等原因，导致乱序，而对于流中迟到的元素，Flink 又不能无限期等下去，所以必须要有个机制来保证一个特定的时间后，必须触发 window 去进行计算了。这个特别的机制，就是 watermark——水位线机制。</p><h2 id="3-4、水位线解决乱序的原理"><a href="#3-4、水位线解决乱序的原理" class="headerlink" title="3.4、水位线解决乱序的原理"></a>3.4、水位线解决乱序的原理</h2><p>前面分析了，watermark 是用来解决乱序的，即保证一个特定时间后，必须触发 window 窗口计算，因此，可以根据事件的 event time，计算出水位线，并且设置一些延迟，给迟到的数据一些机会，也就是说正常来讲，对于迟到的数据，我只等你一段时间，再不来就没有机会了。</p><p>通过前面窗口机制概括，我们知道比如滚动窗口，或滑动窗口等，都有自己的触发机制，比如每隔 5 秒窗口就会计算（触发）一次。假如我们设置 10s 的时间窗口（window），那么 0<del>10s，10</del>20s 都是一个窗口，以 0~10s 为例，0 是 start-time，10 是 end-time。假如有 4 个数据（ABCD），它们的 event-time 分别是 8(A),12.5(B),9(C),13.5(D)，<strong>我们设置水位时间为当前所有到达数据的 event-time 的最大值减去延迟时间，</strong>这里延迟时间设置为 3.5s，也就是说对于迟到的数据，我们只等你 3.5 秒。【如果超过 3.5 秒该怎么办，这时候就需要我们对生产环境有一个整体的认识和把握，数据是否有延迟，延迟大概是多长时间，怎么样达到数据不丢失。当然还有另外的方法来处理延迟，这里只分析水位线的作用】。如下：</p><table><thead><tr><th>流中元素</th><th>事件时间（s）</th><th>真正的到达顺序（并没严格按照事件时间进入 Flink）</th><th>水位线（s）</th><th>是否触发窗口计算（10s 的时间窗口）</th></tr></thead><tbody><tr><td>A</td><td>8</td><td>A 到达</td><td>max{8} - 3.5 &#x3D; 8 - 3.5 &#x3D; 4.5</td><td>否</td></tr><tr><td>B</td><td>12.5</td><td>B 到达</td><td>max(12.5, 8) - 3.5 &#x3D; 12.5 - 3.5 &#x3D; 9</td><td>否</td></tr><tr><td>C</td><td>9</td><td><strong>C 到达（迟到）</strong></td><td>max(12.5, 8, 9) - 3.5 &#x3D; 12.5 - 3.5 &#x3D; 9</td><td>否</td></tr><tr><td>D</td><td>13.5</td><td>D 到达</td><td>max(13.5, 12.5, 8, 9) - 3.5 &#x3D; 13.5 - 3.5 &#x3D; 10</td><td>是</td></tr></tbody></table><p>D 元素触发窗口计算的时候，会将 ABC（因为他们都小于 10）都计算进去，通过上面这种方式，就将迟到的 C 计算进去了，这样一来，watermark 可以在数据无序传递的时候有一定容错率，如果晚来的数据在容错范围之内，会当做正常传递来处理。</p><h2 id="3-5、水位线不是万能的"><a href="#3-5、水位线不是万能的" class="headerlink" title="3.5、水位线不是万能的"></a>3.5、水位线不是万能的</h2><p>3.4 里的延迟 3.5s 是假设一个数据到达的时候，比他早 3.5s 的数据肯定也都到达了，这个是需要根据经验推算的，假设 D 到达以后，又到达了一个 E，其 event-time&#x3D;6，但是由于 0~10 的时间窗口已经开始计算了，所以 E 就丢了，E 的丢失说明水位线机制不是万能的，但是如果根据我们自己的生产经验 + 侧道输出等方案，可以做到数据不丢失。这又是一个新话题了，以后分析。</p>]]></content>
      
      
      <categories>
          
          <category> 数据工程 </category>
          
          <category> flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>推荐系统技术演进趋势：从召回到排序再到重排</title>
      <link href="/article/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E8%B6%8B%E5%8A%BF%EF%BC%9A%E4%BB%8E%E5%8F%AC%E5%9B%9E%E5%88%B0%E6%8E%92%E5%BA%8F%E5%86%8D%E5%88%B0%E9%87%8D%E6%8E%92.html"/>
      <url>/article/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E8%B6%8B%E5%8A%BF%EF%BC%9A%E4%BB%8E%E5%8F%AC%E5%9B%9E%E5%88%B0%E6%8E%92%E5%BA%8F%E5%86%8D%E5%88%B0%E9%87%8D%E6%8E%92.html</url>
      
        <content type="html"><![CDATA[<p>推荐系统技术，总体而言，与NLP和图像领域比，发展速度不算太快。不过最近两年，由于深度学习等一些新技术的引入，总体还是表现出了一些比较明显的技术发展趋势。这篇文章试图从推荐系统几个环节，以及不同的技术角度，来对目前推荐技术的比较彰显的技术趋势做个归纳。个人判断较多，偏颇难免，所以还请谨慎参考。</p><p>在写技术趋势前，照例还是对推荐系统的宏观架构做个简单说明，以免读者迷失在技术细节中。</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/recommend/recommend.jpg">实际的工业推荐系统，如果粗分的化，经常讲的有两个阶段。首先是召回，主要根据用户部分特征，从海量的物品库里，快速找回一小部分用户潜在感兴趣的物品，然后交给排序环节，排序环节可以融入较多特征，使用复杂模型，来精准地做个性化推荐。召回强调快，排序强调准。当然，这是传统角度看推荐这个事情。</p><p>但是，如果我们更细致地看实用的推荐系统，一般会有四个环节，如下图所示：</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/recommend/step.jpg"></p><p>四个环节分别是：召回、粗排、精排和重排。召回目的如上所述；有时候因为每个用户召回环节返回的物品数量还是太多，怕排序环节速度跟不上，所以可以在召回和精排之间加入一个粗排环节，通过少量用户和物品特征，简单模型，来对召回的结果进行个粗略的排序，在保证一定精准的前提下，进一步减少往后传送的物品数量，粗排往往是可选的，可用可不同，跟场景有关。之后，是精排环节，使用你能想到的任何特征，可以上你能承受速度极限的复杂模型，尽量精准地对物品进行个性化排序。排序完成后，传给重排环节，传统地看，这里往往会上各种技术及业务策略，比如去已读、去重、打散、多样性保证、固定类型物品插入等等，主要是技术产品策略主导或者为了改进用户体验的。</p><p>那么，每个环节，从技术发展的角度看，都各自有怎样的发展趋势呢？下面我们分头说明。</p><span id="more"></span><h2 id="召回技术演进趋势"><a href="#召回技术演进趋势" class="headerlink" title="召回技术演进趋势"></a><strong>召回技术演进趋势</strong></h2><p>推荐系统的召回阶段是很关键的一个环节，但是客观的说，传统地看，这个环节，技术含量是不太高的，偏向策略型导向，往往灵机一动，就能想到一个策略，增加一路新的召回。你在网上搜，发现讲推荐模型的，95%是讲排序阶段的模型，讲召回的别说模型，讲它本身的都很少，这与它的策略导向有关系，大家觉得没什么好讲的。总体而言，召回环节的有监督模型化以及一切Embedding化，这是两个相辅相成的总体发展趋势。而打embedding的具体方法，则可以有各种选择，比如下面介绍的几个技术发展趋势，可以理解为不同的给用户和物品打embedding的不同方法而已。</p><p><strong>模型召回</strong></p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/recommend/model_rank.jpg"></p><p>传统的标准召回结构一般是多路召回，如上图所示。如果我们根据召回路是否有用户个性化因素存在来划分，可以分成两大类：一类是无个性化因素的召回路，比如热门商品或者热门文章或者历史点击率高的物料的召回；另外一类是包含个性化因素的召回路，比如用户兴趣标签召回。我们应该怎么看待包含个性化因素的召回路呢？其实吧，你可以这么看，可以把某个召回路看作是：单特征模型排序的排序结果。意思是，可以把某路召回，看成是某个排序模型的排序结果，只不过，这个排序模型，在用户侧和物品侧只用了一个特征。比如说，标签召回，其实就是用用户兴趣标签和物品标签进行排序的单特征排序结果；再比如协同召回，可以看成是只包含UID和ItemID的两个特征的排序结果….诸如此类。我们应该统一从排序的角度来看待推荐系统的各个环节，这样可能会更好理解本文所讲述的一些技术。</p><p>如果我们换做上面的角度看待有个性化因素召回路，那么在召回阶段引入模型，就是自然而然的一个拓展结果：无非是把单特征排序，拓展成多特征排序的模型而已；而多路召回，则可以通过引入多特征，被融入到独立的召回模型中，找到它的替代品。如此而已。所以，随着技术的发展，在embedding基础上的模型化召回，必然是个符合技术发展潮流的方向。</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/recommend/general.jpg"></p><p>那么如何在召回阶段利用模型来代替多路召回呢？上图展示了一个抽象的模型召回的通用架构，核心思想是：将用户特征和物品特征分离，各自通过某个具体的模型，分别打出用户Embedding以及物品Embedding。在线上，可以根据用户兴趣Embedding，采用类似Faiss等高效Embedding检索工具，快速找出和用户兴趣匹配的物品，这样就等于做出了利用多特征融合的召回模型了。理论上来说，任何你能见到的有监督模型，都可以用来做这个召回模型，比如FM／FFM／DNN等，常说的所谓“双塔”模型，指的其实是用户侧和物品侧特征分离分别打Embedding的结构而已，并非具体的模型。</p><p>模型召回具备自己独有的好处和优势，比如多路召回每路截断条数的超参个性化问题等会自然被消解掉。当然，它也会带来自己的问题，比较典型的是召回内容头部问题，因为之前多路，每路召回个数靠硬性截断，可以根据需要，保证你想要召回的，总能通过某一路拉回来；而由于换成了模型召回，面向海量物料库，排在前列得分高的可能聚集在几个物料分布比较多的头部领域。解决这个问题的方法包括比如训练数据对头部领域的降采样，减少某些领域主导，以及在模型角度鼓励多样性等不同的方法。</p><p>另外一点值得注意的是：如果在召回阶段使用模型召回，理论上也应该同步采用和排序模型相同的优化目标，尤其是如果排序阶段采用多目标优化的情况下，召回模型也应该对应采取相同的多目标优化。同理，如果整个流程中包含粗排模块，粗排也应该采用和精排相同的多目标优化，几个环节优化目标应保持一致。因为召回和粗排是精排的前置环节，否则，如果优化目标不一致，很可能会出现高质量精排目标，在前置环节就被过滤掉的可能，影响整体效果。</p><p>典型工作：</p><p>FM模型召回：<a href="https://zhuanlan.zhihu.com/p/58160982">推荐系统召回四模型之：全能的FM模型</a></p><p>DNN双塔召回：Sampling-Bias-Corrected Neural Modeling for Large Corpus Item Recommendations</p><p><strong>用户行为序列召回</strong></p><p>用户在使用APP或者网站的时候，一般会产生一些针对物品的行为，比如点击一些感兴趣的物品，收藏或者互动行为，或者是购买商品等。而一般用户之所以会对物品发生行为，往往意味着这些物品是符合用户兴趣的，而不同类型的行为，可能代表了不同程度的兴趣。比如购买就是比点击更能表征用户兴趣的行为。</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/recommend/user_list.jpg"></p><p>而用户行为过的物品序列，其实是具备表征用户兴趣的非常有价值的信息，而且这种兴趣表征，是细粒度的用户兴趣，所以对于刻画用户兴趣具备特别的价值。利用用户行为过的物品序列，来表征用户兴趣，具备很好的实用价值。</p><p>如果我们抽象地来看的话，利用用户行为过的物品序列对用户兴趣建模，本质上就是这么个过程：输入是用户行为过的物品序列，可以只用物品ID表征，也可以融入物品的Side Information比如名称，描述，图片等，现在我们需要一个函数Fun，这个函数以这些物品为输入，需要通过一定的方法把这些进行糅合到一个embedding里，而这个糅合好的embedding，就代表了用户兴趣。无论是在召回过程，还是排序过程，都可以融入用户行为序列。在召回阶段，我们可以用用户兴趣Embedding采取向量召回，而在排序阶段，这个embedding则可以作为用户侧的特征。</p><p>所以，核心在于：这个物品聚合函数Fun如何定义的问题。这里需要注意的一点是：用户行为序列中的物品，是有时间顺序的。理论上，任何能够体现时序特点或特征局部性关联的模型，都比较适合应用在这里，典型的比如CNN、RNN、Transformer等，都比较适合用来集成用户行为序列信息。而目前的很多试验结果证明，GRU（RNN的变体模型）可能是聚合用户行为序列效果最好又比较简单的模型。当然，RNN不能并行的低效率，那是另外一个问题。</p><p>在召回阶段，如何根据用户行为序列打embedding，可以采取有监督的模型，比如Next Item Prediction的预测方式即可；也可以采用无监督的方式，比如物品只要能打出embedding，就能无监督集成用户行为序列内容，例如Sum Pooling。而排序侧，必然是有监督的模式，需要注意的是：排序侧表征用户特征的时候，可以只用用户行为过的物品序列，也可以混合用户其它特征，比如群体属性特征等一起来表征用户兴趣，方式比较灵活。比如DIEN，就是典型的采用混合模式的方法。</p><p>典型工作：</p><p>GRU：Recurrent Neural Networks with Top-k Gains for Session-based Recommendations</p><p>CNN：Personalized Top-N Sequential Recommendation via Convolutional Sequence Embedding</p><p>Transformer: Self-Attentive Sequential Recommendation</p><p><strong>用户多兴趣拆分</strong></p><p>上文讲了利用用户行为物品序列，打出用户兴趣Embedding的做法。但是，另外一个现实是：用户往往是多兴趣的，比如可能同时对娱乐、体育、收藏感兴趣。这些不同的兴趣也能从用户行为序列的物品构成上看出来，比如行为序列中大部分是娱乐类，一部分体育类，少部分收藏类等。那么能否把用户行为序列物品中，这种不同类型的用户兴趣细分，而不是都笼统地打到一个用户兴趣Embedding里呢？用户多兴趣拆分就是解决这类更细致刻画用户兴趣的方向。</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/recommend/embedding.jpg"></p><p>用户多兴趣拆分，本质上是上文所叙述的用户行为序列打embedding方向的一个细化，无非上文说的是：以用户行为序列物品作为输入，通过一些能体现时序特点的模型，映射成一个用户兴趣embedding。而用户多兴趣拆分，输入是一样的，输出不同，无非由输出单独一个用户embedding，换成输出多个用户兴趣embedding而已。虽说道理如此，但是在具体技术使用方向上却不太一样，对于单用户兴趣embedding来说，只需要考虑信息有效集成即可；而对于多用户兴趣拆分来说，需要多做些事情，多做什么事情呢？本质上，把用户行为序列打到多个embedding上，实际它是个类似聚类的过程，就是把不同的Item，聚类到不同的兴趣类别里去。目前常用的拆分用户兴趣embedding的方法，主要是胶囊网络和Memory Network，但是理论上，很多类似聚类的方法应该都是有效的，所以完全可以在这块替换成你自己的能产生聚类效果的方法来做。</p><p>说到这里，有同学会问了：把用户行为序列拆分到不同的embedding里，有这个必要吗？反正不论怎样，即使是一个embedding，信息都已经包含到里面了，并未有什么信息损失问题呀。这个问题很好。我的个人感觉是：在召回阶段，把用户兴趣拆分成多个embedding是有直接价值和意义的，前面我们说过，召回阶段有时候容易碰到头部问题，就是比如通过用户兴趣embedding拉回来的物料，可能集中在头部优势领域中，造成弱势兴趣不太能体现出来的问题。而如果把用户兴趣进行拆分，每个兴趣embedding各自拉回部分相关的物料，则可以很大程度缓解召回的头部问题。所以我感觉，这种兴趣拆分，在召回阶段是很合适的，可以定向解决它面临的一些实际问题。对于排序环节，是否有必要把用户兴趣拆分成多个，我倒觉得必要性不是太大，很难直观感受这样做背后发生作用的机理是怎样的。我能想到的，在排序环节使用多兴趣Embedding能发生作用的地方，好像有一个：因为我们在计算user对某个item是否感兴趣的时候，对于用户行为序列物品，往往计算目标item和行为序列物品的Attention是有帮助的，因为用户兴趣是多样的，物品Item的类型归属往往是唯一的，所以行为序列里面只有一部分物品和当前要判断的Item是类型相关的，这会对判断有作用，其它的无关物品其实没啥用，于是Attention就是必要的，可以减少那些无关物品对当前物品判断的影响。而当行为序列物品太多的时候，我们知道，Atttention计算是非常耗时的操作，如果我们把这种Attention计算，放到聚类完的几个兴趣embedding维度计算，无疑能极大提升训练和预测的速度。貌似这个优点还是成立的。</p><p>典型工作：</p><p>召回：Multi-Interest Network with Dynamic Routing for Recommendation at Tmall</p><p>排序：Practice on Long Sequential User Behavior Modeling for Click-Through Rate Prediction</p><p><strong>知识图谱融合召回</strong></p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/recommend/user_item_entity.jpg"></p><p>推荐系统中，最核心的数据是用户对物品的行为数据，因为这直接表明了用户兴趣所在。如上图所示，如果把用户放在一侧，物品放在另一侧，若用户对某物品有行为产生，则建立一条边，这样就构建了用户-物品交互的二部图。其实，有另外一种隐藏在冰山之下的数据，那就是物品之间是有一些知识联系存在的，就是我们常说的知识图谱，而这类数据是可以考虑用来增强推荐效果的，尤其是对于用户行为数据稀疏的场景，或者冷启动场景。以上图例子说明，用户点击过电影“泰坦尼克号”，这是用户行为数据，我们知道，电影“泰坦尼克号”的主演是莱昂纳多，于是可以推荐其它由莱昂纳多主演的电影给这个用户。后面这几步操作，利用的是电影领域的知识图谱数据，通过知识图谱中的“电影1—&gt;主演—&gt;电影2”的图路径给出的推荐结果。</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/recommend/know_recall.jpg"></p><p>用于做推荐，一般有两大类知识图谱融合模式：知识图谱Embedding模式（KGE）及图路径模式。知识图谱Embedding模式首先根据TransE等对知识图谱进行Embedding化编码的工具，将节点和边转换成Embedding表征方式。然后根据用户行为过的物品，以及物品在知识图谱中的Embedding和知识图谱中其它知识embedding的距离，来扩展物品的信息含量，或者扩充用户行为数据，类似用已知的用户行为数据，在知识图谱辅助下进行外扩。知识图谱的Embedding模式在可解释性方面比较弱，因为知识之间的关联是通过Embedding计算出来的，不好解释为什么从这个知识跳到那个知识；而图路径模式则是根据物品属性之间的关联等人工定义好的所谓Meta-Path，也就是人工定义的知识图谱中知识的关联和传播模式，通过中间属性来对知识传播进行路径搭建，具体例子就是上面说的“电影1主演电影2”，这就是人事先定义好的Meta-Path，也就是人把自己的经验写成规则，来利用知识图谱里的数据。图路径模式在可解释性方面效果较好，因为是人工定义的传播路径，所以非常好理解知识传播关系，但是往往实际应用效果并不好。</p><p>知识图谱是一种信息拓展的模式，很明显，对知识进行近距离的拓展，这可能会带来信息补充作用，但是如果拓展的比较远，或者拓展不当，反而可能会引入噪音，这个道理好理解。所以，我的感觉是，知识图谱在排序侧并不是特别好用，如果想用的化，比较适合用户行为数据非常稀疏以及用户冷启动的场景，也就是说如果用户数据太少，需要拓展，可以考虑使用它。另外，知识图谱还有一个普适性的问题，完全通用的知识图谱在特定场景下是否好用，对此我是有疑问的，而专业性的知识图谱，还有一个如何构建以及构建成本问题；而且很多时候，所谓的知识传播，是可以通过添加属性特征来解决的，比如：电影1—&gt;主演—&gt;电影2这种知识传播路径，完全可以通过把主演作为电影这个实体的属性特征加入常规排序模型，来达到类似知识近距离传播的目的，所以感觉也不是很有必要在排序侧专门去做知识图谱拓展这种事情。</p><p>这种知识拓展，可能比较适合用在召回阶段，因为对于传统观点的召回来说，精准并不是最重要的目标，找出和用户兴趣有一定程度相关性但是又具备泛化性能的物品是召回侧的重点，所以可能知识图谱的模式更适合将知识图谱放在召回侧。</p><p>当然，知识图谱有一个独有的优势和价值，那就是对于推荐结果的可解释性；比如推荐给用户某个物品，可以在知识图谱里通过物品的关键关联路径给出合理解释，这对于推荐结果的解释性来说是很好的，因为知识图谱说到底是人编码出来让自己容易理解的一套知识体系，所以人非常容易理解其间的关系。但是，在推荐领域目前的工作中，知识图谱的可解释性往往是和图路径方法关联在一起的，而Path类方法，很多实验证明了，在排序角度来看，是效果最差的一类方法。所以，我觉得，应该把知识图谱的可解释性优势从具体方法中独立出来，专门用它来做推荐结果的可解释性，这样就能独立发挥它自身的优势；</p><p>至于如何利用知识图谱做召回，其实很直观，比如可以采取如下的无监督学习版本：例如，推荐系统里对用户感兴趣的实体比如某个或者某些明星，往往是个单独的召回路，而可以根据用户的兴趣实体，通过知识图谱的实体Embedding化表达后（或者直接在知识图谱节点上外扩），通过知识外扩或者可以根据Embedding相似性，拓展出相关实体。形成另外一路相关性弱，但是泛化能力强的Knowledge融合召回路。</p><p>典型工作：</p><ol><li><p>KGAT: Knowledge Graph Attention Network for Recommendation</p></li><li><p>RippleNet: Propagating User Preferences on the Knowledge Graph for Recommender Systems</p></li></ol><p><strong>图神经网络模型召回</strong></p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/recommend/graph.jpg"></p><p>严格来说，知识图谱其实是图神经网络的一个比较特殊的具体实例，但是，知识图谱因为编码的是静态知识，而不是用户比较直接的行为数据，和具体应用距离比较远，这可能是导致两者在推荐领域表现差异的主要原因。图神经网络中的图结构，可以是上面介绍知识图谱时候说过的“用户-物品”二部图，也可以是我们常见的有向图或者无向图，图中的节点是各种不同类型的物品及用户，边往往是通过用户行为建立起来的，可以是具体用户的具体行为，也可以是所有用户的群体统计行为，比如物品1—&gt;物品2可以有边，边还可以带上权重，如果越多的用户对物品1进行行为后对物品2进行行为，则这条边的权重越大。而且对于用户或者物品来说，其属性也可以体现在图中，比如对于一个微博，它的文本内容、图片内容、发布者等等属性都可以引入到图中，比如挂接到物品上，或者建立独立的节点也是可以的，这取决于具体的做法。</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/recommend/graphnn.jpg"></p><p>图神经网络的最终目的是要通过一定技术手段，获得图中节点的embedding编码。最常用的embedding聚合工具是CNN，对于某个图节点来说，它的输入可以有两类信息，一类是自身的属性信息，比如上面举的微博的例子；另外一类是图结构信息，就是和当前节点有直接边关联的其它节点信息。通过CNN，可以对两类信息进行编码和聚合，形成图节点的embedding。通过CNN等信息聚合器，在图节点上进行计算，并反复迭代更新图节点的embedding，就能够最终获得可靠的图节点embedding信息，而这种迭代过程，其实体现的是远距离的节点将信息逐步通过图结构传递信息的过程，所以图结构是可以进行知识传递和补充的。</p><p>我们可以进一步思考下，图节点因为可以带有属性信息，比如物品的Content信息，所以明显这对于解决物品侧的冷启动问题有帮助；而因为它也允许知识在图中远距离进行传递，所以比如对于用户行为比较少的场景，可以形成知识传递和补充，这说明它也比较适合用于数据稀疏的推荐场景；另外一面，图中的边往往是通过用户行为构建的，而用户行为，在统计层面来看，本质上是一种协同信息，比如我们常说的“A物品协同B物品”，本质上就是说很多用户行为了物品A后，大概率会去对物品B进行行为；所以图具备的一个很好的优势是：它比较便于把协同信息、用户行为信息、内容属性信息等各种异质信息在一个统一的框架里进行融合，并统一表征为embedding的形式，这是它独有的一个优势，做起来比较自然。另外的一个特有优势，就是信息在图中的传播性，所以对于推荐的冷启动以及数据稀疏场景应该特别有用。</p><p>因为图神经网络，最终获得的往往是图中节点的embedding，这个embedding，就像我们上面说的，其实融合了各种异质信息。所以它是特别适合用来做召回的，比如拿到图网络中用户的embedding和物品embedding，可以直接用来做向量召回。当然，物品和用户的embedding也可以作为特征，引入排序模型中，这都是比较自然的。有些推荐场景也可以直接根据embedding计算user to user&#x2F;item to item的推荐结果，比如看了又看这种推荐场景。</p><p>早期的图神经网络做推荐，因为需要全局信息，所以计算速度是个问题，往往图规模都非常小，不具备实战价值。而GraphSAGE则通过一些手段比如从临近节点进行采样等减少计算规模，加快计算速度，很多后期改进计算效率的方法都是从这个工作衍生的；而PinSage在GraphSAGE基础上（这是同一拨人做的），进一步采取大规模分布式计算，拓展了图计算的实用性，可以计算Pinterest的30亿规模节点、180亿规模边的巨型图，并产生了较好的落地效果。所以这两个工作可以重点借鉴一下。</p><p>总体而言，图模型召回，是个很有前景的值得探索的方向。</p><p>典型工作：</p><p>GraphSAGE: Inductive Representation Learning on Large Graphs</p><p>PinSage: Graph Convolutional Neural Networks for Web-Scale Recommender Systems</p><h2 id="排序模型技术演进趋势"><a href="#排序模型技术演进趋势" class="headerlink" title="排序模型技术演进趋势"></a><strong>排序模型技术演进趋势</strong></h2><p>排序环节是推荐系统最关键，也是最具有技术含量的部分，目前大多数推荐技术其实都聚焦在这块。下面我们从模型表达能力、模型优化目标以及特征及信息三个角度分述推荐排序模型的技术发展趋势。</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/recommend/rank_step.jpg"></p><p>模型表达能力代表了模型是否具备充分利用有效特征及特征组合的能力，其中显示特征组合、新型特征抽取器、增强学习技术应用以及AutoML自动探索模型结构是这方面明显的技术进化方向；模型优化目标则体现了我们希望推荐系统去做好什么，往往跟业务目标有关联，这里我们主要从技术角度来探讨，而多目标优化以及ListWise最优是目前最常见的技术进化方向，ListWise优化目标在排序阶段和重排阶段都可采用，我们把它放到重排部分去讲，这里主要介绍多目标优化；从特征和信息角度，如何采用更丰富的新类型特征，以及信息和特征的扩充及融合是主要技术进化方向，用户长短期兴趣分离、用户行为序列数据的使用、图神经网络以及多模态融合等是这方面的主要技术趋势，因为用户行为序列以及图神经网络在召回部分介绍过，这些点同样可以应用在排序部分，所以这里不再叙述这两点。</p><p><strong>显式特征组合</strong></p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/recommend/feature_auto.jpg"></p><p>如果归纳下工业界CTR模型的演化历史的话，你会发现，特征工程及特征组合的自动化，一直是推动实用化推荐系统技术演进最主要的方向，而且没有之一。最早的LR模型，基本是人工特征工程及人工进行特征组合的，简单有效但是费时费力；再发展到LR+GBDT的高阶特征组合自动化，以及FM模型的二阶特征组合自动化；再往后就是DNN模型的引入，纯粹的简单DNN模型本质上其实是在FM模型的特征Embedding化基础上，添加几层MLP隐层来进行隐式的特征非线性自动组合而已。所谓隐式，意思是并没有明确的网络结构对特征的二阶组合、三阶组合进行直接建模，只是通过MLP，让不同特征发生交互，至于怎么发生交互的，怎么进行特征组合的，谁也说不清楚，这是MLP结构隐式特征组合的作用，当然由于MLP的引入，也会在特征组合时候考虑进入了特征间的非线性关系。</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/recommend/feature_cross.jpg"></p><p>明白了隐式特征组合，也就明白了什么是显式特征组合。就是在模型结构中，明确设计一些子网络或者子结构，对二阶特征组合、三阶特征组合，甚至更高阶的特征组合进行表征。比如说DeepFM，Deep部分就是个典型的DNN模型，这个大家基本都会用，而FM部分则是明确对特征二阶组合进行建模的子模型。这就是一个典型的显式二阶特征组合的模型。而如果进一步拓展的话，很自然想到的一个改进思路是：除了明确的把特征二阶组合做一个子结构，还可以把特征三阶特征组合，更高阶特征组合…..分别做一个模型子结构。融合这些子结构一起来做预测。这就是显式特征组合的含义，其实这条线的发展脉络是异常清晰的。典型的对高阶特征组合建模的比如Deep&amp; Cross、XDeepFM模型等，就是这么个思路。</p><p>在两年多前，我一直以为这个方向是CTR或者推荐模型的关键所在，而且可能如何简洁融入更多特征组合是最重要且最有前景的方向。但是后来发现可能错了，目前基本对这个方向改变了看法。目前我对这个方向的看法是：这个方向确实很重要，但是未来可挖掘的潜力和空间很有限，在这条路上继续行进，应该不会走得太远。原因在于，目前基本很多经验已经证明了，显式的二阶特征组合是非常重要的，三阶特征组合对不同类型任务基本都有帮助。四阶特征组合已经说不清楚是否有用了，跟数据集有关系，有些数据集合引入显式4阶特征组合有帮助，有些数据集合没什么用。至于更高阶的特征组合，明确用对应的子结构建模，基本已经没什么用了，甚至是负面作用。这说明：我们在实际做事情的时候，其实显式结构把三阶特征组合引入，已经基本足够了。这是为什么说这条路继续往后走潜力不大的原因。</p><p>典型工作：</p><p>Deep&amp; Cross: Deep &amp; Cross Network for Ad Click Predictions</p><p>XDeepFM: Combining Explicit and Implicit Feature Interactions for Recommender Systems</p><p><strong>特征抽取器的进化</strong></p><p>从特征抽取器的角度来看，目前主流的DNN 排序模型，最常用的特征抽取器仍然是MLP结构，通常是两层或者三层的MLP隐层。目前也有理论研究表明：MLP结构用来捕获特征组合，是效率比较低下的，除非把隐层神经元个数急剧放大，而这又会急剧增加参数规模。与自然语言处理和图像处理比较，推荐领域的特征抽取器仍然处于非常初级的发展阶段。所以，探寻新型特征抽取器，对于推荐模型的进化是个非常重要的发展方向。</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/recommend/feature_trans.jpg"></p><p>目前其它AI领域里，常用的特征抽取器包括图像领域的CNN、NLP领域的RNN和Transformer。这些新型特征抽取器，在推荐领域最近两年也逐步开始尝试使用，但是宏观地看，在推荐领域，相对MLP结构并未取得明显优势，这里的原因比较复杂。CNN捕获局部特征关联是非常有效的结构，但是并不太适合做纯特征输入的推荐模型，因为推荐领域的特征之间，在输入顺序上并无必然的序列关系，基本属于人工定义随机顺序，而CNN处理这种远距离特征关系能力薄弱，所以并不是特别适合用来处理特征级的推荐模型。当然，对于行为序列数据，因为本身带有序列属性，所以CNN和RNN都是非常适合应用在行为序列结构上的，也是有一定应用历史的典型工具，但是对于没有序关系存在的特征来说，这两个模型的优势不能发挥出来，反而会放大各自的劣势，比如CNN的捕获远距离特征关系能力差的弱点，以及RNN的不可并行处理、所以速度慢的劣势等。</p><p>Transformer作为NLP领域最新型也是最有效的特征抽取器，从其工作机制来说，其实是非常适合用来做推荐的。为什么这么说呢？核心在于Transformer的Multi-Head Self Attention机制上。MHA结构在NLP里面，会对输入句子中任意两个单词的相关程度作出判断，而如果把这种关系套用到推荐领域，就是通过MHA来对任意特征进行特征组合，而上文说过，特征组合对于推荐是个很重要的环节，所以从这个角度来说，Transformer是特别适合来对特征组合进行建模的，一层Transformer Block代表了特征的二阶组合，更多的Transformer Block代表了更高阶的特征组合。但是，实际上如果应用Transformer来做推荐，其应用效果并没有体现出明显优势，甚至没有体现出什么优势，基本稍微好于或者类似于典型的MLP结构的效果。这意味着，可能我们需要针对推荐领域特点，对Transformer需要进行针对性的改造，而不是完全直接照搬NLP里的结构。</p><p>典型工作：</p><p>AutoInt: Automatic Feature Interaction Learning via Self-Attentive Neural Networks</p><p>DeepFM: An End-to-End Wide &amp; Deep Learning Framework for CTR Prediction</p><p><strong>AutoML在推荐的应用</strong></p><p>AutoML在17年初开始出现，最近三年蓬勃发展，在比如图像领域、NLP领域等都有非常重要的研究进展，在这些领域，目前都能通过AutoML找到比人设计的效果更好的模型结构。AutoML作为算法方向最大的领域趋势之一，能否在不同领域超过人类专家的表现？这应该不是一个需要回答“会不会”的问题，而是应该回答“什么时间会”的问题。原因很简单，AutoML通过各种基础算子的任意组合，在超大的算子组合空间内，寻找性能表现最好的模型，几乎可以达到穷举遍历的效果，而人类专家设计出来的最好的模型，无非是算子组合空间中的一个点而已，而且人类专家设计的那个模型，是最好模型的可能性是很低的。如果设计精良的AutoML，一定可以自己找到超过目前人类专家设计的最好的那个模型，这基本不会有什么疑问，就像人类就算不是2017年，也会是某一年，下围棋下不过机器，道理其实是一样的，因为AutoML在巨大的算子组合空间里寻找最优模型，跟围棋在无穷的棋盘空间寻找胜利的盘面，本质上是一个事情。无非，现在AutoML的不成熟，体现在需要搜索的空间太大，比较消耗计算资源方面而已，随着技术的不断成熟，搜索成本越来越低，AutoML在很多算法方向超过人类表现只是个时间问题。</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/recommend/enas.jpg"></p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/recommend/dnn_rank.jpg"></p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/recommend/dnn_rank_str.jpg"></p><p>在推荐领域，采用AutoML做网络结构的工作还很少，这里面有很多原因。由于我一直以来特别看好这个方向，所以在18年的时候，我们也尝试过利用AutoML来自动探索推荐系统的网络结构，这里非常简略地介绍下过程及结果（参考上面三图）。我们用ENAS作为网络搜索工具，设计了推荐领域网络结构自动探索的尝试。ENAS是个非常高效率的AutoML工具，可以做到单GPU半天搜索找到最优的网络结构，但是它定义的主要是CNN结构和RNN结构搜索。我们对ENAS进行了改造，包括算子定义，优化目标以及评价指标定义等。DNN排序模型因为模型比较单一，所以算子是比较好找的，我们定义了推荐领域的常用算子，然后在这些算子组合空间内通过ENAS自动寻找效果最优的网络结构，最终找到的一个表现最好的网络结构如下图所示：</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/recommend/enas_find.jpg"></p><p>首先是特征onehot到embedding的映射，我们把这层固定住了，不作为模型结构探索因子。在特征embedding之上，有三个并行结构，其中两个是包含两个隐层的MLP结构，另外一个是特征双线性组合模块（Each Fields Type，具体含义可以参考下面的FibiNet）。其表现超过了DeepFM等人工结构，但是并未超过很多。（感谢黄通文同学的具体尝试）</p><p>总体而言，目前AutoML来做推荐模型，还很不成熟，找出的结构相对人工设计结构效果优势也不是太明显。这与DNN Ranking模型比较简单，算子类型太少以及模型深度做不起来也有很大关系。但是，我相信这里可以有更进一步的工作可做。</p><p>典型工作：</p><p>ENAS结构搜索：<a href="https://link.zhihu.com/?target=https://www.docin.com/p-2269372287.html">AutoML在推荐排序网络结构搜索的应用</a></p><p>双线性特征组合: FiBiNET: Combining Feature Importance and Bilinear feature Interaction for Click-Through Rate Prediction</p><p><strong>增强学习在推荐的应用</strong></p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/recommend/improve_learn.jpg"></p><p>增强学习其实是比较吻合推荐场景建模的。一般而言，增强学习有几个关键要素：状态、行为以及回报。在推荐场景下，我们可以把状态St定义为用户的行为历史物品集合；推荐系统可选的行为空间则是根据用户当前状态St推荐给用户的推荐结果列表，这里可以看出，推荐场景下，用户行为空间是巨大无比的，这制约了很多无法对巨大行为空间建模的增强学习方法的应用；而回报呢，则是用户对推荐系统给出的列表内容进行互动的行为价值，比如可以定义点击了某个物品，则回报是1，购买了某个物品，回报是5….诸如此类。有了这几个要素的场景定义，就可以用典型的增强学习来对推荐进行建模。</p><p>利用增强学习来做推荐系统，有几个显而易见的好处，比如：</p><ol><li>比较容易对“利用-探索”（Exploitation&#x2F;Exploration）建模。所谓利用，就是推荐给用户当前收益最大的物品，一般推荐模型都是优化这个目标；所谓探索，就是随机推给用户一些物品，以此来探测用户潜在感兴趣的东西。如果要进行探索，往往会牺牲推荐系统的当前总体收益，毕竟探索效率比较低，相当的通过探索渠道推给用户的物品，用户其实并不感兴趣，浪费了推荐位。但是，利用-探索的均衡，是比较容易通过调节增强学习的回报（Reward）来体现这个事情的，比较自然；</li><li>比较容易体现用户兴趣的动态变化。我们知道，用户兴趣有长期稳定的，也有不断变化的。而增强学习比较容易通过用户行为和反馈的物品对应的回报的重要性，而动态对推荐结果产生变化，所以是比较容易融入体现用户兴趣变化这个特点的。</li><li>有利于推荐系统长期收益建模。这点是增强学习做推荐最有优势的一个点。我们优化推荐系统，往往会有一些短期的目标比如增加点击率等，但是长期目标比如用户体验或者用户活跃留存等指标，一般不太好直接优化，而增强学习模型比较容易对长期收益目标来进行建模。</li></ol><p>说了这么多优点，貌似增强学习应该重点投入去做，是吧？我的意见正好相反，觉得从实际落地角度来看，推荐系统里要尝试增强学习方法，如果你有这个冲动，最好还是抑制一下。主要原因是，貌似增强学习是技术落地投入产出比非常低的技术点。首先投入高，要想把增强学习做work，意味着有很多大坑在等着你去踩，数据怎么做、模型怎么写、回报怎么拍，长期收益怎么定义、建模并拆解成回报…….超大规模实际场景的用户和物品，增强学习这么复杂的模型，系统怎么才能真的落地并撑住流量…..很多坑在里面；其次，貌似目前看到的文献看，貌似很少见到真的把增强学习大规模推到真实线上系统，并产生很好的收益的系统。Youtube在最近一年做了不少尝试，虽说把系统推上线了，但是收益怎样不好说。而且，从另外一个角度看，做增强学习里面还是有不少Trick在，那些收益到底是系统带来的，还是Trick带来的，真还不太好说。所以，综合而言，目前看在增强学习做推荐投入，貌似还是一笔不太合算的买卖。当然，长远看，可能还是很有潜力的，但是貌似这个潜力还需要新的技术突破去推动和挖掘。</p><p>典型工作：</p><p>Youtube: Top-K Off-Policy Correction for a REINFORCE Recommender System</p><p>Youtube: Reinforcement Learning for Slate-based Recommender Systems: A Tractable Decomposition and Practical Methodology</p><p><strong>多目标优化</strong></p><p>推荐系统的多目标优化（点击，互动，时长等多个目标同时优化）严格来说不仅仅是趋势，而是目前很多公司的研发现状。对于推荐系统来说，不同的优化目标可能存在互相拉后腿的现象，比如互动和时长，往往拉起一个指标另外一个就会明显往下掉，而多目标旨在平衡不同目标的相互影响，尽量能够做到所有指标同步上涨，即使很难做到，也尽量做到在某个优化目标上涨的情况下，不拉低或者将尽量少拉低其它指标。多目标优化对于实用化的推荐系统起到了举足轻重的作用，这里其实是有很多工作可以做的，而如果多目标优化效果好，对于业务效果的推动作用也非常大。总而言之，多目标优化是值得推荐系统相关研发人员重点关注的技术方向。</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/recommend/multi_target.jpg"></p><p>从技术角度讲，多目标优化最关键的有两个问题。第一个问题是多个优化目标的模型结构问题；第二个问题是不同优化目标的重要性如何界定的问题。</p><p>既然存在多个优化目标，最简单直接的方式，也是目前最常用的方式是：每个优化目标独立优化，比如点击目标训练一个模型，互动目标训练一个模型，时长目标训练一个模型，各自优化，然后每个目标独立给实例预测打分，给每个目标设定权重值，各个目标打分加权求和线性融合，或者引入权重指数及根据目标关系引入非线性融合。这是目前最常见的落地方案。因为目标之间独立优化，模型是通过分数融合来实现多目标的，所以可以把这种多目标方式称作“Share-Nothing”结构。这个结构实现和优化方式很简单。</p><p>与Share-Nothing结构相比，其实我们是可以让不同优化目标共享一部分参数的，一旦引入不同目标或者任务的参数共享，我们就踏入了Transfer Learning的领地了。那么为什么要共享参数呢？一方面出于计算效率考虑，不同目标共享结构能够提升计算效率；另外一点，假设我们有两类任务或者目标，其中一个目标的训练数据很充分，而另外一个目标的训练数据比较少；如果独立优化，训练数据少的目标可能很难获得很好的效果；如果两个任务相关性比较高的话，其实我们可以通过共享参数，达到把大训练数据任务的知识迁移给训练数据比较少的任务的目的，这样可以极大提升训练数据量比较少的任务的效果。Share-Bottom结构是个非常典型的共享参数的多目标优化结构，核心思想是在比如网络的底层参数，所有任务共享参数，而上层网络，不同任务各自维护自己独有的一部分参数，这样就能达成通过共享参数实现知识迁移的目的。但是，Share-Bottom结构有他的缺点：如果两个任务不那么相关的话，因为强制共享参数，所以可能任务之间相互干扰，会拉低不同目标的效果。MMOE针对Share-Bottom结构的局限进行了改进，核心思想也很简单，就是把底层全部共享的参数切分成小的子网络，不同任务根据自己的特点，学习配置不同权重的小网络来进行参数共享。这样做的话，即使是两个任务不太相关，可以通过不同的配置来达到模型解耦的目的，而如果模型相关性强，可以共享更多的子网络。明显这样的组合方式更灵活，所以对于MMOE来说，无论是相关还是不相关的任务，它都可以达到我们想要的效果。</p><p>上面介绍的是典型的不同多目标的模型结构，各自有其适用场景和特点。而假设我们选定了模型结构，仍然存在一个很关键的问题：不同优化目标权重如何设定？当然，我们可以根据业务要求，强制制定一些权重，比如视频网站可能更重视时长或者完播率等指标，那就把这个目标权重设置大一些。但是，我们讲过，有些任务之间的指标优化是负相关的，提升某个目标的权重，有可能造成另外一些指标的下跌。所以，如何设定不同目标权重，能够尽量减少相互之间的负面影响，就非常重要。这块貌似目前并没有特别简单实用的方案，很多实际做法做起来还是根据经验拍一些权重参数上线AB测试，费时费力。而如何用模型自动寻找最优权重参数组合就是一个非常有价值的方向，目前最常用的方式是采用帕累托最优的方案来进行权重组合寻优，这是从经济学引入的技术方案，未来还有很大的发展空间。</p><p>典型工作：</p><p>MMOE：Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts</p><p>帕累托最优：A Pareto-Efficient Algorithm for Multiple Objective Optimization in E-Commerce Recommendation</p><p><strong>多模态信息融合</strong></p><p>所谓模态，指的是不同类型的或者模态形式的信息存在形式，比如文本、图片、视频、音频、互动行为、社交关系等，都是信息不同的存在模态形式。如果类比一下的话，就仿佛我们人类感知世界，也是用不同的感官来感知不同的信息类型的，比如视觉、听觉、味觉、触觉等等，就是接受不同模态类型的信息，而大脑会把多模态信息进行融合，来接受更全面更综合的世界知识。类似的，如何让机器学习模型能够接受不同模态类型的信息，并做知识和信息互补，更全面理解实体或者行为。这不仅仅是推荐领域的技术发现趋势，也是人工智能几乎所有方向都面临的重大发展方向，所以这个方向特别值得重视。</p><p>多模态融合，从技术手段来说，本质上是把不同模态类型的信息，通过比如Embedding编码，映射到统一的语义空间内，使得不同模态的信息，表达相同语义的信息完全可类比。比如说自然语言说的单词“苹果”，和一张苹果的图片，应该通过一定的技术手段，对两者进行信息编码，比如打出的embedding，相似度是很高的，这意味着不同模态的知识映射到了相同的语义空间了。这样，你可以通过文本的苹果，比如搜索包含苹果的照片，诸如此类，可以玩出很多新花样。</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/recommend/multi_cross.jpg"></p><p>在推荐场景下，多模态融合其实不是个很有难度的算法方向，大的技术框架仍然遵循目前主流的技术框架，比如DNN Ranking。为了体现多模态集成的目标，可以在User侧或者Item侧，把多模态信息作为新的特征融入，比如加入CNN特征抽取器，把商品图片的特征抽取出来，作为商品侧的一种新特征，不同模态的融入，很可能意味着找到对应的特征抽取器，以新特征的方式融入，而有监督学习的学习目标会指导特征抽取器抽出那些有用的特征。所以，你可以看到，如果在推荐里融入多模态，从算法层面看，并不难，它的难点其实在它处；本质上，多模态做推荐，如果说难点的话，难在工程效率。因为目前很多模态的信息抽取器，比如图片的特征抽取，用深层ResNet或者ReceptionNet，效果都很好，但是因为网络层深太深，抽取图片特征的速度问题就是多模态落地面临的主要问题。所以，本质上，在推荐领域应用多模态，看上去其实是个工程效率问题，而非复杂的算法问题。而且，如果融合多模态的话，离开DNN模型，基本是不现实的。在这点上，可以比较充分体现DNN模型相对传统模型的绝对技术优势。</p><p>多模态信息融合，不仅仅是排序端的一个发展方向，在召回侧也是一样的，比如用用户点击过的图片，作为图片类型的新召回路，或者作为模型召回的新特征。明显这种多模态融合是贯穿了推荐领域各个技术环节的。</p><p>典型工作：</p><p>DNN召回：Collaborative Multi-modal deep learning for the personalized product retrieval in Facebook Marketplace</p><p>排序：Image Matters: Visually modeling user behaviors using Advanced Model Server</p><p><strong>长期兴趣／短期兴趣分离</strong></p><p>对于推荐系统而言，准确描述用户兴趣是非常重要的。目前常用的描述用户兴趣的方式主要有两类。一类是以用户侧特征的角度来表征用户兴趣，也是最常见的；另外一类是以用户发生过行为的物品序列作为用户兴趣的表征。</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/recommend/term_interest.jpg"></p><p>我们知道，用户兴趣其实是可以继续细分的，一种典型的分法就是划分为长期兴趣和短期兴趣。长期兴趣代表用户长久的比较稳定的偏好；而短期兴趣具有不断变化等特点。两者综合，可以从稳定性和变化性这个维度来表征用户偏好。</p><p>最近推荐系统在排序侧模型的演进方向来说，把用户长期兴趣和短期兴趣分离并各自建立模型是个技术小趋势。那么用什么信息作为用户的短期兴趣表征？什么信息作为用户的长期兴趣表征呢？各自又用什么模型来集成这些信息呢？这是这个趋势的三个关键之处。</p><p>目前的常用做法是：用户短期兴趣往往使用用户点击（或购买，互动等其它行为类型）过的物品序列来表征，尤其对于比较活跃的用户，用点击序列更能体现短期的含义，因为出于工程效率的考虑，如果用户行为序列太长，往往不会都拿来使用，而是使用最近的K个行为序列中的物品，来表征用户兴趣，而这明显更含有短期的含义；因为点击序列具备序列性和时间属性，所以对于这类数据，用那些能够刻画序列特性或者物品局部相关性的模型比较合适，比如RNN／CNN和Transformer都比较适合用来对用户短期兴趣建模。</p><p>而用户长期兴趣如何表征呢？我们换个角度来看，其实传统的以特征作为用户兴趣表征的方法，其中部分特征就是从用户长期兴趣出发来刻画的，比如群体人群属性，是种间接刻画用户长期兴趣的方法，再比如类似用户兴趣标签，是种用用户行为序列物品的统计结果来表征用户长期兴趣的方法。这些方法当然可以用来刻画用户长期兴趣，但是往往粒度太粗，所以我们其实需要一个比较细致刻画用户长期兴趣的方式和方法。目前在对长短期兴趣分离的工作中，关于如何刻画用户长期兴趣，往往还是用非常简单的方法，就是用UID特征来表征用户的长期兴趣，通过训练过程对UID进行Embedding编码，以此学习到的UID Embedding作为用户长期兴趣表征，而用户行为序列物品作为用户短期兴趣表征。当然，UID如果用一些其它手段比如矩阵分解获得的Embedding初始化，也是很有帮助的。</p><p>总而言之，用户长期兴趣和短期兴趣的分离建模，应该还是有意义的。长期兴趣目前建模方式还比较简单，这里完全可以引入一些新方法来进行进一步的兴趣刻画，而且有很大的建模空间。</p><p>典型工作：</p><ol><li><p>Neural News Recommendation with Long- and Short-term User Representations</p></li><li><p>Sequence-Aware Recommendation with Long-Term and Short-Term Attention Memory Networks</p></li></ol><h2 id="重排技术演进趋势"><a href="#重排技术演进趋势" class="headerlink" title="重排技术演进趋势"></a><strong>重排技术演进趋势</strong></h2><p>在重排环节，常规的做法，这里是个策略出没之地，就是集中了各种业务和技术策略。比如为了更好的推荐体验，这里会加入去除重复、结果打散增加推荐结果的多样性、强插某种类型的推荐结果等等不同类型的策略。</p><p>按理说，这块没什么可讲的。但是，如果从技术发展趋势角度看，重排阶段上模型，来代替各种花样的业务策略，是个总体的大趋势。</p><p><strong>List Wise重排序</strong></p><p>关于List Wise排序，可以从两个角度来说，一个是优化目标或损失函数；一个是推荐模块的模型结构。</p><p>推荐系统里Learning to Rank做排序，我们知道常见的有三种优化目标：Point Wise、Pair Wise和List Wise。所以我们首先应该明确的一点是：List Wise它不是指的具体的某个或者某类模型，而是指的模型的优化目标或者损失函数定义方式，理论上各种不用的模型都可以使用List Wise损失来进行模型训练。最简单的损失函数定义是Point Wise，就是输入用户特征和单个物品特征，对这个物品进行打分，物品之间的排序，就是谁应该在谁前面，不用考虑。明显这种方式无论是训练还是在线推理，都非常简单直接效率高，但是它的缺点是没有考虑物品直接的关联，而这在排序中其实是有用的。Pair Wise损失在训练模型时，直接用两个物品的顺序关系来训练模型，就是说优化目标是物品A排序要高于物品B，类似这种优化目标。其实Pair Wise的Loss在推荐领域已经被非常广泛得使用，比如BPR损失，就是典型且非常有效的Pair Wise的Loss Function，经常被使用，尤其在隐式反馈中，是非常有效的优化目标。List Wise的Loss更关注整个列表中物品顺序关系，会从列表整体中物品顺序的角度考虑，来优化模型。在推荐中，List Wise损失函数因为训练数据的制作难，训练速度慢，在线推理速度慢等多种原因，尽管用的还比较少，但是因为更注重排序结果整体的最优性，所以也是目前很多推荐系统正在做的事情。</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/recommend/listwise.jpg"></p><p>从模型结构上来看。因为重排序模块往往是放在精排模块之后，而精排已经对推荐物品做了比较准确的打分，所以往往重排模块的输入是精排模块的Top得分输出结果，也就是说，是有序的。而精排模块的打分或者排序对于重排模块来说，是非常重要的参考信息。于是，这个排序模块的输出顺序就比较重要，而能够考虑到输入的序列性的模型，自然就是重排模型的首选。我们知道，最常见的考虑时序性的模型是RNN和Transformer，所以经常把这两类模型用在重排模块，这是很自然的事情。一般的做法是：排序Top结果的物品有序，作为RNN或者Transformer的输入，RNN或者Transformer明显可以考虑在特征级别，融合当前物品上下文，也就是排序列表中其它物品，的特征，来从列表整体评估效果。RNN或者Transformer每个输入对应位置经过特征融合，再次输出预测得分，按照新预测的得分重新对物品排序，就完成了融合上下文信息，进行重新排序的目的。</p><p>尽管目前还没看到CNN做重排的方法，但是从机制上来说，明显CNN也是比较适合用来做重排环节模型的，感兴趣的同学可以试一试。当然，前面说的强化学习，也是非常适合用在List Wise优化的，目前也有不少相关工作出现。</p><p>典型工作：</p><p>1.Personalized Re-ranking for Recommendation</p><p>2.Learning a Deep Listwise Context Model for Ranking Refinement</p><ul><li>本文地址：<a href="https://zhuanlan.zhihu.com/p/100019681">推荐系统技术演进趋势：从召回到排序再到重排</a></li><li>本文版权归作者[张俊林]</li></ul>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
          <category> 推荐 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 模型 </tag>
            
            <tag> 推荐 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HBase内存管理之MemStore进化论</title>
      <link href="/article/HBase%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E4%B9%8BMemStore%E8%BF%9B%E5%8C%96%E8%AE%BA.html"/>
      <url>/article/HBase%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E4%B9%8BMemStore%E8%BF%9B%E5%8C%96%E8%AE%BA.html</url>
      
        <content type="html"><![CDATA[<p>Java工程中内存管理总是一个绕不过去的知识模块，无论HBase、Flink还是Spark等，如果使用的JVM堆比较大同时对读写延迟等性能有较高要求，一般都会选择自己管理内存，而且一般都会选择使用部分堆外内存。HBase系统中有两块大的内存管理模块，一块是MemStore ，一块是BlockCache，这两块内存的管理在HBase的版本迭代过程中不断进行过各种优化，接下来笔者结合自己的理解，将这两个模块的内存管理迭代过程通过几篇文章梳理一遍，相信很多优化方案在各个系统中都有，举一反三，个人觉得对内核开发有很大的学习意义。本篇文章重点集中介绍MemStore内存管理优化。</p><h2 id="基于跳表实现的MemStore基础模型"><a href="#基于跳表实现的MemStore基础模型" class="headerlink" title="基于跳表实现的MemStore基础模型"></a>基于跳表实现的MemStore基础模型</h2><p>实现MemStore模型的数据结构是SkipList（跳表），跳表可以实现高效的查询\插入\删除操作，这些操作的期望复杂度都是O(logN)。另外，因为跳表本质上是由链表构成，所以理解和实现都更加简单。这是很多KV数据库（Redis、LevelDB等）使用跳表实现有序数据集合的两个主要原因。跳表数据结构不再赘述，网上有比较多的介绍，可以参考。</p><p>JDK原生自带的跳表实现目前只有ConcurrentSkipListMap（简称CSLM，注意：ConcurrentSkipListSet是基于ConcurrentSkipListMap实现的）。ConcurrentSkipListMap是JDK Map的一种实现，所以本质上是一种Map，不过这个Map中的元素是有序的。这个有序的保证就是通过跳表实现的。ConcurrentSkipListMap的结构如下图所示：</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/hbase-memstore-evolution/ConcurrentSkipListMap.png"></p><p>基于ConcurrentSkipListMap这样的基础数据结构，按照最简单的思路来看，如果写入一个KeyValue到MemStore中，肯定是如下的写入步骤：</p><ol><li><p>在JVM堆中为KeyValue对象申请一块内存区域。</p></li><li><p>调用ConcurrentSkipListMap的put(K key, V value)方法将这个KeyValue对象作为参数传入。</p></li></ol><span id="more"></span><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/hbase-memstore-evolution/put.png"></p><pre><code>                                                          图1 基于跳表实现的最基础MemStore模型</code></pre><p>对吧，这样的话，实现非常简单。根据Key查询可以利用跳表的有序性。但是这样的内存存储模型会有很多问题（具体见下节），本文就基于这个最原始的模型开始优化之旅。</p><p>再看图1这个存储模型，可以发现MemStore从内存管理上来说主要由两个部分组成，一个是原生KeyValue的内存管理，见上图下半部分；一个是ConcurrentSkipListMap的内存管理，见上图上半部分。接下来笔者分别就这两个部分的内存管理优化，分成两个小节进行深入介绍。</p><h2 id="MemStore中原生KeyValue对象内存存储优化"><a href="#MemStore中原生KeyValue对象内存存储优化" class="headerlink" title="MemStore中原生KeyValue对象内存存储优化"></a>MemStore中原生KeyValue对象内存存储优化</h2><p>对于HBase这样基于LSM实现的MemStore来说，上述实现方案每写入一个KeyValue，在没有写入ConcurrentSkipList之前就需要申请一个内存对象，可以想见，对于很多写入吞吐量几万每秒的业务来说，每秒就会有几万个内存对象产生，这些对象会在内存中存在很长一段时间，对应的会晋升到老生代，一旦执行了flush操作，老生代的这些对象会被GC回收掉。这样的内存玩法，会导致JVM的GC压力非常大。GC压力主要来源于：这些内存对象一旦晋升到老生代，执行完Major GC后会存在大量的非常小的内存碎片，这些内存碎片会引起频繁的Full GC，而且每次Full GC的时间会异常的长。</p><h3 id="MemStore引入MemStoreLAB"><a href="#MemStore引入MemStoreLAB" class="headerlink" title="MemStore引入MemStoreLAB"></a>MemStore引入MemStoreLAB</h3><p>针对上面的问题，MemStore借鉴TLAB（Thread Local Allocation Buffer）机制，实现了MemStoreLAB，简称MSLAB。基于MSLAB实现写入的核心流程如下：</p><ol><li><p>一个KeyValue写入之后不再单独为KeyValue申请内存，而是提前申请好一个2M大小的内存区域（Chunk）。</p></li><li><p>将写入的KeyValue顺序复制到申请的Chunk中，一旦Chunk写满，再申请下一个Chunk。</p></li><li><p>将KeyValue复制到Chunk中后，生成一个Cell对象（这个Cell对象在源码中为ByteBufferChunkKeyValue），这个Cell对象指向Chunk中的KeyValue内存区域。</p></li><li><p>将这个Cell对象作为Key和Value写入ConcurrentSkipListMap中。</p></li><li><p>原生的KeyValue对象写入到Chunk之后就没有再被引用，所以很快就会被Young GC回收掉。</p></li></ol><p>基于MSLAB的MemStore可以表征为下图：</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/hbase-memstore-evolution/MemStore.png"></p><pre><code>                                                          图2 基于MSLAB实现的MemStore示意图</code></pre><p>对比图1和图2，引入MSLAB之后MemStore实现稍显复杂，后者引入了两个长寿内存对象，一个是2M的Chunk对象，一个是指向KV内存区域的Cell对象，这两种内存对象都会晋升到老生代。这里分别针对这两个内存对象进行解读：</p><ol><li><p>引入2M大小的Chunk对象之后，数据写入就不再需要为每个KeyValue申请一个内存对象。这样可以大大降低内存碎片的产生。</p></li><li><p>那Cell对象不会引起内存碎片？这个笔者查阅了很多资料都没有找到相关的说明，个人理解是因为Cell相对原生KeyValue来说占用内存小的多，可以一定程度上可以忽略。Cell与KeyValue对象分别占用内存大小如下所示：</p></li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ByteBufferChunkKeyValue类（Cell对象）的字段如下：</span><br><span class="line">protected final ByteBuffer buf;</span><br><span class="line">protected final int offset;</span><br><span class="line">protected final int length;</span><br><span class="line">private long seqId = 0;</span><br></pre></td></tr></table></figure><p>对象大小可以表示为对象头和各个字段的大小总和，其中对象头占16Byte，Reference类型占8Byte，int类型占4Byte，long类型占8Byte，Cell对象大小可以表示为：ClassSize.OBJECT + ClassSize.REFERENCE + (2 * Bytes.SIZEOF_INT) + Bytes.SIZEOF_LONG &#x3D; 16 + 8 + 2 * 4 + 8 &#x3D; 40 Byte。</p><p>原生KeyValue对象大小为：ClassSize.OBJECT(16) + Key Length(4) + Value Length(4) + Row Length(2) + FAMILY LENGTH(1) + TIMESTAMP_TYPE LENGTH(9) + length(row) + length(column family) + length(column qualifier) + length(value) &#x3D; 36 + length(row) + length(column family) + length(column qualifier) + length(value)</p><p>按照一个KV中length(row) + length(column family) + length(column qualifier) + length(value)总计84Byte算，原生KeyValue对象大小为120Byte，为Cell对象的3倍。</pre></p><p>引入MSLAB后一定程度上降低了老生代内存碎片的产生，进而降低了Promotion Failure类型的Full GC产生。那还有没有进一步的优化空间呢？针对Chunk，还有两个大的优化思路：</p><h3 id="MemStore引入ChunkPool"><a href="#MemStore引入ChunkPool" class="headerlink" title="MemStore引入ChunkPool"></a>MemStore引入ChunkPool</h3><p>MSLAB机制中KeyValue写入Chunk，如果Chunk写满了会在JVM堆内存申请一个新的Chunk。引入ChunkPool后，申请Chunk都从ChunkPool中申请，如果ChunkPool中没有可用的空闲Chunk，才会从JVM堆内存中申请新Chunk。如果一个MemStore执行flush操作后，这个MemStore对应的所有Chunk都可以被回收，回收后重新进入池子中，以备下次使用。基本原理如图3、图4所示：</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/hbase-memstore-evolution/ChunkPool.png"></p><pre><code>                                                        图3 基于ChunkPool实现的Chunk管理模型</code></pre><p>每个RegionServer会有一个全局的Chunk管理器，负责Chunk的生成、回收等。MemStore申请Chunk对象会发送请求让Chunk管理器创建新Chunk，Chunk管理器会检查当前是否有空闲Chunk，如果有空闲Chunk，就会将这个Chunk对象分配给MemStore，否则从JVM堆上重新申请。每个MemStore仅持有Chunk内存区域的引用，如图3中MemStoreLAB的小格子。</p><p>下图是MemStore执行Flush之后，对应的所有Chunk对象中KV落盘形成HFile，这部分Chunk就可以被Chunk管理器回收到空闲池子。</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/hbase-memstore-evolution/chunk.png"></p><pre><code>                                                        图4 MemStore Flush过程中Chunk回收过程</code></pre><p>使用ChunkPool的好处是什么呢？因为Chunk可以回收再使用，这就一定程度上降低了Chunk对象申请的频率，有利于Young GC。</p><h3 id="MemStore-Offheap实现"><a href="#MemStore-Offheap实现" class="headerlink" title="MemStore Offheap实现"></a>MemStore Offheap实现</h3><p>除过ChunkPool之外，HBase 2.x版本针对Chunk对象优化的另一个思路是将Chunk使用的这部分内存堆外化。关于堆外内存的细节内容，笔者将会在下篇文章重点分析，这篇文章只做个简单介绍。</p><p>Chunk堆外化实现比较简单，在创建新Chunk时根据用户配置选择是否使用堆外内存，如果使用堆外内存，就使用JDK提供的ByteBuffer.allocateDirect方法在堆外申请特定大小的内存区域，否则使用ByteBuffer.allocate方法在堆内申请。如果不做配置，默认使用堆内内存，用户可以设置hbase.regionserver.offheap.global.memstore.size这个值为大于0的值开启堆外，表示RegionServer中所有MemStore可以使用的堆外内存总大小。</p><h3 id="原生KeyValue对象内存存储优化总结"><a href="#原生KeyValue对象内存存储优化总结" class="headerlink" title="原生KeyValue对象内存存储优化总结"></a>原生KeyValue对象内存存储优化总结</h3><p>基于原生KeyValue直接写入ConcurrentSkipListMap方案，HBase在之后的版本中不断优化，针对原生KeyValue内存管理部分分别采用MemStoreLAB机制、ChunkPool机制以及Chunk Offheap机制三种策略，对GC性能进行持续优化。</p><p>第一节我们提到MemStore内存管理分为原生KeyValue内存管理和ConcurrentSkipListMap内存管理两个部分，第二节重点介绍了HBase针对原生KeyValue内存管理所采用的3种优化方案。接下来第三节首先介绍JDK原生ConcurrentSkipListMap在内存管理方面的主要问题，以及HBase在2.x版本以及3.x版本针对ConcurrentSkipListMap内存管理问题进行优化的两个方案。</p><h2 id="ConcurrentSkipListMap数据结构存在的问题以及优化方案"><a href="#ConcurrentSkipListMap数据结构存在的问题以及优化方案" class="headerlink" title="ConcurrentSkipListMap数据结构存在的问题以及优化方案"></a>ConcurrentSkipListMap数据结构存在的问题以及优化方案</h2><h3 id="一个KV在MemStore中的旅程"><a href="#一个KV在MemStore中的旅程" class="headerlink" title="一个KV在MemStore中的旅程"></a>一个KV在MemStore中的旅程</h3><p>经过上面知识的铺垫我们知道，一个KV写入MemStore会经过如下几个核心步骤：</p><ol><li><p>在Chunk中申请一段与KV相同大小的内存空间将KV拷贝进去。</p></li><li><p>生成一个Cell对象，该对象包含指向Chunk中对应数据块的指针、offsize以及length。</p></li><li><p>将这个Cell对象分别作为Key和Value插入到CSLM表示的跳表Map中。</p></li></ol><p>有了CSLM这样的跳表之后，查询就可以在O(N)时间复杂度内完成。但是，JDK实现的CSLM跳表在内存使用方面有些粗糙，导致内存中产生了大量意义不大的Java对象，这些Java对象的频繁产生一方面导致内存效率使用比较低，另一方面会引起比较严重的Java GC。为什么JDK实现的CSLM跳表会有这样的问题？接着往下看。</p><h3 id="MemStore-ConcurrentSkipListMap数据结构存在的问题"><a href="#MemStore-ConcurrentSkipListMap数据结构存在的问题" class="headerlink" title="MemStore ConcurrentSkipListMap数据结构存在的问题"></a>MemStore ConcurrentSkipListMap数据结构存在的问题</h3><p>原生ConcurrentSkipListMap逻辑示意图如下图所示：</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/hbase-memstore-evolution/cslm.png"></p><pre><code>                                                                    图5 CSLM示意图</code></pre><p>JDK自带的CSLM每个节点都是一个对象，其中最底层节点是Node对象，其他上层节点是Index对象。Node对象和Index对象的核心字段可以参考CSLM源码实现：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Nodes hold keys and values, and are singly linked in sorted</span></span><br><span class="line"><span class="comment"> * order, possibly with some intervening marker nodes. The list is</span></span><br><span class="line"><span class="comment"> * headed by a dummy node accessible as head.node. The value field</span></span><br><span class="line"><span class="comment"> * is declared only as Object because it takes special non-V</span></span><br><span class="line"><span class="comment"> * values for marker and header nodes.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">class</span> <span class="title class_">Node</span>&lt;K,V&gt; &#123;</span><br><span class="line">    <span class="keyword">final</span> K key;</span><br><span class="line">    <span class="keyword">volatile</span> Object value;</span><br><span class="line">    <span class="keyword">volatile</span> Node&lt;K,V&gt; next;</span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Index nodes represent the levels of the skip list.  Note that</span></span><br><span class="line"><span class="comment"> * even though both Nodes and Indexes have forward-pointing</span></span><br><span class="line"><span class="comment"> * fields, they have different types and are handled in different</span></span><br><span class="line"><span class="comment"> * ways, that can&amp;#39;t nicely be captured by placing field in a</span></span><br><span class="line"><span class="comment"> * shared abstract class.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Index</span>&lt;K,V&gt; &#123;</span><br><span class="line">    <span class="keyword">final</span> Node&lt;K,V&gt; node;</span><br><span class="line">    <span class="keyword">final</span> Index&lt;K,V&gt; down;</span><br><span class="line">    <span class="keyword">volatile</span> Index&lt;K,V&gt; right;</span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>其中Node对象由一个key、一个value以及指向下一个Node节点的引用组成。Index对象由一个Node节点引用、向下和向右的引用组成。</p><p>根据上述代码可以知道：</p><ol><li><p>每个Node对象有3个引用变量，分别指向Key（Cell对象）、Value（Cell对象）以及Next Node。</p></li><li><p>每个Index对象有3个引用变量，分别指向代表的Node节点，下层Index节点以及右侧Index节点。</p></li></ol><p>假设业务写入50M规模的KV，那写入到MemStore后，除了正常存储KV数据占用的Chunk对象外，CSLM占用的对象和内存分别有多少呢？</p><ol><li><p>对象数：50M个Node对象，假如跳表中level N层的Index节点个数是50M&#x2F;2^(N+2)，那么总共会有50M&#x2F;4个Index对象。整个CSLM一共有62.5M个对象。</p></li><li><p>内存占用情况（均认为JVM设置大于32G，未开启压缩指针）：</p></li></ol><p>（1）Node对象</p><pre class="prettyprint lang-js">50M * (ClassSize.OBJECT + ClassSize.REFERENCE + ClassSize.REFERENCE + ClassSize.REFERENCE) ＝50M * (16 + 8 + 8 + 8) = 2000M</pre><p>（2）Index对象</p><pre class="prettyprint lang-js">12.5M * (ClassSize.OBJECT + ClassSize.REFERENCE + ClassSize.REFERENCE + ClassSize.REFERENCE) ＝12.5M * (16 + 8 + 8 + 8)  = 500M</pre><p>总内存占用2500M。假设业务写入的KV为50Byte，那总的数据量为2500M。为了存储这2500M大小的数据，MemStore又产生了额外的2500M内存。</p><h3 id="CompactingMemStore如何优化这个困境"><a href="#CompactingMemStore如何优化这个困境" class="headerlink" title="CompactingMemStore如何优化这个困境"></a>CompactingMemStore如何优化这个困境</h3><p>CompactingMemStore的核心工作原理如图所示：</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/hbase-memstore-evolution/CompactingMemStore.png"></p><pre><code>                                                   图6 CompactingMemStore核心工作原理示意图</code></pre><ol><li>一个Cell写入到Region后会先写入MutableSegment中。MutableSegment可以认为就是一个小的MemStore，MutableSegment包含一个MSLAB存储Chunk，同时包含一个ConcurrentSkipListMap。</li><li>默认情况下一旦MutableSegment的大小超过2M，就会执行In-memory Flush操作，将MutableSegment变为ImmutableSegment，并重新生成一个新的MutableSegment接收写入。ImmutableSegment有多个实现类，In-memory Flush生成的ImmutableSegment为CSLMImmutableSegment，可以预见这个ImmutableSegment在数据结构上也是使用CSLM。</li><li>每次执行完In-memory Flush之后，RegionServer都会启动一个异步线程执行In-memory Compaction。In-memory Compaction的本质是将CSLMImmutableSegment变为CellArrayImmutableSegment或者CellChunkImmutableSegment，这才是CompactingMemStore最核心的地方。那什么是CellArrayImmutableSegment&#x2F;CellChunkImmutableSegment呢？为什么要做这样的转换？接着往下看。</li></ol><h4 id="In-memory-Compaction机制"><a href="#In-memory-Compaction机制" class="headerlink" title="In-memory Compaction机制"></a>In-memory Compaction机制</h4><p>现在我们需要回过头来想想这两个问题：</p><ol><li><p>为什么要将一个大的MemStore切分成这么多小的Segment？这么设计的初衷是为In-memory Compaction做准备，只有将MemStore分为MutableSegment和ImmutableSegment，才可能基于ImmutableSegment进行内存优化。</p></li><li><p>如何对ImmutableSegment进行内存优化？答案是将CSLMImmutableSegment变为CellArrayImmutableSegment或者CellChunkImmutableSegment。通过上文的介绍我们知道，CSLM这种数据结构对内存并不友好，因为ImmutableSegment本身已经不再接收任何更新删除写入操作，只允许读操作，这样的话CSLM就可以转换为对内存更加友好的Array或者其他的数据结构。这个转换就是In-memory Compaction。</p></li></ol><p>理清楚上面两个问题，我们再来看看In-memory Compaction的主要流程。如果参与Compaction的Segment只有一个，我们称之为Flatten，非常形象，就是将CSLM拉平为Array或者Chunk，示意图如下图图7所示。</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/hbase-memstore-evolution/flatten.png"></p><pre><code>                                 图7 In-Memory Compaction之Flatten示意图</code></pre><p>紧接着就有两个问题：CSLMImmutableSegment是如何拉平成CellArrayImmutableSegment？CellArrayImmutableSegment和CellChunkImmutableSegment分别是什么样的数据结构？</p><p>CSLMImmutableSegment拉平成CellArrayImmutableSegment比较容易理解，顺序遍历CSLMImmutableSegment读取出对应的Cell，顺序写入一个申请好的数组即可。所以直观上看，CSLMImmutableSegment和CellArrayImmutableSegment相比就是将CSLM变成了一个数组。</p><p>那CellArrayImmutableSegment能不能进一步优化呢？是不是可以将Array[Cell]这样一个在内存中不完全连续的对象转变成一块完全连续内容空间的对象，这种优化方式也比较自然，借鉴Chunk思路申请一块2M的大内存空间，遍历数组中的Cell对象，将其顺序拷贝到这个Chunk（这种Chunk称为Index Chunk，区别与存储KV数据的Data Chunk）中，就变成了CellChunkImmutableSegment，将内存由不连续变为连续的一大好处就是变换后连续的内存区域可以在堆外管理，默认情况下In-memory Compaction会直接将CSLMImmutableSegment拉平成CellChunkImmutableSegment。</p><p>上述过程是只有一个Segment参与Compaction的流程。如果参与Compaction的Segment个数超过1个，会有两种Compaction的形式：Merge和Compact。先说Merge，Merge的处理流程和Flatten基本一致，如示意图xxx所示，左侧两个Segment进行合并形成右侧一个大的CellChunkImmutableSegment，合并过程就是顺序遍历左边两个Segment，取出对应的Cell，然后顺序写入右边CellChunkImmutableSegment中。</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/hbase-memstore-evolution/merge.png"></p><pre><code>                                                          图8 In-Memory Compaction之Merge示意图</code></pre><p>Compaction与Merge的处理流程基本相同，不同的是，Compaction在合并的过程中顺序遍历左边两个Segment，读取对应Cell之后会检测是否有多个版本的Cell，如果存在超过设置版本数的Cell，就将老版本的Cell删掉。因为存在原始KV的变更，所以新生成的Data Chunk会进行重建，这是和Merge最大的不同。如示意图所示，右侧新生成的CellChunkImmutableSegment的Data Chunk是经过重建过的。</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/hbase-memstore-evolution/Compaction.png"></p><pre><code>                                            图9 In-Memory Compaction之Compaction示意图</code></pre><p>CompactingMemStore通过将CSLM数据结构变成Array或者Chunk，优化了CSLM数据结构本身内存利用效率低的问题，提升GC效率。另外，提升内存利用率可以使MemStore中存储下更多的KV数据，进而减少Flush和Compaction发生的频率，提升整个HBase集群的性能。</p><h2 id="CCSMap又是如何优化CSLM？"><a href="#CCSMap又是如何优化CSLM？" class="headerlink" title="CCSMap又是如何优化CSLM？"></a>CCSMap又是如何优化CSLM？</h2><p>CCSMap全称CompactedConcurrentSkipListMap，是阿里巴巴内部版本为了优化CSLM数据结构内存利用效率低所实现的一个新的数据结构。CCSMap数据结构的基本理念是将原生的ConcurrentSkipListMap进行压缩，压缩的直观效果如下图所示：</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/hbase-memstore-evolution/ccsmap.png"></p><pre><code>                                            图10 CCSMap数据结构逻辑示意图</code></pre><p>上图中上面结构是原生的CSLM数据结构，下面是CCSMap数据结构，很明显，主要是将Index对象压缩到了Node对象上，数据写入&#x2F;读取流程和CSLM基本上一致。压缩后可以抹掉Index对象，但是这样的优化显然不是全部。接下来的优化才是重点。</p><p>CCSMap数据结构可以认为只有一个Node对象（Index可以理解为Node对象的一个字段），既然只有一种对象，是否可以借鉴MSLAB的思路将Node对象顺序存储到固定大小的Chunk中，这样做的好处显而易见：整个Chunk可以以大块申请，同时可以在堆外申请。CCSMap就是基于这个思路进行的物理存储设计，笔者根据相关Jira上给出的资料以及阅读源代码画出来的一个物理存储示意图：</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/hbase-memstore-evolution/ccsmap_data.png"></p><pre><code>                                                        图11 CCSMap数据结构物理实现示意图</code></pre><p>这里有个认知的转换，在CSLM数据结构下，KV就是KV，但是在CCSMap数据结构下，KV需要包装成Node对象，Node对象的核心字段如下：</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/hbase-memstore-evolution/ccsmap_node.png"></p><p>Node对象除了正常的KV Data之外，还有几个比较重要的字段，meta字段主要存储level，dataLen存储数据大小，nextNode存储当前节点的后继节点，levelIndex是一个数组，表示这个Node在各个Level上Index指向的Node(NodeId)。这样一个Node对象就可以完全表征逻辑示意图中Node节点。</p><p>当然在具体实现中如何根据Index存储的一个long类型的NodeId在CCSMap中找到对应的Node，这里面有个小小的技巧，就是这个long类型的NodeId前4Byte表示ChunkId，后4Byte表示对应Node在指定Chunk上的偏移量，这样就可以根据NodeId轻松读取到这个Node对应的内存空间。</p><p>根据物理存储示意图，KV数据写入的时候会首先包装成一个Node对象，包装的过程主要是生成level字段，然后根据跳表规则不断查找，确定对应的nextNode和levelIndex[]两个字段。Node对象封装好之后就可以顺序持久化到Chunk中。</p><h3 id="CCSMap相比CSLM可以节省多少对象？多少内存？"><a href="#CCSMap相比CSLM可以节省多少对象？多少内存？" class="headerlink" title="CCSMap相比CSLM可以节省多少对象？多少内存？"></a>CCSMap相比CSLM可以节省多少对象？多少内存？</h3><ol><li><p>减少多少对象？CCSMap将ConcurrentSkipListMap和KV对象一起放到Chunk中去了，所以没有任何对象开销，这点比原生的CSLM优秀了非常多。</p></li><li><p>减少了多少内存？还是假设业务写入50M规模的KV，CCSMap中Node对象中long[] levelIndex会占用12.5M * 8Byte &#x3D; 100M，另外，dataLen占用4Byte，nextNode占用8Byte，meta占用4Byte，总共占用50 * 16Byte &#x3D; 800M。所以总计占用900M。相比CSLM的2500M，降低了64%。</p></li></ol><h2 id="MemStore内存进化总结"><a href="#MemStore内存进化总结" class="headerlink" title="MemStore内存进化总结"></a>MemStore内存进化总结</h2><p>基于上述长篇大论，我们知道MemStore的内存主要分为两部分，其中一部分是KV存储本身，一部分是CSLM。文中第二节重点介绍了KV存储本身的几个优化思路，包括MSLAB、ChunkPool以及Chunk Offheap等，第三节分别重点介绍了使用CompactingMemStore和CCSMap两种机制对CSLM数据结构进行优化的原理。其实，优化来优化去，最核心的落脚点还是能不能将对象顺序持久化到连续一段内存（Chunk）上，抓住这个最终落脚点非常重要。</p><p>最后说点题外话，前一段时间JDK13发布，进一步增强了ZGC特性。ZGC应该是Java历史上最大的改进之一，这点应该没有任何疑问，TB级别的堆可以保证GC时间低于10ms，实际场景中128G内存最大GC时间才1.68ms。如果真是这样的GC性能，可能很多现在我们做的各种内存管理优化在很多年之后都不再是问题。</p><ul><li>本文地址：<a href="http://hbasefly.com/2019/10/18/hbase-memstore-evolution/">HBase内存管理之MemStore进化论</a></li><li>本文版权归作者和<a href="http://hbasefly.com/">hbasefly</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> HBase </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HBase </tag>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>从一句情话来了解语言模型的发展</title>
      <link href="/article/%E4%BB%8E%E4%B8%80%E5%8F%A5%E6%83%85%E8%AF%9D%E6%9D%A5%E4%BA%86%E8%A7%A3%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%91%E5%B1%95.html"/>
      <url>/article/%E4%BB%8E%E4%B8%80%E5%8F%A5%E6%83%85%E8%AF%9D%E6%9D%A5%E4%BA%86%E8%A7%A3%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%91%E5%B1%95.html</url>
      
        <content type="html"><![CDATA[<h2 id="问题定义"><a href="#问题定义" class="headerlink" title="问题定义"></a>问题定义</h2><p>一段文字，例如：今夜月色真美。代表的是什么含义？如果在春天温度适宜的 9、10 点站在阳台的人对你脱口而出地说出这句话，你会怎么理解这句话，亦或者你会怎么回应他(她)呢？</p><p>这句话是十九世纪末的文学家 夏目漱石对 <code>I love you</code> 的英译日标注结果（今夜は月が綺麗ですね）。根据他的标注 <code>我爱你</code> 和 <code>今夜月色真美</code> 表达了相同的意义。但是计算机这么认为吗？输入 <code>今夜月色真美</code>，它理解这句话和 <code>我爱你</code> 是相似的含义吗？这个可以被归类为自然语言理解(NLU)领域的语义匹配问题。</p><p>众所周知在计算机中一切都是数字信号，那么如果想让计算机理解一句话的含义，解决 <code>今夜月色真美</code> 和 <code>我爱你</code> 的语义匹配问题，那么先决问题是将一句话表示为一系列的数字信号。一个理所当然的想法是将语料库中的每一个词w用一个唯一的 n 维向量v&#x3D;[v1​,v2​,…,vn​]来表达，那么数个向量的序列seq&#x3D;{v1​,v2​,…,vm​}就可以表达一句话，这一类方法就是词嵌入模型。本期文章通过对比这个 case 在 <code>one-hot </code>、<code>n-gram </code>、<code>word2vec </code>、<code>BERT</code> 四种语言模型的结果，分析各个方法的优缺点。</p><h2 id="one-hot"><a href="#one-hot" class="headerlink" title="one-hot"></a>one-hot</h2><p>一个最简单的想法就是使用 one-hot 向量来表达一个词。具体流程：</p><ol><li>遍历语料库，统计词的集合W，集合大小为K</li><li>将每个词在集合W中的下标的元素为 1，其他位置元素为 0，构建长度为K的 0-1 向量</li></ol><p>假设我们对 <code>今夜月色真美</code> 的分词结果为：今夜、月色、真、美。那么使用 one-hot 向量就能将这个句子表示为4×K的 0-1 矩阵。我们假设语料库中一共有 10 个词：{我、爱、你、今夜、月色、真、美、今晚、漂亮、喜欢}。那么V今夜​&#x3D;[0,0,0,1,0,0,0,0,0]，V今晚​&#x3D;[0,0,0,0,0,0,0,1,0,0]，V我​&#x3D;[1,0,0,0,0,0,0,0,0,0]。</p><p>one-hot 词嵌入方法优点在于简单，并且最大程度地保留了每个词的信息。但是缺点也很明显：</p><ol><li>对于从未出现在语料库中的未登录词，无法进行兼容。假如词 <code>恨</code> 需要编码，那么只能编码为零向量，否则需要对所有词向量进行更新，扩展向量维度。</li><li>丢失了词与词之间的相关信息。例如 <code>今夜</code> 和 <code>今晚</code> 本身是相近语义的词，但是通过 one-hot 编码的向量差异并没有比 <code>我</code> 和 <code>今夜</code> 小。</li></ol><span id="more"></span><h2 id="统计语言模型：N-GRAM"><a href="#统计语言模型：N-GRAM" class="headerlink" title="统计语言模型：N-GRAM"></a>统计语言模型：N-GRAM</h2><p>one-hot 词嵌入方法有以上的缺点，我们希望去改进这些缺点。所以我们先关注于第二点，如何保留词与词之间的相关关系。很自然的，会想到用一个词以及其邻近的词来共同表示这个词。例如：<code>今夜</code> 和 <code>今晚</code> 由于他们是相似词，所以他们是互相可以替换。例如将 <code>今晚天气真好</code> 替换为 <code>今夜天气真好</code>。这句话的语义不会发生大的变化。因此一个假设：对于词 <code>A</code> 与词 <code>B</code>，A,B∈W，W是语料库中所有词的集合有：</p><p>if R(A,B)&#x3D;1 then P(C∣A)&#x3D;P(C∣B),C∈W</p><p>P(C∣A)表示在一条语料中出现词A后出现词C的概率。以上一个例子为例，对于天气这个词来与今晚和今夜分别共现的语料条数为N和M。假设出现今晚的语料共N′条，今夜的语料共M′条，那么按照假设会有N′N​&#x3D;M′M​。</p><p>假设我们已经统计出了 <code>今晚</code> 这个词对其他所有词(包括今晚)的条件概率P(C∣今晚)。那么我们可以把 one-hot 向量上的每一个分量替换为今晚对这个位置上对应词的条件概率。这样构成的向量在上述假设下，今晚和今夜的结果应是相似的。并且在这个词向量上所有分量之和等于 1。</p><p>基于共现条件概率构建的词向量在短文本上效果还不错，但是仍然有两个的缺点：</p><ol><li>违反了人书写的概率模型，因为人书写都是自然的从左到右。一个词对出现在其前面的词不会产生影响。</li><li>无视了距离对词的依赖关系的影响，假设词同等依赖于所有位置的词。但是对于长文本而言，这个假设显然不成立。</li></ol><p>为了补充以上两个缺点，我们考虑 N-Gram 统计概率模型代替共现条件概率。</p><p>N-Gram 模型假设人的书写过程是随机过程，其概率图为一个有向无环图：</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/nlp/ngram.png"></p><p>按照上图，<code>今夜月色真美</code> 这个语料中每个词出现的概率为P(w4​&#x3D;美∣w0​&#x3D;start,w1​&#x3D;今夜,w2​&#x3D;月色,w3​&#x3D;真)，P(w3​&#x3D;真∣w0​&#x3D;start,w1​&#x3D;今夜,w2​&#x3D;月色)，P(w2​&#x3D;月色∣w0​&#x3D;start,w1​&#x3D;今夜)，P(w1​&#x3D;今夜∣w0​&#x3D;start)。</p><p>进一步为了降低距离对词依赖的影响，也同时为了语料库规模与计算能力的局限所考虑，N-Gram 模型假设人书写的随机过程满足N阶马尔科夫条件。如果满足二阶马尔科夫条件的模型称为 Bi-Gram。</p><p>在 Bi-Gram 下每个词出现的概率可以描述为P(w4​&#x3D;美∣w3​&#x3D;真)，P(w3​&#x3D;真∣w2​&#x3D;月色)，P(w2​&#x3D;月色∣w1​&#x3D;今夜)，P(w1​&#x3D;今夜∣w0​&#x3D;start)。</p><p>由此共现条件概率的两个缺点使用 N-Gram 模型能很好的弥补。在实际使用上一般会将start单独作为作为一个词，会将 <code>今夜月色真美</code> 改写为 <code>[start]今夜月色真美</code>，然后在语料中统计P(w1​&#x3D;今夜∣w0​&#x3D;start)。同理我们可以在向量中加入 Uni-Gram(满足一阶马尔科夫条件)、Tri-Gram(满足三阶马尔科夫条件)，甚至可以加入更高阶的 Gram 模型，来组成 N-Gram 的词嵌入，在实际应用中一般不会使用高于三阶的模型。</p><p>N-Gram 词嵌入在实际应用上游很多的 Trick。这些 Trick 主要要解决有限语料库与概率估计之间的权衡。对于长尾的词组，直接使用统计值进行估计往往不准确，可能会存在偏差。更多的时候会采用统计平滑方法对统计条件概率进行平滑，常用 Good-Turing 平滑或者 Kneser-Ney 平滑等，在这篇博客中有对其详细介绍：<a href="https://www.6aiq.com/forward?goto=">NLP 笔记 - 平滑方法(Smoothing)小结</a> 笔记 - 平滑方法(Smoothing)小结&#x2F;)。</p><p>基于 N-Gram 词嵌入在实践过程中还有很多基于矩阵分解的变体，因为所有词向量的矩阵可以构成一个高维对称矩阵，在这个矩阵上可以应用类似于 SVD 分解、QR 分解等等方法对矩阵进行分解，得到性质更好的向量。</p><h2 id="神经语言模型"><a href="#神经语言模型" class="headerlink" title="神经语言模型"></a>神经语言模型</h2><p>N-Gram 是统计语言模型的一个经典方法。当满足其假设条件的情况下，统计语言模型的效果很好。但是在实际应用场景情况下，很难满足统计语言模型的假设条件：</p><ol><li>书写过程是一个先决定一个词，再决定下一个词的序列随机过程</li><li>随机过程满足N阶马尔科夫条件</li></ol><p>但是在实际的场景下上述两个假设条件往往难以满足。最简单的例子是，我们在高考作文中经常会写三段式议论文文章，往往会先在开头引出结论，然后再在后续对开头的结论进行证明，最后在文章末尾对文章的论点进行总结。从这种书写方式来说，首先开头外的所有文字都是为开头的论点服务，因此马尔科夫条件的 N 阶可能会非常高，甚至说无法满足这个条件。其次词的随机过程首先会有一个名为论点的先验分布。其次 <code> 今天天气不错哇</code> 和 <code> 天气不错哇，今天</code>，在口头表达中表达的是相同意思，但是其词序有差异。这说明人的书写顺序并非是从左到右的阅读顺序。在不满足其假设条件的情况下。N-Gram 语言的效果往往会大打折扣。因此在神经语言模型兴起之后，基于 Mask Language Model(MLM)的嵌入方法开始流行。</p><p>MLM 的基本思想是将一段文字随机隐藏一部分文字，学习目标是重构这段文字。一般我们把一个<strong>单位</strong>的文字称为一个 <strong>token</strong> 例如 <code>今夜月色真美</code> 这段文字，Mask <code>真</code> 这个词之后，这段文字变成了 <code>今夜月色[mask]美</code>。模型的任务就是预测被 mask 的 token 是什么。常用的 Mask 策略有：</p><ol><li>随机 Mask 一个 token（CBOW）</li><li>只保留一个 Token，其他所有 Token 都被 Mask（SKIP-GRAM）</li><li>随机 Mask 一定比例的 Token（BERT）</li><li>随机 Mask 一段 Token 序列（SpanBERT）</li><li>按照语序从后往前 Mask 一段 Token 序列（XLNET）</li></ol><p>由于篇幅限制，本文只介绍 Word2Vec 和 BERT 以及 XLNET。</p><h3 id="Word2vec"><a href="#Word2vec" class="headerlink" title="Word2vec"></a>Word2vec</h3><p>上文所说的 CBOW 和 SKIP-GRAM 都是 word2vec 的两种训练方法。相信大家对 word2vec 的大名都有一定了解。作为词嵌入方法上最具代表性的模型，目前在工业界基本上是嵌入方法的代表模型。并且在之外有 <code>GloV</code>、 <code>ELM</code> 等一系列衍生方法。各位感兴趣的读者可以了解一下。</p><p>word2vec 的模型架构整体上比较简单：</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/nlp/word2vec.png"></p><ul><li>Input Vector：CBOW 模型的输入层是被 mask 的 token 附近多个被保留 token 的 one-hot 向量之和，SKIP-GRAM 模型的输入层是被保留的一个 token 的 one-hot 向量</li><li>Hidden Layer：两到三层的 MLP</li><li>Output Layer：使用 softmax 激活函数来对 token 进行预测，CBOW 模型预测被 mask 的 token，SKIP-GRAM 预测被保留的 token 附近多个被 mask 的 token。见图：</li><li>将隐藏层的第一层的矩阵A提取出来，将每个词的 one-hot 向量x与A的乘积Ax作为这个词的向量(实际上就是取了A矩阵对应位置的行向量)。</li></ul><p>使用 Word2Vec 要如何对 <code>今夜月色真美</code> 及进行理解呢？为了方便描述我们不妨假设除了 <code>美</code> 之外的词，现在模型已经完全理解了。现在的问题是如何使用现有的语料对 <code>美</code> 进行学习。由于每次使用反向传播来更新矩阵A的值，而且将 word2vec 将未被 mask 的 token 作为输入，所以每次训练的是未被 mask 部分的 token 的向量。因此直接的想法是将 <code>美</code> 保留，<code>今夜月色真</code> 被 mask。这样每次训练的就是 <code>美</code> 这个词，通过语料库中所有带 <code>美</code> 这个 token 的语料，我们可以不断更新矩阵A的值，得到 <code>美</code> 的向量。</p><p>上述描述的就是 SKIP-GRAM 模型。通过在语料库中不断学习，模型学习到 <code>美</code> 描述了 <code>今夜月色真</code>。通过大量的语料，模型也会学习到 <code>美</code> 用来描述其他东西，得到在全体语料库的 <code>美</code> 表达的共同点(向量)。</p><p>与 SKIP-GRAM 相反，如果要学习 <code>美</code> 的向量，需要将 <code>美</code> 保留，而 mask 其他 token。如果要训练 <code>美</code> 的想来那个，那么 <code>今夜真美</code> 预测 <code>月色</code>，<code>今夜月色美</code> 预测 <code>真</code> 这些样本需要参与模型训练。从学习方式上看，CBOW 一次会对多个 token 进行学习，在学习一个具体的 token 的时候会受到同句其他 token 的影响。因此在一些长尾 token 上 CBOW 效果不如 SKIP-GRAM。</p><p>通过 Word2vec 我们可以学习到 <code>今夜</code>、<code>月色</code>、<code>真</code>、<code>美</code>、<code>我</code>、<code>爱</code>、<code>你</code>。每个 token 的表达。那么可以得到 <code>今夜</code>+<code>月色</code>+<code>真</code>+<code>美</code>&#x3D;<code>我</code>+<code>爱</code>+<code>你</code> 吗？不考虑特殊的语料库的情况下，Word2vec 很难学习到这个信息。因为从上文描述的学习方法来看，word2vec 学习的是在统计情况下，一个普遍的上下文情况下一个词的意义。但是对于一个特定的对话场景下一个词在不同的语境下的信息无法表达。最明显的就是 <code>苹果手机</code> 和 <code>山东烟台苹果</code> 两句话的中 <code>苹果</code> 是表达的不是同一个意思。而对于 Word2vec 这类词嵌入模型，一个 token 的表达是固定的。</p><p>回到 <code>今夜月色真美</code>，其中说的就是今夜的月色吗？为了方便解释，我们不妨将 <code>今夜月色</code> 解释为是一种指代，指代的是 <code>你</code>。所以这句话可以被转换为 <code>你真美</code>，另外 <code>今夜月色</code> 在这句话中又承担了环境的语境。完全展开为 <code>今天晚上在月色的衬托下你真美</code>，进一步在这种氛围下赞美异性，所表达的含义即是 <code>I love you</code>。但是 word2vec 这种静态的词嵌入方法下，一个词只会有一种语义，那么在包含两种语义的 <code>今夜月色</code> 成为了这段翻译的主要问题。</p><h3 id="BERT：Bidirectional-Transformer"><a href="#BERT：Bidirectional-Transformer" class="headerlink" title="BERT：Bidirectional Transformer"></a>BERT：Bidirectional Transformer</h3><p>那么如何才能保留一个词在不同语境下的信息呢？很简单，直接学习一整句话就可以了。之前我们在训练 word2vec 的时候，采用了第一层的隐层权重作为每个词的权重。但是实际上我可以把任意一个 token 序列放入这个模型中，然后取任意隐藏层的输出结果作为句子级的表示。这类预训练模型主要有两种类型：</p><ol><li><strong>frozen</strong> 模型：在预训练语料上训练后，模型参数固定不变。</li><li><strong>fine-tuning</strong> 模型：在预训练语料上训练后，会随着子任务继续微调模型参数。</li></ol><p>frozen 模型的代表是 ELMo，是 NAACL18 Best Paper。fine-tuning 模型的代表是 Google 在 2018 年发表的 BERT 模型。关于 BERT，强烈推荐大家看财大气粗的 Google 在 19 年发表的论文：<a href="https://arxiv.org/pdf/1910.10683.pdf">Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer</a>，在模型中 Google 对于各种 BERT 上的 trick 进行了实验效果对比。包括 Mask 策略的选择，模型参数的选择等等。本文就不详细展开了。</p><p>BERT 是 Bidirectional Transformer 的缩写，关于 Transformer 大家可以看之前写的这篇博客：<a href="https://www.6aiq.com/article/1590176752335">算法工程师必知必会的经典模型系列一：Transformer 模型串讲</a>。Bidirectional Transformer 相较于 <a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need</a> 中描述的 Transformer 差异主要体现在只使用了其中的 Encoder 部分，但是不代表选择 Encoder 部分就是最优的。甚至在 Google 后续的论文中指出<a href="https://arxiv.org/pdf/1910.10683.pdf">使用完整的 Encoder+Decoder 部分</a>的 Transformer 效果更好。</p><p>BERT 模型通过将前一层各个位置的输出序列作为下一层 Transformer 的输入，这样不断堆叠 Transformer。然后得到隐藏层的输出序列。如下图所示，BERT 模型的输入是序列：{E1​,E2​,…En​}，通过两层 Bidirectional Transformer。得到输出序列：{T1​,T2​,…,Tn​}。</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/nlp/bert.png"></p><p>模型本身很简单，但是这篇文章贡献了两个对 NLP 领域影响巨大的重要结论：</p><ol><li>证明了 MLM 在无监督预训练模型能够为 fine-tuning 阶段的监督模型提供信息</li><li>证明了 pre-train+fine-tuning 的两阶段模型对特定任务迁移学习的效果</li></ol><p>BERT 没有像 Transformer 论文中直接用三角函数值计算 Position Embedding。而是采用嵌入学习的方法，对 Position Embedding、Segment Embedding 和 Token Embedding 进行训练，在模型输入的时候如下图所示将 Position Embedding、Segment Embedding 和 Token Embedding 相加作为模型的输入。</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/nlp/input.png"></p><p>在预训练过程中，BERT 将句子中的 15% 的 Token 隐藏。然后将还原这个句子作为学习任务。因为隐藏一个 token 相当于在这个 token 上加了一段噪声，使这个 token 的信息丢失，预测还原句子相当于将这段噪声去除，还原这个 token 的信息。因此这类模型也被称为 Denoising AutoEncoder（DAE）模型。</p><p>在原始论文中，被 Mask 的 Token 是固定的。比如 <code>今夜月色真美</code> 这个句子，如果被 mask 后序列为 <code>今夜[mask]真[mask]</code>，那么在每个 epoch 的训练中都是这个序列。但是后续试验证明，采用 <a href="https://www.6aiq.com/forward?goto=https://arxiv.org/pdf/1907.11692.pdf">Dynamic Mask</a>，即每次训练时实时对样本序列进行 Mask 效果优于固定 Mask 方法。</p><p>在原始论文中，除了 MLM 外，还会将预测下一句(Next Segment Predict，简称 NSP)作为一个学习任务，与 MLM 共同预训练 BERT 模型。但是在后续试验证明<a href="https://wbice.cn/article?goto=https://arxiv.org/pdf/1907.11692.pdf">去除 NSP</a> 在多个任务上效果会更好，并且训练速度更快。并且有类似于 <a href="https://www.6aiq.com/forward?goto=https://arxiv.org/abs/1906.08237">XLNET</a>、<a href="https://www.6aiq.com/forward?goto=https://arxiv.org/abs/1908.04577">StructBERT</a> 等模型指出一个合适的预训练任务，能够提升 BERT 的效果。</p><p>BERT 官方在 GLUE 数据集上对不同的任务进行 fine-tuning 时采用了如下图的方式对不同类型的学习任务进行 fine-tuning：</p><ol><li>对于单句分类任务，将[CLS]的输出作为句子的表达，后续通过连接一层 MLP+tanh 激活函数 +layer normalization 后连接分类网络。</li><li>对于句对分类任务，将其中一句作为第一句，另一句作为第二句。然后按照单句分类进行预测。</li><li>对于对话任务，使用末尾的一段 token 对应的输出进行预测。</li><li>对于序列标注任务，使用每个 token 的输出进行预测。</li></ol><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/nlp/token.png"></p><p>我们回到 Word2Vec 对翻译 <code>今夜月色真美</code> 的问题，无法通过语境，来将 <code>今夜月色</code> 识别为 <code>你</code>。对于 BERT，来说这个问题就不是问题。对于 <code>真美</code> 这段文字来说，<code>今夜月色</code> 是一个代词。对于这个句子整体来说 <code>今夜月色</code> 是烘托气氛的环境。那么对于 <code>真美</code> 来说，<code>今夜月色</code> 不会影响到 <code>真美</code> 这段文字的含义，但是对于 <code>今夜月色</code> 来说，由于 <code>真美</code> 的存在所有导致了 <code>今夜月色</code> 成为了指代。针对这种情况，BERT 通过 Attention 机制有效评估了一个句子中的各个 token 对一个 token 的影响。</p><ul><li>本文地址：<a href="https://www.6aiq.com/article/1590668236351">从一句情话来了解语言模型的发展</a></li><li>本文版权归作者和<a href="https://www.6aiq.com/">AIQ</a>共有，欢迎转载，但未经作者同意必须保留此段声明，且在文章页面明显位置给出</li></ul>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 模型 </tag>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Dataflow 模型</title>
      <link href="/article/dataflow-model.html"/>
      <url>/article/dataflow-model.html</url>
      
        <content type="html"><![CDATA[<p>Dataflow 模型：是谷歌在处理无边界数据的实践中，总结的一套 SDK 级别的解决方案，其目标是做到在非有序的，无边界的海量数据上，基于事件时间进行运算，并能根据数据自身的属性进行 window 操作，同时数据处理过程的正确性，延迟，代价可根据需求进行灵活的调整配置。</p><h2 id="DataFlow-模型核心"><a href="#DataFlow-模型核心" class="headerlink" title="DataFlow 模型核心"></a>DataFlow 模型核心</h2><p>和 Spark 通过 micro batch 模型来处理 Streaming 场景的出发点不同，Dataflow 认为 batch 的处理模式只是 streaming 处理模式的一个子集。在无边界数据集的处理过程中，要及时产出数据结果，无限等待显然是不可能的，所以必然需要对要处理的数据划定一个窗口区间，从而对数据及时的进行分段处理和产出，而各种处理模式（stream，micro batch，session，batch），本质上，只是窗口的大小不同，窗口的划分方式不同而已。Batch 的处理模式就只是一个窗口区间涵盖了整个有边界的数据集这样的一种特例场景而已。一个设计良好的能处理无边界数据集的系统，完全能在准确性和正确性上做到和“Batch”系统一样甚至应该更好。</p><span id="more"></span><p>Dataflow 模型里强调的两个时间概念：Event time 和 Process time：</p><ul><li>Event time 事件时间: 就是数据真正发生的时间，比如用户浏览了一个页面，或者下了一个订单等等，这时候通常就会有一些数据会被生产出来，比如前者可能会产生一条用户的浏览日志</li><li>Process time: 则是这条日志数据真正到达计算框架中被处理的时间点，简单的说，就是你的程序是什么时候读到这条日志的</li></ul><p>现实情况下，由于各种原因，数据采集，传输到达处理系统的时间可能会有长短不同的延迟，在分布式应用场景环境下，不仅是延迟，数据乱序到达往往也是常态。这些问题，在有边界数据集的处理过程中往往并不存在，或者无关紧要。</p><p>但在无边界数据集中，乱序，延迟问题就显得很关键。在 Dataflow 模型中，数据的处理过程中需要解决的问题，被概括为以下 4 个方面：</p><ul><li>What results are being computed ： 计算逻辑是什么</li><li>Where in event time they are being computed ： 计算什么时候（事件时间）的数据</li><li>When in processing time they are materialized ： 在什么时候（处理时间）进行计算&#x2F;输出</li><li>How earlier results relate to later refinements ： 后续数据如何影响（修正）之前的计算结果</li></ul><p>针对以上四个问题，提出了三个模型：</p><ul><li>一个支持基于事件时间的窗口（window）模型，并提供简易的 API 接口：支持固定窗口／滑动窗口／Session（以 Key 为维度，基于事件时间连续性进行划分）等窗口模式。（<strong>解决 Where 问题</strong>）</li><li>一个和数据自身特性绑定的计算结果输出触发模型，并提供灵活可描述的 API 接口。（<strong>解决 when 问题</strong>）</li><li>一个增量更新模型，可以将数据增量更新的能力融合进上述窗口和结果触发模型中。（<strong>解决 how 问题</strong>）</li></ul><h2 id="三个模型"><a href="#三个模型" class="headerlink" title="三个模型"></a>三个模型</h2><h3 id="windowing"><a href="#windowing" class="headerlink" title="windowing"></a>windowing</h3><p>这要解决的 where 问题，即在 infinite 的数据流中，我们要处理哪部分数据。<br>对于unbounded data，只能基于windowing做处理。windowing 有以下三种：<br><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/dataflow-model/windowing.png"><br>前两种很简单，Sessions Windowing，这个比较新鲜，这个是在 google 实践中很重要的一种 windowing 形式。</p><p>Session，即当连续出现 key1 时形成session windowing窗口，没有key1出现是就不存在窗口，典型应用异常检测，当出现持续异常时就是session windowing，没有异常是不需要统计Time Domains。</p><p>时间域，分为两种，</p><p><strong>Event Time</strong>, which is the time at which the event itself actually occurred，发生时间</p><p><strong>Processing Time</strong>, which is the time at which an event is observed at any given point during processing within the pipeline，处理时间</p><p>显然处理时间一定是晚于发生时间的，我们可以用下面的 watermark 图来 visualize 他们的 skew 关系</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/dataflow-model/time-domain.png"></p><p>首先，dataflow 将 window 信息放入 tuple 内，<br>所以 dataflow 的 tuple 是 4 元组，(<strong>key; value; event time; window</strong>)</p><p>同时，支持两种 windows 操作，</p><p>AssignWindows，</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/dataflow-model/assignwindows.png"></p><p>可以看到通过 AssignWindows，可以将原始数据，转换为带 windowing 信息的数据</p><p>在例子给出的 case 下，一条 raw 数据会产生两条带 windowing 信息的数据</p><p>这样做的好处就将，where 信息固化在原始数据中了，你不用再在代码里面记着</p><p>问题是，这样可能会带来数据膨胀，如果 Sliding（60m，1m），岂不是一条 raw tuple，要产生 60 条带 windowing 信息的 tuple</p><p>WindowMerging，</p><p>这个过程，可以用来消除前面带来的数据膨胀，</p><figure class="half">    <img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/dataflow-model/windowmerge0.png">    <img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/dataflow-model/windowmerge1.png"></figure><p>这个过程还是比较清晰的</p><h3 id="Triggers-amp-Incremental-Processing"><a href="#Triggers-amp-Incremental-Processing" class="headerlink" title="Triggers &amp; Incremental Processing"></a>Triggers &amp; Incremental Processing</h3><p>开始解决 when 和 how 的问题</p><p>核心问题，我们面对的时候无序的数据，那么我们怎么知道，这个 windowing 里面的数据已经到全了，可以 emit 产生结果了？</p><p>是不是可以依赖我们上面给出的 watermark 图来预估，是可以的，但这个方案不完善，会有too fast和too slow问题。</p><p>too fast，即通过watermark你是无法保证 100% 数据完整性的，因为 watermark 是启发式生成的</p><p>too slow，即latency 问题，watermark反映的是大部分数据到全的时间点，必然不会有好的latency</p><p>所以可见，这个方案挺废的，即保证不了一致性，也保证不了latency</p><p>那么回到那个问题，我们怎么知道什么时候该 emit 结果了？</p><p>答案是，你无法准确知道。</p><p>所以这边的思路和 lamda 是一致的，先输出实时数据满足latency需要，并且用 batch数据来backfill，修正数据的正确性。</p><p>这就是这里提到的trigger 和增量更新模型，</p><p>trigger 模型解决when的问题，你可以定义各种不同的 trigger，已满足你对 latency 和 correctness 的 balancing 的需求。</p><p>增量模型解决 how 的问题，即如何修正数据的正确性，这里分为 3 种，</p><p><strong>Discarding</strong>: Upon triggering, window contents are discarded, and later results bear no relation to previous results.</p><p>trigger 触发时，会丢弃当前 window 的数据，这样要求 various trigger fires to be independent，比如说 sum 操作<br>这样的好处，减小 mem 的负担；问题是，会产生碎片化数据，需要后续再次 combine 和 merge</p><p><strong>Accumulating</strong>: Upon triggering, window contents are left intact in persistent state, and later results become a refinement of previous results.</p><p>trigger 触发时，会保留当前 window 的数据，后续可以继续 refine 数据<br>这样的场景，适用于 downstream consumer 支持 overwrites 操作，比如数据库</p><p>这样的问题就是，当数据量比较大的时候，你无法在 mem 里面保留长时间数据，那么需要写入存储，那么 backfill 可能需要 offline 来完成</p><p><strong>Accumulating &amp; Retracting</strong>: 比上面那种多了 retracting</p><p>这个只是用于不同的场景，比如 downstream consumer 是在做 sum 统计，那么必须先把上次的减去，才能加上这次的数据</p><h2 id="DATAFLOW-MODEL"><a href="#DATAFLOW-MODEL" class="headerlink" title="DATAFLOW MODEL"></a>DATAFLOW MODEL</h2><p>In this section, we will de ne the formal model for the system and explain why its semantics are general enough to subsume the standard batch, micro-batch, and streaming models, as well as the hybrid streaming and batch semantics of the Lambda Architecture.</p><h3 id="Core-Primitives"><a href="#Core-Primitives" class="headerlink" title="Core Primitives"></a>Core Primitives</h3><p>dataflow 提供两种基本原语，分别对应于无状态和有状态</p><p><strong>ParDo</strong> for generic parallel processing. Each input element to be processed (which itself may be a nite collection) is provided to a user-defined function (called a DoFn in Dataflow), which can yield zero or more output elements per input.</p><p>基本的无状态原语<br>可以等同于 flatMap，和 map 的不同是，可以输出 0 到多个结果</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/dataflow-model/parDo.png"></p><p><strong>GroupByKey</strong> for key-grouping (key; value) pairs.</p><p>有状态的原语</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/dataflow-model/groupbykey.png"></p><h2 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h2><p>对于下面的 input，</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/dataflow-model/input.png"></p><h3 id="Batch-Model"><a href="#Batch-Model" class="headerlink" title="Batch Model"></a>Batch Model</h3><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/dataflow-model/batch-model.png"></p><p>Batch 的方式，等所有数据都来全了，计算一遍解决，问题就是 latency 高达接近 10 分钟 （对于最早的数据）<br><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/dataflow-model/classic-batch.png"></p><p>基于 windowing 的 batch 方式，和普通 batch 区别，增加 windows 聚合的结果</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/dataflow-model/window-batch.png"></p><h3 id="Micro-Batch-Model"><a href="#Micro-Batch-Model" class="headerlink" title="Micro-Batch Model"></a>Micro-Batch Model</h3><p>和 batch 比，兼顾 latency</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/dataflow-model/micro-batch-model.png"></p><p>incremental 的方式不同，下面是 discarding，看看区别</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/dataflow-model/micro-batch-discard.png"></p><p>基于 windowing 的 micro-batch，</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/dataflow-model/micro-batch-window.png"></p><h3 id="基于流的-Windowing-Model"><a href="#基于流的-Windowing-Model" class="headerlink" title="基于流的 Windowing Model"></a>基于流的 Windowing Model</h3><p>采用 watermark 的 trigger，</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/dataflow-model/stream-watermark.png"></p><p>这个的问题上面说过，<br>too fast，9 在依据 watermark 触发时，还没到<br>too late, 7 的数据要等到 8 到达的时候才能输出，</p><p>在 watermark trigger 的基础上增加 micro-batch trigger，这样的好处还是提高 latency，</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/dataflow-model/watermark-microbatch.png"></p><h3 id="基于-Session-Windowing-Model"><a href="#基于-Session-Windowing-Model" class="headerlink" title="基于 Session Windowing Model"></a>基于 Session Windowing Model</h3><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/dataflow-model/stream-watermark-session.png"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>更细的学习了 flink watermark 后，再来看这篇文章，就更加能懂里面的一些概念，只看文章，没有具体实现还是比较难理解它的设计要点。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://www.cnblogs.com/fxjwind/p/5124174.html">https://www.cnblogs.com/fxjwind/p/5124174.html</a><br><a href="https://www.cnblogs.com/tgzhu/p/7656508.html">https://www.cnblogs.com/tgzhu/p/7656508.html</a></p>]]></content>
      
      
      <categories>
          
          <category> 数据工程 </category>
          
          <category> 流式计算 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
            <tag> 大数据 </tag>
            
            <tag> 流式计算 </tag>
            
            <tag> spark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>来美团3个月总结</title>
      <link href="/article/%E6%9D%A5%E7%BE%8E%E5%9B%A23%E4%B8%AA%E6%9C%88%E6%80%BB%E7%BB%93.html"/>
      <url>/article/%E6%9D%A5%E7%BE%8E%E5%9B%A23%E4%B8%AA%E6%9C%88%E6%80%BB%E7%BB%93.html</url>
      
        <content type="html"><![CDATA[<p>来美团也三个月了，也渐渐习惯这边的风格。再流程制度上，有让我觉得很不错的地方，也有一些需要改善的地方。自己的能力模型上，还有哪些需要提高的，接下来自己需要在这些地方进步。</p><h3 id="好的地方"><a href="#好的地方" class="headerlink" title="好的地方"></a>好的地方</h3><ul><li>文档。在文档这方便做的挺好的，把工作中很多都能记录下来，比如会议纪要，产品PRD，技术方案，月度总结等，以及各个系统的详细文档等。而且也能搜到很多技术方案设计，能力模型等。这样比较详细的学习别人怎样去做的，怎样设计的。</li><li>各个基础平台和系统。在这边不用什么都从头开始，公司提供了各种基础平台，比如服务发布的CI&#x2F;CD工具，微服务的RPC框架，服务治理，熔断降级等系统。以及各种存储，KV存储，es平台，大数据平台等，让自己能够专注于业务，而不需要放很多精力在以来的平台开发运维上面。</li><li>流程规范。大公司流程还是比较规范的，如开发上线流程，整套流程每一步都细化，大家按照这套流程开发。极大的规避掉一些因为个人理解偏差和信息对齐上面造成的上线问题，能够保质保量的进行新功能迭代上线。</li><li>制定绩效合同，后面绩效根据此打，更大化的做得客观。</li><li>因为我原来是做大数据平台的，更多的面向的是公司内部，而现在是面向用户。可以感受到这边对监控，线上问题的也紧要重视。（这个主要是我岗位的变化）<span id="more"></span></li></ul><h3 id="不好的地方"><a href="#不好的地方" class="headerlink" title="不好的地方"></a>不好的地方</h3><ul><li>从上至下传导下来的上线压力。对于上线出错本来是大概率的，这需要看影响层面，以及及时修复即可。而现在却让RD对每次上线都战战兢兢，生怕出点错。所以对于研发来说，或许不开发代码不上线就是一个好coder?</li><li>产品和开发的绩效目标不一致。对于一个面向用户的app，最大的绩效是提升用户使用感受。这需要产品和研发能够统一战线，产品既要摸索用户需求，又要和研发统一好研发成本；研发在开发的同时，能够为产品提出意见。而不是产品一直提需求，却不考虑研发成本，因为这不是他们的绩效，在极短的时间内写的code大概率是质量很低的代码，后期维护成本，出错可能性都很大，所以研发忙于奔命，也就没时间去优化代码，想些真正对用户有价值的需求。这是现阶段存在的一个矛盾点。</li><li>因为牵扯团队部门很多，所以很多需求都涉及多部门协作，沟通成本也是现阶段比较繁重的。需要对齐信息，以及确定边界，这些都是很正常的部门沟通。但其中有一点，因为对于线上问题，各部门开始撕扯，这时候就会将文档和聊天记录作为一些凭证，所以对于在部门沟通的时候，很多时间需要想怎么讲话，这无形增加了大家的沟通成本，逐渐往撕逼方向发展。</li></ul><h3 id="自己需要提高的地方"><a href="#自己需要提高的地方" class="headerlink" title="自己需要提高的地方"></a>自己需要提高的地方</h3><ul><li>项目管理能力。经过了两三个项目的经历，逐渐熟悉了整个项目管理过程，与产品需求谈判对齐，与其他团队的接口定义，部门内的人力安排，项目的风险等，都需要项目管理者把握。在这些方面，如何与产品对产品需求合理性与该不该去做这方面的能力还需要提高，首先需要想这个功能能带来什么，以及实现这个功能的成本，有限排期内如何分阶段去实现这个功能。</li><li>涉及外部接口调用的，如果是新接口，需要找相关团队的人给接口文档，并给出SLA，哪些是必填参数，这些都需要写在技术方案文档中，并给相关人查看。如果出现线上问题，能够更能保护好自己。</li><li>目标感还需要加强。多与领导沟通，以及自己多想想自己想从事哪些事，将这些都给领导讲诉。让领导能够更好的给分配自己想做的，有利于自己成长的工作。</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 总结 </tag>
            
            <tag> 思考 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>过去，未来</title>
      <link href="/article/pass-and-future.html"/>
      <url>/article/pass-and-future.html</url>
      
        <content type="html"><![CDATA[<p>很快，已经大半年没写博客了，这半年内，一直再准备面试，找工作，终于在7月去了自己还认为不错的公司。也发现自己已经工作四年了。如果要给自己前四年以一个词语做总结的话，我想我会选择“混沌”这个词。</p><h3 id="过去"><a href="#过去" class="headerlink" title="过去"></a>过去</h3><p>在物理学上，混沌（chaos）是指确定性动力学系统因对初值敏感而表现出的不可预测的、类似随机性的运动。又称浑沌。英语词Chaos源于希腊语，原始 含义是宇宙初开之前的景象，基本含义主要指混乱、无序的状态。</p><p>而自己曾经的过往也是这样的随机飘荡。没有为自己制定一个人生目标，也不造为何而追求，是我之前很长一段时间的状态。主要体现在我认为的以下几点：</p><ul><li>没有制定人生规划。因为没有大方向，所以很多时候更偏向于随遇而安。</li><li>工作单位随意性。和人生规划也有关，所以在面临单位的抉择方便没有去更加的努力。没有想好不同的单位能为我带来什么样的背景和能力。</li><li>情感的随意性。在情感方面，自己并没有什么优势，所以更需要自己勇于去争取。而为此，需要去提高自己的设计能力，沟通表达能力，自己却没有过多的在意。</li><li>到底想要什么。这个问题思考的不够深刻，因为道路上的一些阻碍，也造成前进方向的左右摇摆。</li><li>勇敢去争取的心。无论在工作上，情感上，生活上，如果没有一颗勇敢去争取的心，人很容易颓废，然后陷入自我怀疑。社会因为信息的不对等，所以机会更容易给予勇敢去争取的人，而不去争取的人，却只能抱怨“他不如我，为啥是他”这种无聊的问题。</li></ul><span id="more"></span><p>努力去争取是我感触最深的，因为不够勇敢，自己错失了很多。接下来，自己希望自己能够做个勇敢的人，不怕失败，但一定要勇敢去争取。再勇敢去争取的道路上，不断提升自己，建立自信。</p><h3 id="未来"><a href="#未来" class="headerlink" title="未来"></a>未来</h3><p>7月，从新换了个公司，也对自己的人生有了新的认识。自己也制定自己的三驾马车：</p><ul><li>技术能力。也是自己赖以生存的根本，作为程序员，技术是根本。所以在工作中，不断打磨技术。</li><li>表达能力。人还是社会的人，一个会沟通，善表达的人能够让其更有自信，能够在职场，生活更游刃有余。而如何去有效的表达，需要不断重复又重复的练习。仅仅思维上还不行，需要不断实践。多与人接触，平等对待每个人，能给自己带来不一样的收获。</li><li>经济知识能力。在现代社会，经济知识不可或缺，有经济知识，能够让自己更容易做好决策，能够让自己能够站在利益的角度去审视每个人的行为。另外，理财投资也是现代必备，不懂经济，只会工作的人，很容易沦为金融家的牺牲品。</li></ul><p>以上三点，是术的层面。而自己更需要改变的是道的层面，这个会更艰难，首先需要逐渐有颗勇敢的心，不时要告诫自己，生活不能这样随遇而安，不管以后自己想要什么，努力争取，把选择权握在自己手里会比让别人来选择自己好很多。努力提升自己，自信积极，从而提升自己的经济实力和为人处世能力。</p><p>最后以一句话为接下来而结尾：你若盛开，清风自来。心若浮沉，浅笑安然。</p>]]></content>
      
      
      <categories>
          
          <category> 成长 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 总结 </tag>
            
            <tag> 目标 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python协程</title>
      <link href="/article/coroutine.html"/>
      <url>/article/coroutine.html</url>
      
        <content type="html"><![CDATA[<p>这些天，在标签调度上，可预见性的标签调度会越来越多，如果全由调度系统承载，调度系统压力增大，负责调度系统的同事担心会影响其他任务，遂在讨论下，决策开发一个简版的标签执行服务&#x2F;脚本（相比现有调度系统，只保留任务执行控制，例如池化，并发控制等，任务编排，启动时间都由调度系统控制，整个执行服务就是调度系统的一个task）。而我对此持保持意见，我认为应该增强调度系统能力，2333。</p><p>既然决策已定，加上部门现在主要使用python，而调度系统也使用的是airflow，所以主要开发语言也定为python。对于此执行服务&#x2F;脚本，希望能够并行的执行任务，并且能够控制每次在跑的任务数。调研了下python的并发模型，以及多线程的知识。很多说python多线程是<a href="https://www.zhihu.com/question/23474039">鸡肋</a>，而自己也不想引入第三方并发的库，又看到python支持协程，且相比线程轻量很多，代码易理解，遂最终选定使用协程来实现这个需求。</p><h3 id="协程"><a href="#协程" class="headerlink" title="协程"></a>协程</h3><p>网上对协程的解释众说纷纭，有说协程是一种用户态的轻量级线程，协程的调度完全由用户控制。wikipedia的定义：<br>协程是一个无优先级的子程序调度组件，允许子程序在特点的地方挂起恢复。但大家对协程的作用倒挺统一的：</p><ul><li>占用资源少，开个协程只需要K级别内存，而新开个线程则需要M级别</li><li>线程之间的上下文切换，性能消耗大，而协程间切换非常快</li><li>相比事件驱动模型的回调复杂性，协程易于理解，写协程代码就像写同步代码一样。</li><li>协程的调度是协作式调度，需要协程自己主动把控制权转让出去之后，其他协程才能被执行到（很难像抢占式调度那样做到强制的 CPU 控制权切换到其他进程&#x2F;线程）</li></ul><h3 id="历史的宿命"><a href="#历史的宿命" class="headerlink" title="历史的宿命"></a>历史的宿命</h3><p>在互联网行业面临C10K问题时，线程方案不足以扛住大量的并发，这时的解决方案是epoll() 式的事件循环，nginx在这波潮流中顺利换掉apache上位。同一时间的开发社区为nginx的成绩感到震撼，出现了很多利用事件循环的应用框架，如tornado&#x2F; nodejs，也确实能够跑出更高的分数。而且python&#x2F;ruby 社区受GIL之累，几乎没有并发支持，这时事件循环是一种并发的解放。然而事件循环的异步控制流对开发者并不友好。业务代码中随处可见的mysql&#x2F;memcache调用，迅速地膨胀成一坨callback hell。这时社区发现了协程，在用户态实现上下文切换的工具，把epoll()事件循环隐藏起来，而且成本不高：用每个协程一个用户态的栈，代替手工的状态管理。似乎同时得到了事件循环和线程同步控制流的好处，既得到了epoll()的高性能，又易于开发。甚至通过monkey patch，旧的同步代码可以几乎无缝地得到异步的高性能，真是太完美了。</p><span id="more"></span><h3 id="python协程的实现"><a href="#python协程的实现" class="headerlink" title="python协程的实现"></a>python协程的实现</h3><h4 id="gevent"><a href="#gevent" class="headerlink" title="gevent"></a>gevent</h4><p>gevent是基于协程（greenlet）的网络库，底层的事件轮询基于libev（早期是libevent），当一个greenlet遇到IO操作时，比如访问网络，就自动切换到其他的greenlet，等到IO操作完成，再在适当的时候切换回来继续执行。由于IO操作非常耗时，经常使程序处于等待状态，有了gevent为我们自动切换协程，就保证总有greenlet在运行，而不是等待IO（<font color=red size=2>所以当你的代码没有IO操作，协程便不会进行任务切换，所以你会看到是顺序执行的</font>）。gevent的API概念和Python标准库一致(如事件，队列)。gevent有一个很有意思的东西 monkey-patch，能够使python标准库中的阻塞操作变成异步，如socket的读写。下图是gevent与其他网络库的对比图。</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/coroutine/gevent.png" alt="gevent与其他网络库的对比图"></p><p>gevent代码也很通俗易懂：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">foo</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Running in foo&#x27;</span>)</span><br><span class="line">    gevent.sleep(<span class="number">0</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Explicit context switch to foo again&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">bar</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Explicit context to bar&#x27;</span>)</span><br><span class="line">    gevent.sleep(<span class="number">0</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Implicit context switch back to bar&#x27;</span>)</span><br><span class="line"></span><br><span class="line">gevent.joinall([</span><br><span class="line">    gevent.spawn(foo),</span><br><span class="line">    gevent.spawn(bar),</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># output</span></span><br><span class="line">Running <span class="keyword">in</span> foo</span><br><span class="line">Explicit context to bar</span><br><span class="line">Explicit context switch to foo again</span><br><span class="line">Implicit context switch back to bar</span><br></pre></td></tr></table></figure><p>定义foo和bar两个方法，将foo和bar放入gevent中（gevent.spawn(func)），并注册入轮询事件中。当遇到异步阻塞操作时，如代码中的gevent.sleep(0)，变会切换到其他gevent，一直反反复复，直到所有的gevent执行完成。而整个code也和写同步程序流程一致：定义两个方法，执行两个方法。而gevent内部遇到阻塞IO进行协程切换，而不是等此IO。</p><p><strong>monkey-patch</strong></p><p>写gevent程序几乎都会加一句code</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gevent <span class="keyword">import</span> monkey</span><br><span class="line">monkey.patch_all()</span><br></pre></td></tr></table></figure><p>这是干嘛用的呢？我们知道协程切换是在IO操作时自动完成，所以gevent需要修改Python自带的一些标准库，将python自带的标准库由阻塞IO改成非阻塞IO，这一过程在启动时通过monkey patch完成。</p><h4 id="asyncio"><a href="#asyncio" class="headerlink" title="asyncio"></a>asyncio</h4><p>asyncio是Python 3.4版本引入的标准库，直接内置了对异步IO的支持。asyncio的编程模型就是一个消息循环。我们从asyncio模块中直接获取一个EventLoop的引用，然后把需要执行的协程扔到EventLoop中执行，就实现了异步IO。</p><p>在gevent中，我们不能自己定义协程，只能通过控制非阻塞IO，gevent识别到非阻塞IO，自动切换协程。而gevent支持的非阻塞IO有限（以及通过monkey patch替换某些库），且不能很好的自定义。而且gevent是第三方库，在GitHub上看，以及四五年未更新了。</p><p>asyncio模块中引入了以下几个定义：</p><ul><li>event_loop 事件循环：程序开启一个无限的循环，程序员会把一些函数注册到事件循环上。当满足事件发生的时候，调用相应的协程函数。</li><li>coroutine 协程：协程对象，指一个使用async关键字定义的函数，它的调用不会立即执行函数，而是会返回一个协程对象。协程对象需要注册到事件循环，由事件循环调用。</li><li>task 任务：一个协程对象就是一个原生可以挂起的函数，任务则是对协程进一步封装，其中包含任务的各种状态。</li><li>future： 代表将来执行或没有执行的任务的结果。它和task上没有本质的区别</li><li>async&#x2F;await 关键字：python3.5 用于定义协程的关键字，async定义一个协程，await用于挂起阻塞的异步调用接口。</li></ul><h5 id="asyncio-coroutine-x2F-yield-from"><a href="#asyncio-coroutine-x2F-yield-from" class="headerlink" title="asyncio.coroutine&#x2F;yield from"></a>asyncio.coroutine&#x2F;yield from</h5><p>在python3.4中，asyncio.coroutine修饰器用来标记作为协程的函数，这里的协程是和asyncio及其事件循环一起使用的。结合python之前的yield语法，通过yield from将协程交给其他对象继续执行，代码示例如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"></span><br><span class="line"><span class="meta">@asyncio.coroutine</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">foo</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Running in foo&#x27;</span>)</span><br><span class="line">    <span class="keyword">yield</span> <span class="keyword">from</span> asyncio.sleep(<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Explicit context switch to foo again&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">bar</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Explicit context to bar&#x27;</span>)</span><br><span class="line">    <span class="keyword">yield</span> <span class="keyword">from</span> asyncio.sleep(<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Implicit context switch back to bar&#x27;</span>)</span><br><span class="line"> </span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">tasks = [</span><br><span class="line">    asyncio.ensure_future(foo()),</span><br><span class="line">    asyncio.ensure_future(bar())]</span><br><span class="line">loop.run_until_complete(asyncio.wait(tasks))</span><br><span class="line">loop.close()</span><br></pre></td></tr></table></figure><h5 id="await-x2F-async"><a href="#await-x2F-async" class="headerlink" title="await&#x2F;async"></a>await&#x2F;async</h5><p>Python 3.5 在处理协程时增加了一些特殊的语法（await&#x2F;async）。新功能中很大一部分在3.5 之前的版本就已经有了，不过之前的语法并不算最好的，因为生成器和协程的概念本身就有点容易混淆。PEP-0492 通过使用 async 关键字显式的对生成器和协程做了区分。对于python迭代器，生成器和协程的知识，可以自己去网上查，也可以参考<a href="https://juejin.im/entry/585e6f62570c3500693a1058">从迭代器、生成器到协程</a>。这里就不讲解了。</p><p>而await&#x2F;async也可以简单看成将@asyncio.coroutine替换成await，yield from替换成await</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># This also works in Python 3.5.</span></span><br><span class="line"><span class="meta">@asyncio.coroutine</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">py34_coro</span>():</span><br><span class="line">    <span class="keyword">yield</span> <span class="keyword">from</span> stuff()</span><br><span class="line">````</span><br><span class="line">与</span><br><span class="line">```python</span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">py35_coro</span>():</span><br><span class="line">    <span class="keyword">await</span> stuff()</span><br></pre></td></tr></table></figure><p>在async&#x2F;await模型中，协程函数内部也可以调用多个协程函数。</p><p>如何更好的理解event loop和await&#x2F;async代码呢？</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">worker</span>(<span class="params">name, queue</span>):</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="comment"># Get a &quot;work item&quot; out of the queue.</span></span><br><span class="line">        sleep_for = <span class="keyword">await</span> queue.get()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Sleep for the &quot;sleep_for&quot; seconds.</span></span><br><span class="line">        <span class="keyword">await</span> asyncio.sleep(sleep_for)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Notify the queue that the &quot;work item&quot; has been processed.</span></span><br><span class="line">        queue.task_done()</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;name&#125;</span> has slept for <span class="subst">&#123;sleep_for:<span class="number">.2</span>f&#125;</span> seconds&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="comment"># Create a queue that we will use to store our &quot;workload&quot;.</span></span><br><span class="line">    queue = asyncio.Queue()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Generate random timings and put them into the queue.</span></span><br><span class="line">    total_sleep_time = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">20</span>):</span><br><span class="line">        sleep_for = random.uniform(<span class="number">0.05</span>, <span class="number">1.0</span>)</span><br><span class="line">        total_sleep_time += sleep_for</span><br><span class="line">        queue.put_nowait(sleep_for)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create three worker tasks to process the queue concurrently.</span></span><br><span class="line">    tasks = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">        task = asyncio.create_task(worker(<span class="string">f&#x27;worker-<span class="subst">&#123;i&#125;</span>&#x27;</span>, queue))</span><br><span class="line">        tasks.append(task)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Wait until the queue is fully processed.</span></span><br><span class="line">    started_at = time.monotonic()</span><br><span class="line">    <span class="keyword">await</span> queue.join()</span><br><span class="line">    total_slept_for = time.monotonic() - started_at</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Cancel our worker tasks.</span></span><br><span class="line">    <span class="keyword">for</span> task <span class="keyword">in</span> tasks:</span><br><span class="line">        task.cancel()</span><br><span class="line">    <span class="comment"># Wait until all worker tasks are cancelled.</span></span><br><span class="line">    <span class="keyword">await</span> asyncio.gather(*tasks, return_exceptions=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;====&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;3 workers slept in parallel for <span class="subst">&#123;total_slept_for:<span class="number">.2</span>f&#125;</span> seconds&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;total expected sleep time: <span class="subst">&#123;total_sleep_time:<span class="number">.2</span>f&#125;</span> seconds&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">loop.run_until_complete(main())</span><br><span class="line">loop.close()</span><br></pre></td></tr></table></figure><p>首先需要loop &#x3D; asyncio.get_event_loop()获取一个事件loop，loop是个死循环，轮询遍历task。然后将协程task注册到loop中，在上面的示例中，main()有三个task。当每个task执行协程函数遇到await时，切换到其他task执行，如此反复，直到loop中的task全部执行完毕，退出。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本来简单介绍了协程的优点，以及python对协程的支持，以及如何写python协程代码。但未对gevent或者async&#x2F;await用在服务中，从网上搜索来看，似乎python的协程坑还是挺多的，如果需要使用，还需要多多测试。对于我的需求，使用python协程方案已经能够不错满足了，而且本来也只是利用其并发优势来执行任务，不涉及高并发请求。python现在的定位还是：开发速度快，解释语言，脚本处理，数据处理。如果是高并发服务的话，需要多斟酌下。</p><h3 id="后续"><a href="#后续" class="headerlink" title="后续"></a>后续</h3><p>协程这个概念几乎是由golang语言带火的，golang从底层语言特性添加了对协程的支持，也是现在对协程支持最完善的语言了。后续有时间也研究下~</p><h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p><a href="https://www.zhihu.com/question/32218874">为什么觉得协程是趋势？</a></p><p><a href="https://blog.csdn.net/runner668/article/details/80512664">linux进程-线程-协程上下文环境的切换与实现</a></p><p><a href="https://docs.python.org/3/whatsnew/3.5.html#whatsnew-pep-492">https://docs.python.org/3/whatsnew/3.5.html#whatsnew-pep-492</a></p><p><a href="https://www.liaoxuefeng.com/wiki/001374738125095c955c1e6d8bb493182103fac9270762a000/0013868328689835ecd883d910145dfa8227b539725e5ed000">https://www.liaoxuefeng.com/wiki/001374738125095c955c1e6d8bb493182103fac9270762a000/0013868328689835ecd883d910145dfa8227b539725e5ed000</a></p>]]></content>
      
      
      <categories>
          
          <category> CS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> IO </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>略微糟糕的2018</title>
      <link href="/article/summary-2018.html"/>
      <url>/article/summary-2018.html</url>
      
        <content type="html"><![CDATA[<p>不在以流水形式记录，而网易云音乐年报体搞笑却不能展示更多。在朋友圈看了别人的发的年终总结，遂借鉴其模板。</p><h3 id="2018年让你印象深刻的5件事情是什么？"><a href="#2018年让你印象深刻的5件事情是什么？" class="headerlink" title="2018年让你印象深刻的5件事情是什么？"></a>2018年让你印象深刻的5件事情是什么？</h3><ol><li>定级答辩，完全暴露了自己的弱点，当大领导说自己的ppt很渣时，很懵逼。自己确实没太上心，做的少。虽然后来又重改了，但最终其实效果都不是很满意，包括答辩。表达能力以及技能包装能力都还需要多加练习。最后感谢领导的细心指导。</li><li>不应该老拿别人的弱点说事或者开玩笑。A之前说了个毫无依据的话被大家笑话，然后就竟然被大家拿出来说，以至于大家一旦把焦点给与他，他便有了种不舒服，即便知道大家也是寻乐。自己也会一直拿别人的弱点寻乐，虽然是玩笑，但别人的感受未必是玩笑。当然自己也会被拿着弱点一直攻击你，当然也是寻乐，但自己确实也有不爽，将心比心，也许有时候会意的鼓励会更好。以后自己应该多注意，少娱乐他人的弱点，多提升自己的弱点。</li><li>接近年底，回家办理贷款手续，正好外婆过生，一大家人和和睦睦，开开心心的氛围真好。希望明年能带外婆来北京玩，外婆那些年一路过来不容易，现在也该享享清福了。</li></ol><h3 id="你做的引以为傲的5件事？"><a href="#你做的引以为傲的5件事？" class="headerlink" title="你做的引以为傲的5件事？"></a>你做的引以为傲的5件事？</h3><ol><li>终于还是借着低价买的域名，开通的<a href="http://wbice.cn/">博客</a>，开始记录技术，生活的感悟，以及看书，电影。零零散散的也写了将近20篇文章，虽然内容还有待提供，以及有些是拼凑的。但还是希望自己沉淀一些知识，以及顺便提高自己的写作能力。</li><li>认知的提升。网络上的人云亦云，股市的追涨杀跌，以及自媒体带节奏的十万加，以及各种app推送的信息。让我意识到现在虽然信息变多了，但都是他们为了满足自己的利益而塞给观看者已经加工过的信息。对此，自己的认知的提升，能够对此消息进行独立思考，而不是跟着他人的情感走是非常重要的。而群体更能泛滥此情绪，相比独立思考，会显得更智力低下。<span id="more"></span></li><li>资产配置和理财意识。虽然赚钱还很少，但也逐渐开始配置自己的资产，将自己的资产配置到各个方面，银行，货币基金，股票，房产，对不同的配置认识到风险的存在。另外不断提升自己的经济知识，对宏观经济能够有一定自我推论和判断。在现代社会，货币政策影响着每个人的资产，如果不学习，瞎买卖，可能最终辛辛苦苦赚来的钱全给他人做了嫁妆。</li></ol><h3 id="让你长教训的5件事？"><a href="#让你长教训的5件事？" class="headerlink" title="让你长教训的5件事？"></a>让你长教训的5件事？</h3><ol><li>工作汇报。下半年开始，领导让一个同事E管理我和B，工作事务和一些目标基本都是E下发给我们，然后事务也差不多上报给E。另外自己和领导平时沟通少，也不乐意向领导沟通。E有时因为自己的事务而忘却了大家的目标，以及未能向领导汇报工作，造成自己所作的工作不能被领导所知。“如果你是个职场人，领导给你布置个工作，你就一定要记住在过程中时时汇报，不要总想着把事情搞完后，有了结果，再给领导一个surprise。领导不需要惊喜，只需要控制。”</li><li>A之前管理着某个服务，要向他服务添加内容，都是给他。后来领导让他开放功能，而我负责的板块正好需要重构，于是就开始自己在那个服务上修改内容。因为此服务不稳定（开源的bug），在某天我修改完，出现了异常，我上报于他，但他未能重视，最终第二天造成服务崩塌。后来领导批了我，说我未能跟进解决这个问题，并不是把问题上报就结束，而是要具体到问题已经解决，或者确实领导知道下，有相应的人在处理这个问题，你才能放下这个问题。领导说的对，这个我也检讨总结，确实自己做的不到位。但我对出现问题后，同事极力想把锅甩给我，让我明白了，同事终将是同事，特别是有利益冲突的。但职场上，往往成就了别人才能成就自己，所以能够遇到一个好队友，然后相互成就是多么的幸运。 </li><li>生活上低调，工作上高调。你要想在工作上有所产出，并能被领导看到，你需要”高调“。积极说出自己的想法，即便被领导批的体无完肤，也比不吭声好。这也会正向的督促你多思考，然后给出更好的idea。然后嗅觉灵敏，能及时发现价值点，领导也会一直寻找价值点，以及尝试，他们也会有战略判断失误的时候，能交流指出是最好的。</li><li>控制自己的兴趣波动。喜新厌旧，知难而退的人性弱点，我也不例外，这体现在生活或者工作上就是三分热度。以及自己目标感不足，造就了自我不满意的2018。</li></ol><h3 id="哪5件事情值得更多的时间和精力？"><a href="#哪5件事情值得更多的时间和精力？" class="headerlink" title="哪5件事情值得更多的时间和精力？"></a>哪5件事情值得更多的时间和精力？</h3><ol><li>和朋友家人沟通变得越来越少。这一年宅了很多，走出去的心情变少了。有时候自己觉得自己有很多困惑，也不知道询问谁。社交能力的下降，虽然自己也讨厌无用的社交，但确实发现自己和朋友聚的少了，酣畅淋漓的聊天也少了。因为在外，有时候也会有份孤独。</li><li>专注度。这一年有些分心，币圈的事和书籍，买房的事。而自己本分的工作却没有尽到80%的努力与专注。买房的也告一段落，现在也没钱了，接下来要静下心来，努力提高工作能力。</li><li>是该好好规划自己了。这一年整体上有点浑浑噩噩，自己对自己是不太满意的。有外界的因素，但主要是自己的目标不足，以及自己的人生规划。还有半个月样子自己就26周岁了，真是时不我待啊。</li></ol><h3 id="哪5件值得庆祝的事情？"><a href="#哪5件值得庆祝的事情？" class="headerlink" title="哪5件值得庆祝的事情？"></a>哪5件值得庆祝的事情？</h3><ol><li>买房摇号摇了五六次，号码都是1w以上，最终人品大爆发，摇中了18号，基本可以任意选房了。虽然位置差了点，但限价，很便宜，以后也有地铁，希望能小赚一笔。</li><li>这一年出了下国，作为喜欢体验不同文化的人，看到不同风土人情，简直多么快乐了，就是行程短了点。国庆去了西北，19年元旦去了东北，西北开阔壮丽，10月也开始逐渐变得冷了。东北的冰雕，雪乡的雪蘑菇，让我这个南方人还是挺欣喜的，零下20多度也确实是冷（其实主要风吹脸冷，以及冻脚）。还有就是北京太不争气了，竟然没下雪，水气太少了。自己的足迹图也快布满神州大地了，开心。<br> <img src="http://hexo-1256892004.cos.ap-beijing.myqcloud.com/summary-2018/foot.png"></li></ol><h3 id="接下来你觉得做哪些事情可以让自己感到满足？"><a href="#接下来你觉得做哪些事情可以让自己感到满足？" class="headerlink" title="接下来你觉得做哪些事情可以让自己感到满足？"></a>接下来你觉得做哪些事情可以让自己感到满足？</h3><ol><li>工作能力的提升。能够更专注于工作，减少其他的干扰。给自己定下目标，并努力朝着目标前进。</li><li>当然赚更多的钱。呜呜，毕竟现在债务压身。哈哈，我比较推崇美帝人民的观念，狂举债，然后努力赚钱。当然，美帝人民举债是消费去了，享乐去了，而自己为了能更好的投资与财富积累。</li><li>能努力积极的去寻找自己喜欢的人和事。2018对自己的这个状态感到担忧，觉得自己越来越朝着封闭方向发展，这样慢慢会积累负能量。2019要更上进，开阔。</li><li>2019年应该不会有太大的一次性支出，自己会逐渐增加消费。获得消费的快乐，提高生活品质。</li></ol><h3 id="2019年的目标和展望"><a href="#2019年的目标和展望" class="headerlink" title="2019年的目标和展望"></a>2019年的目标和展望</h3><ol><li>专注于工作能力的提升，从广撒网式的学习转为更为系统深层的学习，被记录在博客中。</li><li>更深刻的去认知网络群体，他们是未来的衣食父母。</li><li>努力寻找未来的ta。</li><li>计划去日本或者台湾。</li></ol><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>2018年确实过的不咋滴，以至于我要想出5件牛逼的事情来，都扣出头皮屑了，哈哈。犯的错挺多，但终将还是过去了。2018年全国大环境不好，网络上也充斥着各种悲观。最近自己在思考：这种时候，其实更是机会，如果能够在这一波低谷活下去，等到下一轮起风了，就会过的更好。虽然在书本上看到过一轮轮经济周期，但自己没亲身感受过，只有自己亲身感受过，并努力地活下来了，那才是真正的成长。而我接下来需要做的就是静下心来，以及目标。</p>]]></content>
      
      
      <categories>
          
          <category> 成长 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 总结 </tag>
            
            <tag> 目标 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>spark streaming</title>
      <link href="/article/spark-streaming.html"/>
      <url>/article/spark-streaming.html</url>
      
        <content type="html"><![CDATA[<p>之前讲解了Google的<a href="http://wbice.cn/article/dataflow-model.html">Dataflow</a>模型。而spark streaming是以micro batch方式来近似streaming数据进行处理。Spark Streaming从实时数据流接入数据，再将其划分为一个个小批量供后续Spark engine处理，所以实际上，Spark Streaming是按一个个小批量来处理数据流的。<br><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/spark-streaming/micro-streaming.png"></p><h3 id="spark-streaming"><a href="#spark-streaming" class="headerlink" title="spark streaming"></a>spark streaming</h3><p>离散数据流（DStream）是Spark Streaming最基本的抽象。它代表了一种连续的数据流，要么从某种数据源提取数据，要么从其他数据流映射转换而来。DStream内部是由一系列连续的RDD组成的，每个RDD都是不可变、分布式的数据集。每个RDD都包含了特定时间间隔内的一批数据，如下图所示：<br><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/spark-streaming/interval-rdd.png"></p><p>任何作用于DStream的算子，其实都会被转化为对其内部RDD的操作。例如，在代码</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> words = lines.flatMap(_.split(<span class="string">&quot; &quot;</span>))</span><br></pre></td></tr></table></figure><p>中，我们将lines这个DStream转成words DStream对象，其实作用于lines上的flatMap算子，会施加于lines中的每个RDD上，并生成新的对应的RDD，而这些新生成的RDD对象就组成了words这个DStream对象。其过程如下图所示：</p><span id="more"></span><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/spark-streaming/transform.png"></p><p>底层的RDD转换仍然是由Spark引擎来计算。DStream的算子将这些细节隐藏了起来，并为开发者提供了更为方便的高级API。</p><p>因为底层仍是Spark引擎，所以streaming也提供了一些类似普通RDD的transform的算子。这里就不做详细介绍了，有需要的参照<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html#transformations-on-dstreams">官网</a>。</p><p><strong>transform算子</strong></p><p>transform算子能够让DStream与其他不在DStream中的数据集相计算。例如：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> spamInfoRDD = ssc.sparkContext.newAPIHadoopRDD(...) <span class="comment">// RDD containing spam information</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> cleanedDStream = wordCounts.transform &#123; rdd =&gt;</span><br><span class="line">  rdd.join(spamInfoRDD).filter(...) <span class="comment">// join data stream with spam information to do data cleaning</span></span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>基于窗口（window）的算子</strong></p><p>Spark Streaming同样也提供基于时间窗口的计算，也就是说，你可以对某一个滑动时间窗内的数据施加特定tranformation算子。如下图所示：<br><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/spark-streaming/window.png"></p><p>如上图所示，每次窗口滑动时，源DStream中落入窗口的RDDs就会被合并成新的windowed DStream。在上图的例子中，这个操作会施加于3个RDD单元，而滑动距离是2个RDD单元。由此可以得出任何窗口相关操作都需要指定一下两个参数：</p><ul><li>（窗口长度）window length – 窗口覆盖的时间长度（上图中为3）</li><li>（滑动距离）sliding interval – 窗口启动的时间间隔（上图中为2）</li></ul><p>注意，这两个参数都必须是DStream批次间隔（上图中为1）的整数倍。<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html#window-operations">window算子</a></p><h3 id="Structured-Streaming"><a href="#Structured-Streaming" class="headerlink" title="Structured Streaming"></a>Structured Streaming</h3><p>Structured Streaming是构建在Spark SQL引擎上的流式数据处理引擎，具有容错功能。你可以像在使用静态RDD数据一样来编写你的流式计算过程。当流数据连续不断的产生时，Spark SQL将会增量的，持续不断的处理这些数据并将结果更新到结果集中。你可以使用DataSet&#x2F;DataFrame API来展现数据流的aggregations, event-time windows,stream-to-batch joins等操作。</p><p>Structured Streaming的核心是将流式的数据看成一张不断增加的数据库表，这种流式的数据处理模型类似于数据块处理模型，你可以把静态数据库表的一些查询操作应用在流式计算中，Spark运行这些标准的SQL查询，从不断增加的无边界表中获取数据。如图所示：<br><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/spark-streaming/unbounded-table.png"></p><h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p><a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">http://spark.apache.org/docs/latest/streaming-programming-guide.html</a></p><p><a href="http://ifeve.com/spark-streaming-2/">官方文档的中文翻译（基于1.6，和最新的可能有些出入）</a></p><p><a href="https://blog.csdn.net/dongyunlon/article/details/52145685">https://blog.csdn.net/dongyunlon/article/details/52145685</a></p>]]></content>
      
      
      <categories>
          
          <category> 数据工程 </category>
          
          <category> 流式计算 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 流式计算 </tag>
            
            <tag> spark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>livy指南</title>
      <link href="/article/livy-guide.html"/>
      <url>/article/livy-guide.html</url>
      
        <content type="html"><![CDATA[<p>Livy是一个基于Spark的开源REST服务，它能够通过REST的方式将代码片段或是序列化的二进制代码提交到Spark集群中去执行。它提供了以下这些基本功能：</p><ul><li>提交Scala、Python或是R代码片段到远端的Spark集群上执行；</li><li>提交Java、Scala、Python所编写的Spark作业到远端的Spark集群上执行；</li><li>提交批处理应用在集群中运行。</li></ul><h3 id="livy安装"><a href="#livy安装" class="headerlink" title="livy安装"></a>livy安装</h3><p>livy安装很简单，从<a href="http://livy.incubator.apache.org/download/">官网</a>下载zip包。<br>解压，设置spark和hadoop的环境。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> SPARK_HOME=spark的路径</span><br><span class="line"><span class="built_in">export</span> HADOOP_CONF_DIR=/etc/hadoop/conf （hadoop配置路径）</span><br></pre></td></tr></table></figure><p>然后在livy的bin目录下执行：<br>livy-server start</p><h3 id="livy配置"><a href="#livy配置" class="headerlink" title="livy配置"></a>livy配置</h3><p>在conf&#x2F;livy.conf文件中有配置，常用的配置：</p><table><thead><tr><th>配置信息</th><th>含义</th></tr></thead><tbody><tr><td>livy.server.host &#x3D; 0.0.0.0</td><td>livy服务启动的host</td></tr><tr><td>livy.server.port &#x3D; 80</td><td>启动端口号</td></tr><tr><td>livy.spark.master &#x3D; yarn</td><td>livy执行spark master</td></tr><tr><td>livy.spark.deploy-mode &#x3D; client</td><td>spark启动模式</td></tr><tr><td>livy.repl.enable-hive-context &#x3D; true</td><td>启动hiveContext</td></tr><tr><td>livy.ui.enabled &#x3D; true</td><td>livy ui页面</td></tr></tbody></table><p>还有其他的配置，用户可以根据自己需求自行配置。<br>另外，当集群开启了kerberos验证，执行spark任务时报gss错误，需要在配置中加上：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">livy.server.launch.kerberos.keytab = /conf/xxx.keytab</span><br><span class="line">livy.server.launch.kerberos.principal = xxx@HADOOP.COM</span><br></pre></td></tr></table></figure><span id="more"></span><h3 id="livy的使用"><a href="#livy的使用" class="headerlink" title="livy的使用"></a>livy的使用</h3><p>livy提供了两种执行方式。</p><ul><li>一种是通过rest接口，见<a href="http://livy.incubator.apache.org/docs/latest/rest-api.html">官网</a>接口定义。<br>用户可以以REST请求的方式通过Livy启动一个新的Spark集群，Livy将每一个启动的Spark集群称之为一个会话（session），一个会话是由一个完整的Spark集群所构成的，并且通过RPC协议在Spark集群和Livy服务端之间进行通信。根据处理交互方式的不同，Livy将会话分成了两种类型：<ul><li>交互式会话（interactive session），这与Spark中的交互式处理相同，交互式会话在其启动后可以接收用户所提交的代码片段，在远端的Spark集群上编译并执行；</li><li>批处理会话（batch session），用户可以通过Livy以批处理的方式启动Spark应用，这样的一个方式在Livy中称之为批处理会话，这与Spark中的批处理是相同的。<br>可以看到，Livy所提供的核心功能与原生Spark是相同的，它提供了两种不同的会话类型来代替Spark中两类不同的处理交互方式。接下来我们具体了解一下这两种类型的会话。</li></ul></li></ul><p>接口都是异步提交形式，就是你提交一个batch任务或者解释执行一段code。如果提交是个batch任务，会创建一个batch，返回batchId，然后你通过GET &#x2F;batches&#x2F;{batchId}或者执行状态，和执行结果，这也是立即返回。如果想同步获取结果，需要程序自己循环获取状态，当success后再退出循环。解释执行方式类似，创建session kind，然后在POST &#x2F;sessions&#x2F;{sessionId}&#x2F;statements中提交code。通过GET &#x2F;sessions&#x2F;{sessionId}&#x2F;statements&#x2F;{statementId}获取执行状态，也是异步返回。<br>batch任务提交示例：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -X POST -H <span class="string">&quot;Content-Type: application/json&quot;</span> -d <span class="string">&#x27;&#123;&quot;file&quot;:&quot;hdfs://xx/user/laiwb/spark-jars/spark-ml.jar&quot;,&quot;className&quot;:&quot;com.xx.data.livy.SparkExp&quot;,&quot;conf&quot;:&#123;&quot;spark.dynamicAllocation.enabled&quot;:&quot;true&quot;&#125;&#125;&#x27;</span> http://192.168.18.10:80/batches</span><br></pre></td></tr></table></figure><p>获取batch任务：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -X GET  http://192.168.18.10:80/batches/&#123;batchId&#125;</span><br></pre></td></tr></table></figure><ul><li>通过<a href="http://livy.incubator.apache.org/docs/latest/programmatic-api.html">livy Programmatic</a>形式。livy封装了sparkContext，添加了对象共享功能（setSharedObject）。下面是spark代码与livy代码对比图：</li></ul><p><img src="http://hexo-1256892004.cos.ap-beijing.myqcloud.com/livy-guide/livy-api.png"></p><p>上图是pyspark，livy也提供了java&#x2F;scala API。spark程序需要继承Job类，覆盖Job类的call()方法。示例如下：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SparkExample</span> <span class="keyword">extends</span> <span class="title">Job</span>[<span class="type">Double</span>]</span>&#123;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">call</span></span>(jobContext: <span class="type">JobContext</span>): <span class="type">Double</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> spark = jobContext.hivectx()</span><br><span class="line">    <span class="keyword">val</span> db = spark.sql(<span class="string">&quot;select max(cnt) max, min(cnt) min, avg(cnt) avg ,stddev_pop(cnt) std from laiwb.user_xx where cast(substr(uid,4) as int) &gt; 100000000 &quot;</span>)</span><br><span class="line">    jobContext.setSharedObject(<span class="string">&quot;avg&quot;</span>, db)</span><br><span class="line">    <span class="keyword">val</span> dou = db.collect().head.getDouble(<span class="number">2</span>)</span><br><span class="line">    dou</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>定义一个spark任务SparkExample，并将其打成jar包，上传到hdfs，也可以放在本地目录中，然后写Submit类。Submit类主要代码如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">// 定义一个livy client 连接，url为livy服务的地址</span><br><span class="line">val client = new LivyClientBuilder(false).setURI(new URI(url)).build()  </span><br><span class="line">// 将SparkExample类打好的jar包（已经上传至hdfs）加入client中。如果jar包在本地，使用client.uploadJar(new File(jar)).get()</span><br><span class="line">client.addJar(new URI(jar))</span><br><span class="line">// main class</span><br><span class="line">val spe = Class.forName(&quot;com.xx.data.livy.SparkExample&quot;).newInstance.asInstanceOf[SparkExample]</span><br><span class="line">// 提交任务，submit()方法返回的是JobHandle对象，继承于Future，是个异步任务。如果想等待任务执行，可以通过get()方法。</span><br><span class="line">// dd便是livy spark任务执行完返回的double值</span><br><span class="line">val dd = client.submit(spe).get()</span><br></pre></td></tr></table></figure><p>在SparkExample类中添加了</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jobContext.setSharedObject(&quot;avg&quot;, db)</span><br></pre></td></tr></table></figure><p>这是livy提供的共享对象功能，在其他任务中可以通过getSharedObject()通过key获取到此共享对象。<br>如果一个任务直接通过getSharedObject()，可以在spark stage界面上看到此对象的task是skip状态，说明它是被缓存起来，不在从DAG的起始开始执行。</p><h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p><a href="http://livy.incubator.apache.org/">http://livy.incubator.apache.org</a></p><p><a href="https://blog.csdn.net/imgxr/article/details/80130340">https://blog.csdn.net/imgxr/article/details/80130340</a></p>]]></content>
      
      
      <categories>
          
          <category> 数据工程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spark </tag>
            
            <tag> livy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>airflow使用指南</title>
      <link href="/article/airflow-guide.html"/>
      <url>/article/airflow-guide.html</url>
      
        <content type="html"><![CDATA[<p>airflow 是一个编排、调度和监控workflow的平台，由Airbnb开源。airflow 将workflow编排为tasks组成的DAGs，调度器在一组workers上按照指定的依赖关系执行tasks。同时，airflow 提供了丰富的命令行工具和简单易用的用户界面以便用户查看和操作，并且airflow提供了监控和报警系统。</p><h3 id="airflow-核心概念"><a href="#airflow-核心概念" class="headerlink" title="airflow 核心概念"></a>airflow 核心概念</h3><ul><li>DAGs：即有向无环图(Directed Acyclic Graph)，将所有需要运行的tasks按照依赖关系组织起来，描述的是所有tasks执行的顺序。</li><li>Operators：可以简单理解为一个class，描述了DAG中一个具体的task具体要做的事。其中，airflow内置了很多operators，如BashOperator 执行一个bash 命令，PythonOperator 调用任意的Python 函数，EmailOperator 用于发送邮件，HTTPOperator 用于发送HTTP请求， SqlOperator 用于执行SQL命令…同时，用户可以自定义Operator，这给用户提供了极大的便利性。</li><li>Tasks：Task 是 Operator的一个实例，也就是DAGs中的一个node。</li><li>Task Instance：task的一次运行。task instance 有自己的状态，包括”running”, “success”, “failed”, “skipped”, “up for retry”等。</li><li>Task Relationships：DAGs中的不同Tasks之间可以有依赖关系，如 TaskA &gt;&gt; TaskB，表明TaskB依赖于TaskA。</li></ul><p>通过将DAGs和Operators结合起来，用户就可以创建各种复杂的 workflow了。</p><h3 id="operators"><a href="#operators" class="headerlink" title="operators"></a>operators</h3><p>下面讲解下常见的operator，以及如何使用，注意点。</p><span id="more"></span><h4 id="BashOperator"><a href="#BashOperator" class="headerlink" title="BashOperator"></a>BashOperator</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">run_this = BashOperator(</span><br><span class="line">    task_id=<span class="string">&#x27;run_after_loop&#x27;</span>, </span><br><span class="line">    bash_command=<span class="string">&#x27;echo 1&#x27;</span>, </span><br><span class="line">    dag=dag)</span><br></pre></td></tr></table></figure><p>很简单的一个operator，执行bash命令。其中bash命令返回状态码0时，表示此task成功；否则，失败。</p><h4 id="PythonOperator"><a href="#PythonOperator" class="headerlink" title="PythonOperator"></a>PythonOperator</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">run_this = PythonOperator(</span><br><span class="line">    task_id=<span class="string">&#x27;print_the_context&#x27;</span>,</span><br><span class="line">    python_callable=print_context,</span><br><span class="line">    op_kwargs=&#123;<span class="string">&#x27;param&#x27;</span>: <span class="number">10</span>&#125;,</span><br><span class="line">    dag=dag,</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>顾名思义，就是执行python函数。参数通过op_kwargs传递。如果想要任务失败，需要raise ValueError。</p><h4 id="BranchPythonOperator"><a href="#BranchPythonOperator" class="headerlink" title="BranchPythonOperator"></a>BranchPythonOperator</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">options = [<span class="string">&#x27;branch_a&#x27;</span>, <span class="string">&#x27;branch_b&#x27;</span>, <span class="string">&#x27;branch_c&#x27;</span>, <span class="string">&#x27;branch_d&#x27;</span>]</span><br><span class="line"></span><br><span class="line">branching = BranchPythonOperator(</span><br><span class="line">    task_id=<span class="string">&#x27;branching&#x27;</span>,</span><br><span class="line">    python_callable=<span class="keyword">lambda</span>: random.choice(options),</span><br><span class="line">    dag=dag,</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>分支操作，通过python_callable返回值选定下一个依赖执行的task，即python_callable返回值等于下一个依赖task的task_id，而其他未被选中的task，则会被skipped。如果在task后面还有依赖join，此时需要将join的trigger_rule设置为‘one_success’ ，如下图所示：<br><img src="http://hexo-1256892004.cos.ap-beijing.myqcloud.com/airflow-guide/branch_operator.png"></p><h4 id="SubDagOperator"><a href="#SubDagOperator" class="headerlink" title="SubDagOperator"></a>SubDagOperator</h4><p>当dag中某部分tasks结构完整，功能统一，能够独立提供某项流程时。就像软件开发中模块划分一样，我们也希望将这部分task依赖抽离出来，独立成为单一的DAG，且能够很好的嵌入其他DAG，完成整个流程。这便出现了subDag。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">section_1 = SubDagOperator(</span><br><span class="line">    task_id=<span class="string">&#x27;section-1&#x27;</span>,</span><br><span class="line">    subdag=subdag(<span class="string">&#x27;parentDag&#x27;</span>, <span class="string">&#x27;subDag&#x27;</span>, args),</span><br><span class="line">    default_args=args,</span><br><span class="line">    dag=dag,</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>其中subdag是个函数，返回Dag实例。假如subDag为Dag A，那么A的dag_id必须为parentDag的dag_id+ ‘.’ + subdag_id。即</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dag_subdag = DAG(</span><br><span class="line">        dag_id=<span class="string">&#x27;%s.%s&#x27;</span> % (parent_dag_name, child_dag_name),</span><br><span class="line">        default_args=args,</span><br><span class="line">        schedule_interval=<span class="string">&quot;@daily&quot;</span>,</span><br><span class="line">    )</span><br></pre></td></tr></table></figure><p>添加subDag后的Dag如：<br><img src="http://hexo-1256892004.cos.ap-beijing.myqcloud.com/airflow-guide/sub_dag.png"></p><p>select-1作为是Dag的一个task，内部则是一个subDag，也有完整的task任务关系。</p><h4 id="TriggerDagRunOperator"><a href="#TriggerDagRunOperator" class="headerlink" title="TriggerDagRunOperator"></a>TriggerDagRunOperator</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">trigger = TriggerDagRunOperator(</span><br><span class="line">    task_id=<span class="string">&#x27;test_trigger_dagrun&#x27;</span>,</span><br><span class="line">    trigger_dag_id=<span class="string">&quot;example_trigger_target_dag&quot;</span>,</span><br><span class="line">    python_callable=conditionally_trigger,</span><br><span class="line">    params=&#123;<span class="string">&#x27;condition_param&#x27;</span>: <span class="literal">True</span>, <span class="string">&#x27;message&#x27;</span>: <span class="string">&#x27;Hello World&#x27;</span>&#125;,</span><br><span class="line">    dag=dag,</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>此operator执行了python_callable对应的方法后，会触发trigger_dag_id对应的dag执行，并通过conditionally_trigger函数中的参数(xxx_obj)将参数传递给trigger_dag，trigger_dag通过kwargs获取到xxx参数。此operator在不影响原来的任务依赖下，能够触发额外的操作，具体使用可根据场景进行选择。</p><h3 id="scheduler"><a href="#scheduler" class="headerlink" title="scheduler"></a>scheduler</h3><p>除了配置task的operator，还需要对整个dag配置调度和触发的限制条件。</p><h4 id="DAG-RUN"><a href="#DAG-RUN" class="headerlink" title="DAG RUN"></a>DAG RUN</h4><ul><li>schedule_interval：调度控制。None代表不会被schedule，只能外部触发；@once只会被schedule触发一次。其他即可通过cron表达式设置。</li><li>Backfill and Catchup：如果DAG设置有start_date（python datetime），且schedule_interval定义了调度周期，那么有个问题，是否需要从start_date按照schedule_interval调度执行到最新时间，或者配置的end_date。这个通过catchup参数配置，catchup&#x3D;False表示不调度执行历史，只会在DAG创建时执行最近一次的schedule_interval。默认catchup&#x3D;True</li></ul><h4 id="task-dependency"><a href="#task-dependency" class="headerlink" title="task dependency"></a>task dependency</h4><ul><li><p>trigger_rule: </p><ul><li>all_success: (default) 所有的父任务都成功</li><li>all_failed: 所有的父任务都失败</li><li>all_done: 所有父任务都已经执行完</li><li>one_failed: 只要有一个父任务失败，就执行，不需要等所有的父任务失败</li><li>one_success: 只要有一个父任务成功，就执行，不需要等所有的父任务成功</li><li>dummy: dependencies are just for show, trigger at will</li></ul></li><li><p>xcoms</p></li></ul><p>xcoms让task之间能够交换信息。xcoms通过’pushed’(sent)和’pulled’(received)来传递变量数据。当一个task push xcom，它变能够被其他task所可用。task通过调用xcom_push()方法或者通过直接从task中的python_callable函数中获取其返回值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">push</span>(<span class="params">**kwargs</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Pushes an XCom without a specific target&quot;&quot;&quot;</span></span><br><span class="line">    kwargs[<span class="string">&#x27;ti&#x27;</span>].xcom_push(key=<span class="string">&#x27;value from pusher 1&#x27;</span>, value=value_1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">push_by_returning</span>(<span class="params">**kwargs</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Pushes an XCom without a specific target, just by returning it&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> value_2</span><br></pre></td></tr></table></figure><p>而获取xcom通过 </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ti = kwargs[<span class="string">&#x27;ti&#x27;</span>]</span><br><span class="line">v1 = ti.xcom_pull(key=<span class="literal">None</span>, task_ids=<span class="string">&#x27;push&#x27;</span>)</span><br><span class="line">v2 = ti.xcom_pull(task_ids=<span class="string">&#x27;push_by_returning&#x27;</span>)</span><br></pre></td></tr></table></figure><h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p><a href="https://airflow.incubator.apache.org/">https://airflow.incubator.apache.org/</a></p><p><a href="https://github.com/apache/incubator-airflow">https://github.com/apache/incubator-airflow</a></p>]]></content>
      
      
      <categories>
          
          <category> 数据工程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> airflow </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Google Spanner</title>
      <link href="/article/google-spanner.html"/>
      <url>/article/google-spanner.html</url>
      
        <content type="html"><![CDATA[<p>原始译文厦门大学林子雨老师翻译，见<a href="http://dblab.xmu.edu.cn/post/google-spanner/">Google Spanner (中文版)</a></p><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>Spanner是谷歌公司研发的、可扩展的、多版本、全球分布式、同步复制数据库。它是第一个把数据分布在全球范围内的系统，并且支持外部一致性的分布式事务。本文描述了Spanner的架构、特性、不同设计决策的背后机理和一个新的时间API，这个API可以暴露时钟的不确定性。这个API及其实现，对于支持外部一致性和许多强大特性而言，是非常重要的，这些强大特性包括：非阻塞的读、不采用锁机制的只读事务、原子模式变更。</p><p>Spanner是个可扩展，多版本，全球分布式还支持同步复制的数据库。他是Google的第一个可以全球扩展并且支持外部一致的事务。Spanner能做到这些，离不开一个用GPS和原子钟实现的时间API。这个API能将数据中心之间的时间同步精确到10ms以内。因此有几个给力的功能：无锁读事务，原子schema修改，读历史数据无block。</p><h3 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h3><p>从高层看Spanner是通过Paxos状态机将分区好的数据分布在全球的。数据复制全球化的，用户可以指定数据复制的份数和存储的地点。Spanner可以在集群或者数据发生变化的时候将数据迁移到合适的地点，做负载均衡。</p><p>spanner提供一些有趣的特性：</p><ul><li>应用可以细粒度的指定数据分布的位置。精确的指定数据离用户有多远，可以有效的控制读延迟(读延迟取决于最近的拷贝)。指定数据拷贝之间有多远，可以控制写的延迟(写延迟取决于最远的拷贝)。还要数据的复制份数，可以控制数据的可靠性和读性能。(多写几份，可以抵御更大的事故)</li><li>Spanner还有两个一般分布式数据库不具备的特性：读写的外部一致性，基于时间戳的全局的读一致。这两个特性可以让Spanner支持一致的备份，一致的MapReduce，还有原子的Schema修改。</li></ul><p>这些特性都得益于spanner有个全球时间同步机制，可以在数据提交的时候给出一个时间戳。因为时间是系列化的，所以才有外部一致性。这个很容易理解，如果有两个提交，一个在T1,一个在T2。那有更晚的时间戳那个提交是正确的。</p><h3 id="与关系型数据库和nosql对比"><a href="#与关系型数据库和nosql对比" class="headerlink" title="与关系型数据库和nosql对比"></a>与关系型数据库和nosql对比</h3><p><a href="https://www.infoq.cn/article/growth-path-of-spanner">https://www.infoq.cn/article/growth-path-of-spanner</a></p>]]></content>
      
      
      <categories>
          
          <category> 数据工程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
            <tag> Google </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HBase case之scan batch</title>
      <link href="/article/hbase-case-batch.html"/>
      <url>/article/hbase-case-batch.html</url>
      
        <content type="html"><![CDATA[<p>标签数据存储在Hbase中，为了加速标签探索功能，会每天导出一份全量数据表。有时候用户也会进行特定标签勾选导出需求。</p><h3 id="导出遇到的问题"><a href="#导出遇到的问题" class="headerlink" title="导出遇到的问题"></a>导出遇到的问题</h3><p>导出后，出现部分用户，同一个用户多条数据（两条为主），见下图：<br><img src="http://hexo-1256892004.cos.ap-beijing.myqcloud.com/hbase-case-batch/tag-1.png"></p><p><img src="http://hexo-1256892004.cos.ap-beijing.myqcloud.com/hbase-case-batch/tag-2.png"></p><p>从图中可以看出，出现了重复用户uid。</p><span id="more"></span><h3 id="问题原因"><a href="#问题原因" class="headerlink" title="问题原因"></a>问题原因</h3><p>首先想到会不会是源数据问题，即Hbase中存储的数据造成的。为何如此想，是因为为了用户scan并发度和热点问题，对rowkey进行了hash(uid)分区。会不会在之前hash方法有变化，造成了脏数据问题。这点个人想了下，貌似也没变过hash函数啊，不应该出现uid hash后出现不同值啊。</p><p>然后对重复的uid随机抽取了几个，查看了数据情况。发现重复的uid的标签数据，标签总是错开的，即第一条数据有标签A;B;C,第二条A;B;C数据为空，而其他标签数据存在。这是一个突破口，思考会不会在导出的过程中，同一个用户的标签并截成了两段，出现了两天数据。为什么如此，这个需要简单介绍下在使用spark程序导出Hbase存储的标签的code。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">val</span> <span class="variable">hbaseCols</span> <span class="operator">=</span> hBaseContext.hbaseRDD(TableName.valueOf(hbase_table), scan, (r: (ImmutableBytesWritable, Result)) =&gt; &#123;</span><br><span class="line">      <span class="type">val</span> <span class="variable">rowkey</span> <span class="operator">=</span> Bytes.toString(r._1.copyBytes())</span><br><span class="line">      <span class="type">val</span> <span class="variable">uid</span> <span class="operator">=</span> rowkey.substring(<span class="number">3</span>).toInt</span><br><span class="line">      <span class="type">val</span> <span class="variable">res</span> <span class="operator">=</span> r._2.rawCells().map(cell =&gt; (Bytes.toString(cell.getQualifierArray, cell.getQualifierOffset, cell.getQualifierLength), cell.getValue)).toMap</span><br><span class="line">      <span class="type">val</span> <span class="variable">cols</span> <span class="operator">=</span> columns.map(c =&gt; &#123;</span><br><span class="line">        res.getOrElse(c._2, <span class="literal">null</span>)</span><br><span class="line">      &#125;)</span><br><span class="line">      Row.fromSeq(uid +: cols)</span><br><span class="line">    &#125;)</span><br></pre></td></tr></table></figure><p>其中Result类是Hbase client读取Hbase中数据，内部是cell数组形式，ImmutableBytesWritable中存储了数据行的rowkey。所以返回的(ImmutableBytesWritable, Result)便是封装了(rowkey,List<columns-value>)的元组。在scan过程，会根据选取的标签列，生成List。但为什么会生成多条数据呢，即List<columns-value>被分成了两个List。通过代码中hBaseContext中需要传入scan参数，而scan变量中设置了过滤条件，和其他属性,见code:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@transient</span> <span class="type">val</span> <span class="variable">scan</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scan</span>()</span><br><span class="line">scan.setBatch(<span class="number">1000000</span>)</span><br><span class="line">columns.map(s =&gt; &#123;</span><br><span class="line">  scan.addColumn(Bytes.toBytes(s._1), Bytes.toBytes(s._2))</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><p>而问题的来源在于<font color=red size=4>scan.setBatch(1000000)</font>，当时设置Batch，为了通过一次scan达到一定量后在返回，起到减少RPC的作用，加快数据导出。在Hbase API查询时，能够通过next()调用获取数据，而通过batch减少client与server见的RPC调用。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Set the maximum number of values to return for each call to next()</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> batch the maximum number of values</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setBatch</span><span class="params">(<span class="type">int</span> batch)</span> &#123;</span><br><span class="line">  <span class="keyword">if</span> (<span class="built_in">this</span>.hasFilter() &amp;&amp; <span class="built_in">this</span>.filter.hasFilterRow()) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IncompatibleFilterException</span>(</span><br><span class="line">      <span class="string">&quot;Cannot set batch on a scan using a filter&quot;</span> +</span><br><span class="line">      <span class="string">&quot; that returns true for filter.hasFilterRow&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">this</span>.batch = batch;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>batch的注释说明每次调用next()返回的最大value个数。<br>而spark-hbase模式，是通过InputFormat直接访问底层数据，然后转换成rdd数据。而设置了batch，同样会让读取的列数达到batch数目时做截断，这可能就造成某些行的列数据被拆分成了不同的batch，也就造成了同一个用户数据变成了两行数据。</p><h3 id="Hbase-batch与caching"><a href="#Hbase-batch与caching" class="headerlink" title="Hbase batch与caching"></a>Hbase batch与caching</h3><p>每一个next()调用都会为每行数据生成一个单独RPC请求，即使使用next(int nbRows)方法，也是如此，因为该方法仅仅是在客户端循环地调用next()方法。很显然，当单元格数据较小时，这样做的性能不会很好。因此，如果一次RPC请求可以获取多行数据，这样更会有意义。这样的方法可以由扫描器缓存实现，默认情况下，这个缓存是关闭的。</p><p>setScannerCaching()可以设置缓存大小，getScannerCaching()可以返回当前缓存大小的值。每次用户调用getScanner(scan)之后，API都会把设定值配置到扫描实例中——除非用户使用了扫描层面的配置并覆盖了表层面的配置，扫描层面的配置优先级最高。可以使用下列Scan类方法设置扫描级的缓存:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> <span class="title function_">setScannerCaching</span><span class="params">(<span class="type">int</span> scannerCaching)</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">getScannerCaching</span><span class="params">()</span></span><br></pre></td></tr></table></figure><p>如果对于数据量非常大的行，这些行很有可能超过客户端进程的内存容量。HBase和它的客户端API对这个问题有一个解决方法：批量。用户可以使用以下方法控制获取批量操作：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> <span class="title function_">setBatch</span><span class="params">(<span class="type">int</span> batch)</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">getBatch</span><span class="params">()</span></span><br></pre></td></tr></table></figure><p>缓存是面向行一级的操作，而批量是面向列一级的操作。批量可以让用户选择每一次ResultScanner()实例的next()操作要取回多少列。<br>**如果一行包括的列数超过了批量中设置的值，则可以将这一行分片，每次next操作返回一片。 **</p><p>这样便可以通过caching和batch来影响RPC次数。下表展示了不同caching和batch的RPC次数，其他一行的列数为20：</p><p>|缓存|批量处理|Result个数|RPC次数|说明|<br>|—–|—–|—–|—–|<br>|1|1|200|201|每个列都作为一个Result实例返回。最后还多一个RPC确认扫描完成|<br>|200|1|200|2|每个Result实例都只包含一列的值，不过它们都被一次RPC请求取回|<br>|2|10|20|11|批量参数是一行所包含的列数的一半，所以200列除以10，需要20个result实例。同时需要10次RPC请求取回。|<br>|5|100|10|3|对一行来讲，这个批量参数实在是太大了，所以一行的20列都被放入到了一个Result实例中。同时缓存为5，所以10个Result实例被两次RPC请求取回。|<br>|5|20|10|3|同上，不过这次的批量值与一行列数正好相同，所以输出与上面一种情况相同|<br>|10|10|20|3|这次把表分成了较小的result实例，但使用了较大的缓存值，所以也是只用了两次RPC请求就返回了数据|</p><h3 id="问题解决"><a href="#问题解决" class="headerlink" title="问题解决"></a>问题解决</h3><p>找到原因了，解决方法也简单，将setBatch()去掉即可。重新导出，不在出现重复的uid数据了。</p>]]></content>
      
      
      <categories>
          
          <category> HBase </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HBase </tag>
            
            <tag> 数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HBase系列之snapshot</title>
      <link href="/article/hbase-snapshot.html"/>
      <url>/article/hbase-snapshot.html</url>
      
        <content type="html"><![CDATA[<h3 id="snapshot（快照）基础原理"><a href="#snapshot（快照）基础原理" class="headerlink" title="snapshot（快照）基础原理"></a>snapshot（快照）基础原理</h3><p>snapshot是很多存储系统和数据库系统都支持的功能。一个snapshot是一个全部文件系统、或者某个目录在某一时刻的镜像。实现数据文件镜像最简单粗暴的方式是加锁拷贝（之所以需要加锁，是因为镜像得到的数据必须是某一时刻完全一致的数据），拷贝的这段时间不允许对原数据进行任何形式的更新删除，仅提供只读操作，拷贝完成之后再释放锁。这种方式涉及数据的实际拷贝，数据量大的情况下必然会花费大量时间，长时间的加锁拷贝必然导致客户端长时间不能更新删除，这是生产线上不能容忍的。</p><p>snapshot机制并不会拷贝数据，可以理解为它是原数据的一份指针。在HBase这种LSM类型系统结构下是比较容易理解的，我们知道HBase数据文件一旦落到磁盘之后就不再允许更新删除等原地修改操作，如果想更新删除的话可以追加写入新文件（HBase中根本没有更新接口，删除命令也是追加写入）。这种机制下实现某个表的snapshot只需要给当前表的所有文件分别新建一个引用（指针），其他新写入的数据重新创建一个新文件写入即可。</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/hbase-snapshot/snapshot.png"></p><p>snapshot流程主要涉及3个步骤：</p><ol><li><p>加一把全局锁，此时不允许任何的数据写入更新以及删除</p></li><li><p>将Memstore中的缓存数据flush到文件中（可选）</p></li><li><p>为所有HFile文件分别新建引用指针，这些指针元数据就是snapshot</p></li></ol><h3 id="snapshot作用"><a href="#snapshot作用" class="headerlink" title="snapshot作用"></a>snapshot作用</h3><ul><li>备份：通常情况下，对重要的业务数据，建议至少每天执行一次snapshot来保存数据的快照记录，并且定期清理过期快照，这样如果业务发生重要错误需要回滚的话是可以回滚到之前的一个快照点的。</li><li>迁移：可以使用ExportSnapshot功能将快照导出到另一个集群，实现数据的迁移<span id="more"></span></li></ul><h3 id="snapshot相关命令"><a href="#snapshot相关命令" class="headerlink" title="snapshot相关命令"></a>snapshot相关命令</h3><p>snapshot最常用的命令有snapshot、restore_snapshot、clone_snapshot以及ExportSnapshot这个工具，具体使用方法如下：</p><p>为表’sourceTable’打一个快照’snapshotName’，快照并不涉及数据移动，可以在线完成。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase&gt; snapshot <span class="string">&#x27;sourceTable&#x27;</span>, ‘snapshotName<span class="string">&#x27;</span></span><br></pre></td></tr></table></figure><p>恢复指定快照，恢复过程会替代原有数据，将表还原到快照点，快照点之后的所有更新将会丢失。需要注意的是原表需要先disable掉，才能执行restore_snapshot操作。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase&gt; restore_snapshot ‘snapshotName<span class="string">&#x27;</span></span><br></pre></td></tr></table></figure><p>根据快照恢复出一个新表，恢复过程不涉及数据移动，可以在秒级完成。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase&gt; clone_snapshot <span class="string">&#x27;snapshotName&#x27;</span>, ‘tableName<span class="string">&#x27;</span></span><br></pre></td></tr></table></figure><p>使用ExportSnapshot命令可以将A集群的快照数据迁移到B集群，ExportSnapshot是HDFS层面的操作，会使用MR进行数据的并行迁移，因此需要在开启MR的机器上进行迁移。HMaster和HRegionServer并不参与这个过程，因此不会带来额外的内存开销以及GC开销。唯一的影响是DN在拷贝数据的时候需要额外的带宽以及IO负载，ExportSnapshot也针对这个问题设置了参数-bandwidth来限制带宽的使用。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hbase org.apache.hadoop.hbase.snapshot.ExportSnapshot \</span><br><span class="line">    -snapshot MySnapshot -copy-from hdfs://srv2:8082/hbase \</span><br><span class="line">    -copy-to hdfs://srv1:50070/hbase -mappers 16 -bandwidth  1024\</span><br></pre></td></tr></table></figure><h3 id="clone-snapshot的实现"><a href="#clone-snapshot的实现" class="headerlink" title="clone_snapshot的实现"></a>clone_snapshot的实现</h3><p>在snapshot原理中，我们获知：snapshot并不会拷贝数据，而是维护原数据的一份指针。可能很多人会有一个疑惑，如果我把原数据删掉，snapshot是否就失效了，毕竟它只是一份指针。最开始我也是这样认为的，后来在自己误删除了原表，然后使用snapshot却将数据还原了，对此感到很不可思议。下面讲解下snapshot内部是如何做到的。</p><p>首先，进行了snapshot的表，在删除操作中，并不会真正的删除数据，而是将数据放入archive目录下。和普通表删除的情况不同的是，普通表一旦删除，刚开始是可以在archive中看到删除表的数据文件，但是等待一段时间后archive中的数据就会被彻底删除，再也无法找回。这是因为master上会启动一个定期清理archive中垃圾文件的线程（HFileCleaner），定期会对这些被删除的垃圾文件进行清理。但是snapshot原始表被删除之后进入archive，并不可以被定期清理掉，上文说过clone出来的新表并没有clone真正的文件，而是生成的指向原始文件的连接，这类文件称之为LinkFile，很显然，只要LinkFile还指向这些原始文件，它们就不可以被删除。</p><p><font color=blue size=4>那么什么时候LinkFile会变成真实的数据文件？</font></p><p>HBase中一个region分裂成两个子region后，子region的文件也是引用文件（见<a href="">HBase系列之region-split</a>），这些引用文件是在执行compact的时候才真正将父region中的文件迁移到自己的文件目录下。LinkFile也一样，在clone出的新表执行<font color=red size=3>compact</font>的时候才将合并后的文件写到新目录并将相关的LinkFile删除，理论上也是借着compact顺便做了这件事。</p><p>所以当时我clone了新表出来后，我在region_server上查看HFile文件，看到了：</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/hbase-snapshot/snapshot-hfile.png"></p><p>从图中可以看出，HFile为0，说明还没有HFile文件，但我在hbase shell中却能够get数据，现在知道HFile没有，而是通过LinkFile指向原始文件。如果想把生成HFile，怎么做呢？很简单，只需要进行让region进行compact，你可以不用管它，在进行插入数据而自动触发compact，也可以手动对新表执行major_compact操作：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">major_compact ’clone_table’</span><br></pre></td></tr></table></figure><p>这样当compact执行完，你就可以在region_server上看到HFile了。</p><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="http://hbasefly.com/2017/09/17/hbase-snapshot/">http://hbasefly.com/2017/09/17/hbase-snapshot/</a></p>]]></content>
      
      
      <categories>
          
          <category> HBase </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HBase </tag>
            
            <tag> 数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HBase系列之region-split上</title>
      <link href="/article/hbase-region-split.html"/>
      <url>/article/hbase-region-split.html</url>
      
        <content type="html"><![CDATA[<p>Region自动切分是HBase能够拥有良好扩张性的最重要因素之一，也必然是所有分布式系统追求无限扩展性的一副良药。那么region又是如何自动切分的呢，触发的条件又是什么？</p><h3 id="Region切分触发策略"><a href="#Region切分触发策略" class="headerlink" title="Region切分触发策略"></a>Region切分触发策略</h3><p>在最新稳定版（1.2.6）中，HBase已经有多达6种切分触发策略。即RegionSplitPolicy的实现子类共有6个，如下类图：<br><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/hbase-region-split/split-class.png"></p><p>当然，每种触发策略都有各自的适用场景，用户可以根据业务在表级别选择不同的切分触发策略。常见的切分策略如下图：<br><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/hbase-region-split/region.png"></p><h4 id="ConstantSizeRegionSplitPolicy"><a href="#ConstantSizeRegionSplitPolicy" class="headerlink" title="ConstantSizeRegionSplitPolicy"></a>ConstantSizeRegionSplitPolicy</h4><p>0.94版本前默认切分策略。这是最容易理解但也最容易产生误解的切分策略，从字面意思来看，当region大小大于某个阈值（hbase.hregion.max.filesize）之后就会触发切分，实际上并不是这样，真正实现中这个阈值是对于某个store来说的，即一个region中最大store的大小大于设置阈值之后才会触发切分。另外一个大家比较关心的问题是这里所说的store大小是压缩后的文件总大小还是未压缩文件总大小，实际实现中store大小为压缩后的文件大小（采用压缩的场景）。ConstantSizeRegionSplitPolicy相对来来说最容易想到，但是在生产线上这种切分策略却有相当大的弊端：切分策略对于大表和小表没有明显的区分。阈值（hbase.hregion.max.filesize）设置较大对大表比较友好，但是小表就有可能不会触发分裂，极端情况下可能就1个，这对业务来说并不是什么好事。如果设置较小则对小表友好，但一个大表就会在整个集群产生大量的region，这对于集群的管理、资源使用、failover来说都不是一件好事。</p><span id="more"></span><h4 id="IncreasingToUpperBoundRegionSplitPolicy"><a href="#IncreasingToUpperBoundRegionSplitPolicy" class="headerlink" title="IncreasingToUpperBoundRegionSplitPolicy"></a>IncreasingToUpperBoundRegionSplitPolicy</h4><p>0.94版本~2.0版本默认切分策略。这种切分策略微微有些复杂，总体来看和ConstantSizeRegionSplitPolicy思路相同，一个region中最大store大小大于设置阈值就会触发切分。但是这个阈值并不像ConstantSizeRegionSplitPolicy是一个固定的值，而是会在一定条件下不断调整，调整规则和region所属表在当前regionserver上的region个数有关系 ：$regions^3$ $\times$ flush size $\times$ 2,即<strong>Region增加策略的初使化大小(其可由配置控制参数为hbase.increasing.policy.initial.size指定；如果没有配置该参数，由取值MemStore的缓存刷新值大小的两倍，MemStore缓存刷新值默认其值为128M，即此时取值256M）$\times$  当前Table Region数的3次方</strong>，当然阈值并不会无限增大，最大值为用户设置的MaxRegionFileSize。这种切分策略很好的弥补了ConstantSizeRegionSplitPolicy的短板，能够自适应大表和小表。而且在大集群条件下对于很多大表来说表现很优秀，但并不完美，这种策略下很多小表会在大集群中产生大量小region，分散在整个集群中。而且在发生region迁移时也可能会触发region分裂。Region增加策略的初使化大小源码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> getConf();</span><br><span class="line">initialSize = conf.getLong(<span class="string">&quot;hbase.increasing.policy.initial.size&quot;</span>, -<span class="number">1</span>);</span><br><span class="line"><span class="keyword">if</span> (initialSize &gt; <span class="number">0</span>) &#123;</span><br><span class="line">  <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">HTableDescriptor</span> <span class="variable">desc</span> <span class="operator">=</span> region.getTableDesc();</span><br><span class="line"><span class="keyword">if</span> (desc != <span class="literal">null</span>) &#123;</span><br><span class="line">  initialSize = <span class="number">2</span> * desc.getMemStoreFlushSize();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (initialSize &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">      initialSize = <span class="number">2</span> * conf.getLong(HConstants.HREGION_MEMSTORE_FLUSH_SIZE,</span><br><span class="line">                           HTableDescriptor.DEFAULT_MEMSTORE_FLUSH_SIZE);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>确定其拆分控制大小的实现方法如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@return</span> Region max size or &#123;<span class="doctag">@code</span> count of regions cubed * 2 * flushsize&#125;,</span></span><br><span class="line"><span class="comment">   * which ever is smaller; guard against there being zero regions on this server.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">protected</span> <span class="type">long</span> <span class="title function_">getSizeToCheck</span><span class="params">(<span class="keyword">final</span> <span class="type">int</span> tableRegionsCount)</span> &#123;</span><br><span class="line">    <span class="comment">// safety check for 100 to avoid numerical overflow in extreme cases</span></span><br><span class="line">    <span class="keyword">return</span> tableRegionsCount == <span class="number">0</span> || tableRegionsCount &gt; <span class="number">100</span></span><br><span class="line">               ? getDesiredMaxFileSize()</span><br><span class="line">               : Math.min(getDesiredMaxFileSize(),</span><br><span class="line">                          initialSize * tableRegionsCount * tableRegionsCount * tableRegionsCount);</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>要想达到每次拆分大小为10G的标准，则需要经过以下4次拆分：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">第一次split：1^3 * 256 = 256MB </span><br><span class="line">第二次split：2^3 * 256 = 2048MB </span><br><span class="line">第三次split：3^3 * 256 = 6912MB </span><br><span class="line">第四次split：4^3 * 256 = 16384MB &gt; 10GB，因此取较小的值10GB </span><br><span class="line">后面每次split的size都是10GB了</span><br></pre></td></tr></table></figure><h4 id="SteppingSplitPolicy"><a href="#SteppingSplitPolicy" class="headerlink" title="SteppingSplitPolicy"></a>SteppingSplitPolicy</h4><p>2.0版本默认切分策略。这种切分策略的切分阈值又发生了变化，相比IncreasingToUpperBoundRegionSplitPolicy简单了一些，依然和待分裂region所属表在当前regionserver上的region个数有关系，如果region个数等于1，切分阈值为flush size * 2，否则为MaxRegionFileSize。这种切分策略对于大集群中的大表、小表会比IncreasingToUpperBoundRegionSplitPolicy更加友好，小表不会再产生大量的小region，而是适可而止。SteppingSplitPolicy是IncreasingToUpperBoundRegionSplitPolicy的子类，其总共源码只有几行，如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SteppingSplitPolicy</span> <span class="keyword">extends</span> <span class="title class_">IncreasingToUpperBoundRegionSplitPolicy</span> &#123;</span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@return</span> flushSize * 2 if there&#x27;s exactly one region of the table in question</span></span><br><span class="line"><span class="comment">   * found on this regionserver. Otherwise max file size.</span></span><br><span class="line"><span class="comment">   * This allows a table to spread quickly across servers, while avoiding creating</span></span><br><span class="line"><span class="comment">   * too many regions.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">protected</span> <span class="type">long</span> <span class="title function_">getSizeToCheck</span><span class="params">(<span class="keyword">final</span> <span class="type">int</span> tableRegionsCount)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> tableRegionsCount == <span class="number">1</span>  ? <span class="built_in">this</span>.initialSize : getDesiredMaxFileSize();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="KeyPrefixRegionSplitPolicy"><a href="#KeyPrefixRegionSplitPolicy" class="headerlink" title="KeyPrefixRegionSplitPolicy"></a>KeyPrefixRegionSplitPolicy</h4><p>根据rowKey的前缀对数据进行分组，以便于将这些数据分到相同的Region中，这里是通过指定rowKey的前多少位作为前缀做为拆分控制参数，其参数控制为通过指定Table的描述参数KeyPrefixRegionSplitPolicy.prefix_length（旧版为prefix_split_key_policy.prefix_length）控制拆分前缀的长度，比如rowKey都是16位的，指定前5位是前缀，那么前5位相同的rowKey在进行region split的时候会分到相同的region中。</p><p>获取拆分点的实现源码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">protected</span> <span class="type">byte</span>[] getSplitPoint() &#123;</span><br><span class="line">    <span class="type">byte</span>[] splitPoint = <span class="built_in">super</span>.getSplitPoint();</span><br><span class="line">    <span class="keyword">if</span> (prefixLength &gt; <span class="number">0</span> &amp;&amp; splitPoint != <span class="literal">null</span> &amp;&amp; splitPoint.length &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="comment">// group split keys by a prefix</span></span><br><span class="line">      <span class="keyword">return</span> Arrays.copyOf(splitPoint,</span><br><span class="line">          Math.min(prefixLength, splitPoint.length));</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">return</span> splitPoint;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>另外，还有一些其他分裂策略，比如使用DisableSplitPolicy:可以禁止region发生分裂；而DelimitedKeyPrefixRegionSplitPolicy也是让相同的PrefixKey待在一个region中。与KeyPrefixRegionSplitPolicy不同的是，其是根据RowKey中指定分隔字符做为拆分的，显得更加灵活，如RowKey的值为“userid_eventtype_eventid”，且指定了分隔字符串为下划线”__”，则DelimitedKeyPrefixRegionSplitPolicy将取RowKey值中从左往右且第一个分隔字符串之前的字符做为拆分串。</p><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="https://www.codercto.com/a/26841.html">https://www.codercto.com/a/26841.html</a></p><p><a href="http://hbasefly.com/2017/08/27/hbase-split/">http://hbasefly.com/2017/08/27/hbase-split/</a></p>]]></content>
      
      
      <categories>
          
          <category> HBase </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HBase </tag>
            
            <tag> 数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HBase系列之compact</title>
      <link href="/article/hbase-compact.html"/>
      <url>/article/hbase-compact.html</url>
      
        <content type="html"><![CDATA[<p>在介绍HBase Compaction之前，我们先来看一下HBase是如何存储和操作数据。<br><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/hbase-compact/hbase-store.png" alt="HBase数据存储"></p><p>如上图所示，HRegionServer负责打开region，并创建对应的HRegion实例。当HRegion打开之后，它会为每个表的HColumnFamily创建一Store实例，ColumnFamily是用户在创建表时定义好的，ColumnFamily在每个region中和Store实例一一对应。每个Store实例包含一个或者多个StoreFile实例，StoreFile是对实际存储数据文件HFile的轻量级封装。每个Store对应一个MemStore（也就是写内存）。一个HRegionServer共享一个HLog实例。</p><p>当我们不停地往HBase中写入数据，也就是往MemStore写入数据，HBase会检查MemStore是否达到了需要刷写到磁盘的阈值（更多关于MemStore刷写的信息，可以参考HBase Reference Guide关于MemStore的介绍）。如果达到刷写的条件，MemStore中的记录就会被刷写到磁盘，形成一个新的StoreFile。可想而知，随着MemStore的不断刷写，会形成越来越多的磁盘文件。然而，对于HBase来说，当每个HStore仅包含一个文件时，才会达到最佳的读效率。因此HBase会通过合并已有的HFile来减少每次读数据的磁盘寻道时间，从而提高读速度，这个文件合并过程就称为Compaction。在这里需要说明的是，显然磁盘IO也是有代价的，如果使用不慎的话，不停地重写数据可能会导致网络和磁盘过载。换句话说，compaction其实就是用当前更高的磁盘IO来换取将来更低的磁盘寻道时间。因此，何时执行compaction，其实是一个相当复杂的决策。</p><p>Compaction会从一个region的一个store中选择一些hfile文件进行合并。合并说来原理很简单，先从这些待合并的数据文件中读出KeyValues，再按照由小到大排列后写入一个新的文件中。之后，这个新生成的文件就会取代之前待合并的所有文件对外提供服务。HBase的compaction分为minor和major两种，每次触发compact检查，系统会自动决定执行哪一种compaction（合并）。有三种情况会触发compact检查：</p><ul><li>MemStore被刷写到磁盘；</li><li>用户执行shell命令compact、major_compact或者调用了相应的API；</li><li>HBase后台线程周期性触发检查。</li></ul><p>除非是用户使用shell命令major_compact或者调用了majorCompact() API（这种情况会强制HBase执行major合并），在其他的触发情况下，HBase服务器会首先检查上次运行到现在是否达到一个指定的时限。如果没有达到这个时限，系统会选择执行minor合并，接着检查是否满足minor合并的条件。</p><p>major合并中会删除那些被标记为删除的数据、超过TTL（time-to-live）时限的数据，以及超过了版本数量限制的数据，将HStore中所有的HFile重写成一个HFile。如此多的工作量，理所当然地，major合并会耗费更多的资源，合并进行时也会影响HBase的响应时间。在HBase 0.96之前，默认每天对region做一次major compact，现在这个周期被改成了7天。然而，因为major compact可能导致某台server短时间内无法响应客户端的请求，如果无法容忍这种情况的话，可以关闭自动major compact，改成在请求低谷期手动触发这一操作。</p><p>Minor Compaction是指选取一些小的、相邻的StoreFile将他们合并成一个更大的StoreFile，在这个过程中不会处理已经Deleted或Expired的Cell。一次Minor Compaction的结果是更少并且更大的StoreFile。</p><span id="more"></span><h3 id="compaction流程"><a href="#compaction流程" class="headerlink" title="compaction流程"></a>compaction流程</h3><p>整个Compaction始于特定的触发条件，比如flush操作、周期性地Compaction检查操作等。一旦触发，HBase会将该Compaction交由一个独立的线程处理，该线程首先会从对应store中选择合适的hfile文件进行合并，这一步是整个Compaction的核心，选取文件需要遵循很多条件，比如文件数不能太多、不能太少、文件大小不能太大等等，最理想的情况是，选取那些承载IO负载重、文件小的文件集，实际实现中，HBase提供了多个文件选取算法：RatioBasedCompactionPolicy、ExploringCompactionPolicy和StripeCompactionPolicy等，用户也可以通过特定接口实现自己的Compaction算法；选出待合并的文件后，HBase会根据这些hfile文件总大小挑选对应的线程池处理，最后对这些文件执行具体的合并操作。可以通过下图简单地梳理上述流程：<br><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/hbase-compact/compact-flow.png"></p><h3 id="触发时机"><a href="#触发时机" class="headerlink" title="触发时机"></a>触发时机</h3><p>HBase中可以触发compaction的因素有很多，最常见的因素有这么三种：Memstore Flush、后台线程周期性检查、手动触发。</p><ul><li><p>Memstore Flush: 应该说compaction操作的源头就来自flush操作，memstore flush会产生HFile文件，文件越来越多就需要compact。因此在每次执行完Flush操作之后，都会对当前Store中的文件数进行判断，一旦文件数 &gt; hbase.store.compaction.min ，就会触发compaction。需要说明的是，compaction都是以Store为单位进行的，而在Flush触发条件下，整个Region的所有Store都会执行compact，所以会在短时间内执行多次compaction。</p></li><li><p>后台线程周期性检查：后台线程CompactionChecker定期触发检查是否需要执行compaction，检查周期为：hbase.server.thread.wakefrequency $\times$ hbase.server.compactchecker.interval.multiplier。和flush不同的是，该线程优先检查文件数是否大于hbase.store.compaction.min，一旦大于就会触发compaction。如果不满足，它会接着检查是否满足major compaction条件，简单来说，如果当前store中hfile的最早更新时间早于某个值mcTime，就会触发major compaction，HBase预想通过这种机制定期删除过期数据。上文mcTime是一个浮动值，浮动区间默认为［7-7$\times$0.2，7+7$\times$0.2］，其中7为hbase.hregion.majorcompaction，0.2为hbase.hregion.majorcompaction.jitter，可见默认在7天左右就会执行一次major compaction。用户如果想禁用major compaction，只需要将参数hbase.hregion.majorcompaction设为0。</p></li><li><p>手动触发：一般来讲，手动触发compaction通常是为了执行major compaction，原因有三，其一是因为很多业务担心自动major compaction影响读写性能，因此会选择低峰期手动触发；其二也有可能是用户在执行完alter操作之后希望立刻生效，执行手动触发major compaction；其三是HBase管理员发现硬盘容量不够的情况下手动触发major compaction删除大量过期数据；无论哪种触发动机，一旦手动触发，HBase会不做很多自动化检查，直接执行合并。</p></li></ul><h3 id="选择合适HFile合并"><a href="#选择合适HFile合并" class="headerlink" title="选择合适HFile合并"></a>选择合适HFile合并</h3><p>选择合适的文件进行合并是整个compaction的核心，因为合并文件的大小以及其当前承载的IO数直接决定了compaction的效果。最理想的情况是，这些文件承载了大量IO请求但是大小很小，这样compaction本身不会消耗太多IO，而且合并完成之后对读的性能会有显著提升。然而现实情况可能大部分都不会是这样，在0.96版本和0.98版本，分别提出了两种选择策略，在充分考虑整体情况的基础上选择最佳方案。无论哪种选择策略，都会首先对该Store中所有HFile进行一一排查，排除不满足条件的部分文件：</p><ul><li>排除当前正在执行compact的文件及其比这些文件更新的所有文件（SequenceId更大）</li><li>排除某些过大的单个文件，如果文件大小大于hbase.hzstore.compaction.max.size（默认Long最大值），则被排除，否则会产生大量IO消耗</li></ul><p>经过排除的文件称为候选文件，HBase接下来会再判断是否满足major compaction条件，如果满足，就会选择全部文件进行合并。判断条件有下面三条，只要满足其中一条就会执行major compaction：</p><ul><li>用户强制执行major compaction</li><li>长时间没有进行compact（CompactionChecker的判断条件2）且候选文件数小于hbase.hstore.compaction.max（默认10）</li><li>Store中含有Reference文件，Reference文件是split region产生的临时文件，只是简单的引用文件，一般必须在compact过程中删除</li></ul><p>如果不满足major compaction条件，就必然为minor compaction，HBase主要有两种minor策略：RatioBasedCompactionPolicy和ExploringCompactionPolicy，下面分别进行介绍：</p><h4 id="RatioBasedCompactionPolicy"><a href="#RatioBasedCompactionPolicy" class="headerlink" title="RatioBasedCompactionPolicy"></a>RatioBasedCompactionPolicy</h4><p>从老到新逐一扫描所有候选文件，满足其中条件之一便停止扫描：</p><p>（1）当前文件大小 &lt; 比它更新的所有文件大小总和 * ratio，其中ratio是一个可变的比例，在高峰期时ratio为1.2，非高峰期为5，也就是非高峰期允许compact更大的文件。那什么时候是高峰期，什么时候是非高峰期呢？用户可以配置参数hbase.offpeak.start.hour和hbase.offpeak.end.hour来设置高峰期。</p><p>（2）当前所剩候选文件数 &lt;&#x3D; hbase.store.compaction.min（默认为3）</p><p>停止扫描后，待合并文件就选择出来了，即为当前扫描文件+比它更新的所有文件</p><h4 id="ExploringCompactionPolicy"><a href="#ExploringCompactionPolicy" class="headerlink" title="ExploringCompactionPolicy"></a>ExploringCompactionPolicy</h4><p>该策略思路基本和RatioBasedCompactionPolicy相同，不同的是，Ratio策略在找到一个合适的文件集合之后就停止扫描了，而Exploring策略会记录下所有合适的文件集合，并在这些文件集合中寻找最优解。最优解可以理解为：待合并文件数最多或者待合并文件数相同的情况下文件大小较小，这样有利于减少compaction带来的IO消耗。Ratio策略是0.94版本的默认策略，而0.96版本之后默认策略就换为了Exploring策略。在<a href="https://blog.cloudera.com/blog/2013/12/what-are-hbase-compactions/">clouder文章</a>中，作者进行了对比，Ratio策略在节省IO方面会有10%左右的提升。<br><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/hbase-compact/exploring.png"></p><h3 id="挑选合适的线程池"><a href="#挑选合适的线程池" class="headerlink" title="挑选合适的线程池"></a>挑选合适的线程池</h3><p>HBase实现中有一个专门的线程CompactSplitThead负责接收compact请求以及split请求，而且为了能够独立处理这些请求，这个线程内部构造了多个线程池：largeCompactions、smallCompactions以及splits等，其中splits线程池负责处理所有的split请求，largeCompactions和smallCompaction负责处理所有的compaction请求，其中前者用来处理大规模compaction，后者处理小规模compaction。这里需要明白三点：</p><ol><li><p>上述设计目的是为了能够将请求独立处理，提供系统的处理性能。</p></li><li><p>哪些compaction应该分配给largeCompactions处理，哪些应该分配给smallCompactions处理？是不是Major Compaction就应该交给largeCompactions线程池处理？不对。这里有个分配原则：待compact的文件总大小如果大于值throttlePoint（可以通过参数hbase.regionserver.thread.compaction.throttle配置，默认为2.5G），分配给largeCompactions处理，否则分配给smallCompactions处理。</p></li><li><p>largeCompactions线程池和smallCompactions线程池默认都只有一个线程，用户可以通过参数hbase.regionserver.thread.compaction.large和hbase.regionserver.thread.compaction.small进行配置。</p></li></ol><h3 id="执行HFile文件合并"><a href="#执行HFile文件合并" class="headerlink" title="执行HFile文件合并"></a>执行HFile文件合并</h3><p>上文一方面选出了待合并的HFile集合，一方面也选出来了合适的处理线程，万事俱备，只欠最后真正的合并。合并流程说起来也简单，主要分为如下几步：</p><ol><li><p>分别读出待合并hfile文件的KV，并顺序写到位于.&#x2F;tmp目录下的临时文件中</p></li><li><p>将临时文件移动到对应region的数据目录</p></li><li><p>将compaction的输入文件路径和输出文件路径封装为KV写入WAL日志，并打上compaction标记，最后强制执行sync</p></li><li><p>将对应region数据目录下的compaction输入文件全部删除</p></li></ol><p>上述四个步骤看起来简单，但实际是很严谨的，具有很强的容错性和完美的幂等性：</p><ol><li><p>如果RS在步骤2之前发生异常，本次compaction会被认为失败，如果继续进行同样的compaction，上次异常对接下来的compaction不会有任何影响，也不会对读写有任何影响，唯一的影响就是多了一份多余的数据。</p></li><li><p>如果RS在步骤2之后、步骤3之前发生异常，同样的，仅仅会多一份冗余数据。</p></li><li><p>如果在步骤3之后、步骤4之前发生异常，RS在重新打开region之后首先会从WAL中看到标有compaction的日志，因为此时输入文件和输出文件已经持久化到HDFS，因此只需要根据WAL移除掉compaction输入文件即可。</p></li></ol><h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p><a href="https://blog.cloudera.com/blog/2013/12/what-are-hbase-compactions/">https://blog.cloudera.com/blog/2013/12/what-are-hbase-compactions/</a></p><p><a href="http://hbasefly.com/2016/07/13/hbase-compaction-1/">http://hbasefly.com/2016/07/13/hbase-compaction-1/</a></p><p><a href="http://www.cnblogs.com/yurunmiao/p/3520066.html">http://www.cnblogs.com/yurunmiao/p/3520066.html</a></p>]]></content>
      
      
      <categories>
          
          <category> HBase </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HBase </tag>
            
            <tag> 数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>八大基础分析模型</title>
      <link href="/article/data-model.html"/>
      <url>/article/data-model.html</url>
      
        <content type="html"><![CDATA[<p>模型是指对于某个实际问题或客观事物、规律进行抽象后的一种形式化表达方式。任何模型都有三个部分组成：目标、变量和关系。<br>通俗来讲：</p><ul><li>目标：这个模型是干嘛用的，要解决什么问题。</li><li>变量：自变量、因变量、中介变量，总之就是，明确变量，改变变量，即可直接呈现结果，实现目标。</li><li>关系：可以理解为对目标和变量进行组织。<br>下面介绍常用的八种基础分析模型，可能大家也都了解。而且这些模型，其实也在不断的优化，并且又有了一些新特性，比如用户分群模型中的“新增后”、事件模型中的“活跃比”</li></ul><h3 id="用户模型"><a href="#用户模型" class="headerlink" title="用户模型"></a>用户模型</h3><p>“用户”是以人为中心的数据分析平台的最小单元，对单个用户画像构建越完整，数据多维交叉的分析能力才能凸显。</p><h3 id="事件模型"><a href="#事件模型" class="headerlink" title="事件模型"></a>事件模型</h3><p>用户在产品上的行为（所有代码的交互）都是会被记录的，怎样标记是事件模型的核心，它是漏斗模型，自定义留存模型，全行为路径分析模型的数据源。</p><p><em><strong>活跃比：某一时间区间内触发某事件的人数占该时间区间内活跃人数的百分比。</strong></em></p><span id="more"></span><h3 id="漏斗分析模型"><a href="#漏斗分析模型" class="headerlink" title="漏斗分析模型"></a>漏斗分析模型</h3><p>漏斗是常用也是最经典的分析模型，在行为数据的漏斗分析中，通常我们以每一步触发的人数为统计口径。漏斗中另一个重要的限定因素是：转化时间的限定。当设定转化时间是一天内，用户只要在一天内先后完成所有事件就是一个成功转化，未触发或是超过时间限定都不会记为一个成功转化。</p><h3 id="热图分析模型"><a href="#热图分析模型" class="headerlink" title="热图分析模型"></a>热图分析模型</h3><p>热图的目标是能更直观的分析用户在页面上的焦点，不需要定义事件，不需要去对比事件，直接在页面上通过颜色深浅还原用户的聚焦位置并形成对比。<br>过去：分析全量人群的热力表现。<br>现在：分析特定人群，群组之间进行对比。</p><h3 id="自定义留存分析模型"><a href="#自定义留存分析模型" class="headerlink" title="自定义留存分析模型"></a>自定义留存分析模型</h3><p>留存被认为是比较高级的一个指标。无论用户在应用内做了什么，只要打开了应用就是一个留存用户，但不同产品对留存有不同的定义。比如，阅读类产品会把至少看过一篇文章的用户定义为有效留存用户，电商类产品会把至少看过一次“商品详情”的用户定义为有效留存用户，所以有了自定义留存。</p><h3 id="粘性分析模型"><a href="#粘性分析模型" class="headerlink" title="粘性分析模型"></a>粘性分析模型</h3><p>计算一段时间内，以周，月为单位看用户不同的访问天数所占的百分比。</p><h3 id="全行为路径分析模型"><a href="#全行为路径分析模型" class="headerlink" title="全行为路径分析模型"></a>全行为路径分析模型</h3><p>用户在产品中的行为其实是个黑盒子，全行为路径是用全局视野看用户的行为轨迹，很多时候你会有意想不到的收获，在可视化的过程中有两个模型，一个是树形图、一个是太阳图。</p><h3 id="用户分群模型"><a href="#用户分群模型" class="headerlink" title="用户分群模型"></a>用户分群模型</h3><p>用户分群其实是最常做的，但是如何把群组划分这一操作变得更便捷和高效，可以进一步优化了这一模型，也足以满足很多场景下的用户分群需求：</p><ul><li>维度：新增于、活跃于、触发过什么行为、用户属性满足什么条件；在基于行为事件筛选人群的时候有一个新的维度，叫：新增后。</li><li>时间：绝对时间和相对时间</li><li>关系：并且、或者</li></ul><p><strong>新增后： 计算用户触发某行为的时间和用户新增的时间，然后定义为“新增后”，比如，你可以快速找到新增后 1 天内就付款、新增后 30 天才付款的用户，背后其实是对用户价值的快速衡量；还可以基于此条件，不断去分群，比如用户完成一次购买是发生在新增后的 7 天，30 天，还是一个月，快速找到用户购买的决策周期。</strong></p>]]></content>
      
      
      <categories>
          
          <category> 数据分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据 </tag>
            
            <tag> 模型 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>传统的MapReduce框架慢在哪里</title>
      <link href="/article/why-MR-slow.html"/>
      <url>/article/why-MR-slow.html</url>
      
        <content type="html"><![CDATA[<p>本文转载于<a href="http://jerryshao.me/2013/04/15/%E4%BC%A0%E7%BB%9F%E7%9A%84MapReduce%E6%A1%86%E6%9E%B6%E6%85%A2%E5%9C%A8%E5%93%AA%E9%87%8C/">传统的MapReduce框架慢在那里</a>,翻译自<a href="http://shark.cs.berkeley.edu/">Shark: SQL and Rich Analytics at Scale</a>的论文第七章节，从理论上讨论了相比于Hive，Shark的优势在哪里，原文可见<a href="http://www.eecs.berkeley.edu/Pubs/TechRpts/2012/EECS-2012-214.pdf">http://www.eecs.berkeley.edu/Pubs/TechRpts/2012/EECS-2012-214.pdf</a>.</p><h3 id="为什么之前的MapReduce系统比较慢"><a href="#为什么之前的MapReduce系统比较慢" class="headerlink" title="为什么之前的MapReduce系统比较慢"></a>为什么之前的MapReduce系统比较慢</h3><p>常理上有几个理由使得MapReduce框架慢于MPP数据库：</p><ul><li>容错所引入的昂贵数据实体化 <font color=red size=2>(data materialization)</font>开销。</li><li>孱弱的数据布局 <font color=red size=2>(data layout)</font>，比如缺少索引。</li><li>执行策略的开销<font color=blue size=2>[1 2]</font>。</li></ul><p>而我们对于Hive的实验也进一步证明了上述的理由，但是通过对Hive“工程上”的改进，如改变存储引擎(内存存储引擎)、改善执行架构(partial DAG execution)能够缩小此种差距。同时我们也发现一些MapReduce实现的细节会对性能有巨大的影响，如任务调度的开销，如果减小调度开销将极大地提高负载的均衡性。</p><p><font color=blue size=4>中间结果输出</font>：类似于Hive这样的基于MapReduce的查询引擎，往往会将中间结果实体化 <font color=red size=2>(materialize)</font>到磁盘上：</p><ul><li>在MapReduce任务内部，为了防止Reduce任务的失败，Map通常会把结果存储在磁盘上。</li><li>通常一些查询在翻译到MapReduce任务的时候，往往会产生多个stage，而这些串联的stage则又依赖于底层文件系统(如HDFS)来存储每一个stage的输出结果。</li></ul><p>对于第一种情况，Map的输出结果存储在磁盘上是为了确保能够有足够的空间来存储这些大数据批量任务的输出。而Map的输出并不会复制到不同的节点上去，因此如果执行Map任务的节点失效的话仍会造成数据丢失[3]。由此可以推出，如果将这部分输出数据缓存在内存中，而不是全部输出到磁盘上面也是合理的。Shark Shuffle的实现正是应用了此推论，将Map的输出结果存储在内存中，极大地提高Shuffle的吞吐量。通常对于聚合 <font color=red size=2>(aggregation)</font>和过滤之类的查询，它们的输出结果往往远小于输入，这种设计是非常合理的。而SSD的流行，也会极大地提高随机读取的性能，对于大数据量的Shuffle，能够获得较大的吞吐量，同时也拥有比内存更大的空间。</p><span id="more"></span><p>对于第二种情况，一些执行引擎扩展了MapReduce的执行模型，将MapReduce的执行模型泛化成更为通用的执行计划图 <font color=red size=2>(task DAG)</font>，可以将多stage的任务串联执行而无需将stage中间结果输出到HDFS中去，这些引擎包括Dryad[4], Tenzing[5]和Spark[6]。</p><p><font color=blue size=4>数据格式和布局</font><font color=red size=3>(layout)</font>： 由于MapReduce单纯的Schema-on-read的处理方式会引起较大的处理开销，许多系统在MapReduce模型内部设计和使用了更高效的存储结构来加速查询。Hive本身支持“分区表<font color=red size=2>(table partitions)</font>”（一种基本的类索引系统，它将特定的键段存储在特定的文件中，可以避免对于整个表的扫描），类似于磁盘数据的列式存储结构[7]。在Shark中我们更进一步地采用了基于内存的列式存储结构，Shark在实现此结构时并没有修改Spark的代码，而是简单地将一组列式元组存储为Spark内的一条记录，而对于列式元组内的结构则有Shark负责解析。</p><p>另一个Spark独有的特性是能够控制数据在不同节点上的分区，这为Shark带来了一种新的功能：对表进行联合分区<font color=red size=2>(co-partition)</font>。</p><p>最后，对于RDD我们还未挖掘其随机读取的能力，虽然对于写入操作，RDD只能支持粗粒度的操作，但对于读取操作，RDD可以精确到每一条记录[6]，这使得RDD可以用来作为索引, Tenzing 可以用此来作为join操作的远程查询表<font color=red size=2>(remote-lookup)</font>。</p><p><font color=blue size=4>执行策略</font>： Hive在数据Shuffle之前花费了大量的时间用来排序，同时将MapReduce结果输出到HDFS上面也占用了大量的时间，这些都是由于Hadoop自身基本的，单次迭代的MapReduce模型所限制的。对于Spark这样的更通用的执行引擎，则可减轻上述问题带来的开销。举例来说，Spark支持基于Hash的分布式聚合和更为通用任务执行计划图<font color=red size=2>(DAG)</font>。</p><p>事实上，为了能够真正优化关系型查询的执行，我们发现在基于数据统计的基础上来选择执行计划是非常有必要的。但是由于UDF和复杂分析函数的存在，而Shark又将其视为一等公民<font color=red size=2>(first-class citizens)</font>，这种统计将变得十分困难。为了能够解决这个问题，我们提出了partial DAG execution (PDE)，这使得Spark能够在基于数据统计的基础上改变后续执行计划图，PDE与其他系统(DryadLINQ)的运行时执行计划图重写的不同在于：它能够收集键值范围内的细粒度统计数据；能够完全重新选择join的执行策略，如broadcast join，而不仅仅是选择Reduce任务的个数。</p><p><font color=blue size=4>任务调度的开销</font>： 大概在诸多影响Shark的部分中，最令人感到意外的却只是一个纯粹工程上的问题：运行任务带来的开销。传统的MapReduce系统，就比如Hadoop，是为了运行长达数小时的批量作业而设计的，而组成作业的每个任务其运行时间则有数分钟之久，他们会在独立的系统进程中执行任务，在某些极端情况下提交一个任务的延迟非常之高。拿Hadoop打比方，它使用周期性的“心跳”消息来向工作节点分配任务，而这个周期是3秒钟，因此总共的任务启动延时就会高达5-10秒。这对于批处理的系统显然是可以忍受的，但是对于实时查询这显然是不够的。</p><p>为了避免上述问题，Spark采用了事件驱动的RPC类库来启动任务，通过复用工作进程来避免系统进程开销。它能够在一秒钟内启动上千个任务，任务之间的延时小于5毫秒，从而使得50-100毫秒的任务，500毫秒的作业变得可能。而这种改进对于查询性能的提升，甚至对于较长执行时间的查询性能的提升也令我们感到吃惊不已。</p><p>亚秒级的任务使得引擎能够更好地在工作节点之间平衡任务的分配，甚至在某些节点遇到了不可预知的延迟(网络延迟或是JVM垃圾回收)的情况下面也能较好地平衡。同时对于数据倾斜也有巨大的帮助，考虑到在100个核上做哈希聚合<font color=red size=2>(hash aggregation)</font>，对于每一个任务所处理的键范围需要精心选定，任何的数据倾斜的部分都会拖慢整个作业。但是如果将作业分发到1000个核上面，那么最慢的任务只会比平均任务慢10倍，这就大大提高了可接受程度。而当我们在PDE中应用倾斜感知的选择策略后，令我们感到失望的是相比于增大Reduce任务个数带来的提升，这种策略所带来的提升却比较小。但不可否认的是，引擎对于异常数据倾斜有了更高的稳定性。</p><p>在Hadoop&#x2F;Hive中，错误的选择任务数量往往会比优化好的执行策略慢上10倍，因此有大量的工作集中在如何自动的选择Reduce任务的数量[8 9]，下图可以看到Hadoop&#x2F;Hive和Spark Reduce任务数量对于作业执行时间的影响。因为Spark作业能够以较小的开销运行数千个Reduce任务，数据倾斜的影响可以通过运行较多任务来减小。<br><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/why-MR-slow/tasks.png"></p><p>事实上，对于更大规模集群(数万个节点)上亚秒级任务的可行性我们还未探究。但是对于Dremel[10]这样的周期性地在数千个节点上运行亚秒级作业的系统，实际情况下当单个主节点无法满足任务调度的速度时，调度策略可以将任务委派给子集群的“副”主节点。同时细粒度的任务执行策略相比于粗粒度的设计不仅仅带来了负载均衡的好处，而且还包括快速恢复 <font color=red size=2>(fast recovery)</font>(通过将失败任务分发到更多的节点上去)、查询的弹性 <font color=red size=2>(query elasticity)</font>。</p><h3 id="细粒度任务模型-Fine-Grained-Task-Modle-带来的其他好处"><a href="#细粒度任务模型-Fine-Grained-Task-Modle-带来的其他好处" class="headerlink" title="细粒度任务模型 (Fine-Grained Task Modle) 带来的其他好处"></a>细粒度任务模型 <font color=red size=4>(Fine-Grained Task Modle)</font> 带来的其他好处</h3><p>虽然这篇文章主要关注的是细粒度任务模型带来的容错性优势，这个模型同样也提供了许多诱人的特性，接下将会介绍在MapReduce系统中已被证明的两个特性。</p><p>伸缩性 <font color=red size=2>(Elasticity)</font>： 在传统的MPP数据库中，一旦分布式执行计划被选中，系统就必须以此并行度执行整一个的查询。但是在细粒度任务系统中，在执行查询的过程中节点可以增删节点，系统会自动地把阻塞的作业分发到其他节点上去，这使得整个系统变得非常具有伸缩性。如果数据库管理者需要在这个系统中移除某些节点，系统可以简单地将这些节点视为失效节点，或者更好的处理方法是将这些节点上的数据复制到其他节点上去。与删除节点相对应的是，当执行查询变得更慢时，数据库系统可以动态地申请更多的资源来提升计算能力。亚马逊的Elastic MapReduce[11]已经支持运行时调整集群规模。</p><p>多租户架构 <font color=red size=2>(Multitenancy)</font>: 多租户架构如同上面提到伸缩性一样，目的是为了在不同用户之间动态地共享资源。在传统的MPP数据库中，当一个重要的查询提交的时候已经有一个较大的查询占据了大多数的集群资源，这时能做的选择不外乎就是取消先前的查询等有限的操作。而在基于细粒度任务模型的系统中，查询作业可以等待几秒到当前作业完成，然后提交新的查询作业。Facebook和Microsoft已经为Hadoop和Dryad开发了公平调度器，使得大型的、计算密集型的历史记录查询与实时的小型查询可以共享集群资源而不会产生饥饿现象[12 13]。</p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>[1] <a href="http://www.cse.nd.edu/~dthain/courses/cse598z/spring2010/benchmarks-sigmod09.pdf">“A. Pavlo et al. A comparison of approaches to large-scale data analysis. In SIGMOD, 2009.”</a></p><p>[2] <a href="http://cs.brown.edu/~pavlo/presentations/mapreduce-pavlo09.pdf">“M. Stonebraker et al. Mapreduce and parallel dbmss: friends or foes? Commun. ACM.”</a></p><p>[3] <a href="http://www.eecs.berkeley.edu/Pubs/TechRpts/2012/EECS-2012-214.pdf">http://www.eecs.berkeley.edu/Pubs/TechRpts/2012/EECS-2012-214.pdf.</a></p><p>[4] <a href="https://www.cs.cmu.edu/afs/cs.cmu.edu/Web/People/15712/papers/isard07.pdf">“M. Isard et al. Dryad: distributed data-parallel programs from sequential building blocks. SIGOPS, 2007.”</a></p><p>[5] <a href="http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/zh-CN//pubs/archive/37200.pdf">“B. Chattopadhyay, , et al. Tenzing a sql implementation on the mapreduce framework. PVLDB, 4(12):1318–1327, 2011.”</a></p><p>[6] <a href="http://www.cs.berkeley.edu/~matei/papers/2011/tr_spark.pdf">“M. Zaharia et al. Resilient distributed datasets: a fault-tolerant abstraction for in-memory cluster computing. NSDI, 2012.”</a></p><p>[7] <a href="http://www.facebook.com/note.php?note_id=89508453919">“A. Thusoo et al. Hive-a petabyte scale data warehouse using hadoop. In ICDE, 2010.”</a></p><p>[8] <a href="http://nuage.cs.washington.edu/pubs/sigmod2012-kwon-correct.pdf">“Y. Kwon et al. Skewtune: mitigating skew in mapreduce applications. In SIGMOD ’12, 2012.”</a></p><p>[9] <a href="http://www-db.in.tum.de/research/publications/conferences/closer2011-100.pdf">“B. Guffler et al. Handling data skew in mapreduce. In CLOSER, 2011.”</a></p><p>[10] <a href="http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/zh-CN//pubs/archive/36632.pdf">“S. Melnik et al. Dremel: interactive analysis of web-scale datasets. Proc. VLDB Endow., 3:330–339, Sept 2010.”</a></p><p>[11] <a href="http://aws.amazon.com/about-aws/whats-new/2010/10/20/amazon-elastic-mapreduce-introduces-resizing-running-job-flows">http://aws.amazon.com/about-aws/whats-new/2010/10/20/amazon-elastic-mapreduce-introduces-resizing-running-job-flows.</a></p><p>[12] <a href="http://www.cs.berkeley.edu/~matei/papers/2010/eurosys_delay_scheduling.pdf">“M. Zaharia et al. Delay scheduling: A simple technique for achieving locality and fairness in cluster scheduling. In EuroSys 10, 2010.”</a></p><p>[13] <a href="http://www.sigops.org/sosp/sosp09/papers/isard-sosp09.pdf">“M. Isard et al. Quincy: Fair scheduling for distributed computing clusters. In SOSP ’09, 2009.”</a></p>]]></content>
      
      
      <categories>
          
          <category> 数据工程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MapReduce </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Performance optimizations in Apache Impala</title>
      <link href="/article/impala-3-0.html"/>
      <url>/article/impala-3-0.html</url>
      
        <content type="html"><![CDATA[<h3 id="历史和动机"><a href="#历史和动机" class="headerlink" title="历史和动机"></a>历史和动机</h3><h4 id="SQL-on-Apache-Hadoop"><a href="#SQL-on-Apache-Hadoop" class="headerlink" title="SQL on Apache Hadoop"></a>SQL on Apache Hadoop</h4><ul><li>SQL</li><li>Run on top of HDFS</li><li>Supported various file formats</li><li>Converted query operators to map-reduce jobs</li><li>Run at scale</li><li>Fault-tolerant</li><li>High startup-costs&#x2F;materialization overhead (slow…)</li></ul><h3 id="impala-performance-optimizations"><a href="#impala-performance-optimizations" class="headerlink" title="impala performance optimizations"></a>impala performance optimizations</h3><h4 id="query-planning"><a href="#query-planning" class="headerlink" title="query planning"></a>query planning</h4><p>2-phase cost-based optimizer</p><ul><li>Phase 1: Generate a single node plan (transformations, join ordering, static partition pruning, runtime filters)</li><li>Phase 2: Convert the single node plan into a distributed query execution plan (add exchange nodes, decide join strategy)<br>Query fragments (units of work):</li><li>Parts of query execution tree</li><li>Each fragment is executed in one or more impalads</li></ul><span id="more"></span><h4 id="metadata-amp-statistics"><a href="#metadata-amp-statistics" class="headerlink" title="metadata &amp; statistics"></a>metadata &amp; statistics</h4><p>Metadata<br>• Table metadata (HMS) and block level (HDFS) information are cached to speed-up query time<br>• Cached data is stored in FlatBuffers to save space and avoid excessive GC<br>• Metadata loading from HDFS&#x2F;S3&#x2F;ADLS uses a thread pool to speedup the operation when needed<br>Statistics<br>• Impala uses an HLL to compute Number of distinct values (NDV)<br>• HLL is much faster than the combination of COUNT and DISTINCT, and uses a constant amount of memory and thus is less memory-intensive for columns with high cardinality.<br>• HLL size is 1KB per column<br>• A Novel implementation of sampled stats is coming soon</p><h4 id="Query-optimizations-based-on-statistics"><a href="#Query-optimizations-based-on-statistics" class="headerlink" title="Query optimizations based on statistics"></a>Query optimizations based on statistics</h4>]]></content>
      
      
      <categories>
          
          <category> 数据工程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> impala </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据存储系统性能优化思维导图</title>
      <link href="/article/database-optimize.html"/>
      <url>/article/database-optimize.html</url>
      
        <content type="html"><![CDATA[<p>当前计算机硬件的基本性能指标及其在数据库中主要操作内容，可以整理出如下图所示的性能基本优化法则：</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/database-optimize/optimize.png"></p><p>这个优化法则归纳为5个层次：</p><p>1、  减少数据访问（减少磁盘访问）</p><p>2、  返回更少数据（减少网络传输或磁盘访问）</p><p>3、  减少交互次数（减少网络传输）</p><p>4、  减少服务器CPU开销（减少CPU及内存开销）</p><p>5、  利用更多资源（增加资源）</p><p>由于每一层优化法则都是解决其对应硬件的性能问题，所以带来的性能提升比例也不一样。传统数据库系统设计是也是尽可能对低速设备提供优化方法，因此针对低速设备问题的可优化手段也更多，优化成本也更低。我们任何一个SQL的性能优化都应该按这个规则由上到下来诊断问题并提出解决方案，而不应该首先想到的是增加资源解决问题。</p><span id="more"></span><p>以下是每个优化法则层级对应优化效果及成本经验参考：</p><table><thead><tr><th>优化法则</th><th>性能提升效果</th><th>优化成本</th></tr></thead><tbody><tr><td>减少数据访问</td><td>1~1000</td><td>低</td></tr><tr><td>返回更少数据</td><td>1~100</td><td>低</td></tr><tr><td>减少交互次数</td><td>1~20</td><td>低</td></tr><tr><td>减少服务器CPU开销</td><td>1~5</td><td>低</td></tr><tr><td>利用更多资源</td><td>@~10</td><td>高</td></tr></tbody></table><p>以上是数据库优化方法思路。同样，在大数据系统也适用。下面通过思维导图方式，例举在大数据领域或者数据库领域存储查询所用到的各种优化方法。</p><p><a href="https://aonaotu.com/open/5b74177afc241000140e066e">性能优化思维导图</a></p>]]></content>
      
      
      <categories>
          
          <category> 数据工程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 存储 </tag>
            
            <tag> 优化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OLAP引擎思维导图</title>
      <link href="/article/olap.html"/>
      <url>/article/olap.html</url>
      
        <content type="html"><![CDATA[<h3 id="联机分析处理-OLAP"><a href="#联机分析处理-OLAP" class="headerlink" title="联机分析处理(OLAP)"></a>联机分析处理(OLAP)</h3><p><a href="https://zh.wikipedia.org/wiki/%E7%B7%9A%E4%B8%8A%E5%88%86%E6%9E%90%E8%99%95%E7%90%86">联机分析处理</a>（英语：On-Line Analytical Processing，简称OLAP），是一套以多维度方式分析数据，而能弹性地提供上卷（Roll-up）、下钻（Drill-down）、和透视分析（pivot）等操作，呈现集成性决策信息的方法，多用于决策支持系统、商务智能或数据仓库。其主要的功能，在于方便大规模数据分析及统计计算，对决策提供参考和支持。<br>OLA数据库的设计目的是为了提高检索数据的速度。<br>OLAP数据库包含两种基本类型的数据：度量值和维度。前者是数值数据，表示您用于做出明智的商业决策的数量和平均值；后者是用于组织这些度量值的类别。OLAP 数据库可帮助您按照多个明细级别组织数据，从而可以使用您熟悉的相同类别来分析数据。</p><h3 id="各类OLAP引擎"><a href="#各类OLAP引擎" class="headerlink" title="各类OLAP引擎"></a>各类OLAP引擎</h3><p>针对OLAP查询，出现了各类的引擎，主要以ROLAP与MOLAP为主，MOLAP将需要查询分析的维度数据预先计算好，来实现高速的查询要求。<br>下面例举常见的OLAP引擎以及优缺点，实现技术细节等。<br><a href="https://aonaotu.com/open/5b59d72768d26d00146de49c">OLAP引擎思维导图</a></p>]]></content>
      
      
      <categories>
          
          <category> 数据工程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> OLAP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>bitmap与标签存储</title>
      <link href="/article/bitmap.html"/>
      <url>/article/bitmap.html</url>
      
        <content type="html"><![CDATA[<p>最近在标签存储中，需要根据标签值查询用户id，所以想到在源数据表基础上建立索引。因为标签数据量大，且标签基数相对较少，查询条件往往涉及多标签组合过滤，所以选用了bitmap作为索引。</p><h3 id="bitmap简介"><a href="#bitmap简介" class="headerlink" title="bitmap简介"></a>bitmap简介</h3><p>bitmap就是以比特位来存储状态。<br><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/bitmap/bitmap.png" alt="bitmap"></p><h3 id="bitmap索引"><a href="#bitmap索引" class="headerlink" title="bitmap索引"></a>bitmap索引</h3><p>例如用户数据表<br><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/bitmap/user_table.png"><br>现在要在用户性别和婚姻状态建立bitmap索引。<br><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/bitmap/user_index.png"><br>通过索引值为1，我们可以看出性别男的用户rowid为1和3，然后在查询源用户表，就可以查出性别男的是张三，王五。婚姻状况同理。<br>下面我们如果要查询：<br>select * from table where Gender&#x3D;’男’ and Marital&#x3D;’未婚’<br>首先我们找到男索引列和未婚索引列，然后对其取并集。<br><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/bitmap/intersection.png"></p><span id="more"></span><p>因为是bit存储，索引取并集就相当简单，只需要进行位运算&amp;即可。所以整个bitmap索引多条件过滤效率很高。</p><h3 id="bitmap的适用范围"><a href="#bitmap的适用范围" class="headerlink" title="bitmap的适用范围"></a>bitmap的适用范围</h3><p>因为bitmap的特性，所以bitmap索引适用于：</p><ul><li>查询为主，更新较少的数据</li><li>基数较少，重复度较多的列</li><li>and&#x2F;or可以直接通过位运算快速得到结果。</li></ul><h3 id="RoaringBitmap"><a href="#RoaringBitmap" class="headerlink" title="RoaringBitmap"></a>RoaringBitmap</h3><p>未压缩的bitmap占有空间大，所以提出了各种的压缩算法。如图：<br><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/bitmap/compress.png"><br>从图中可知，RoaringBitmap是基于Sorted array进行压缩。而其他压缩算法都是基于aligned或者run-length-encoded，核心思想都是把数据规整，然后采用run-length编码。</p><p>截取<a href="https://github.com/RoaringBitmap/RoaringBitmap">RoaringBitmap中的话</a></p><blockquote><p>Most alternatives to Roaring are part of a larger family of compressed bitmaps that are run-length-encoded bitmaps. They identify long runs of 1s or 0s and they represent them with a marker word. If you have a local mix of 1s and 0, you use an uncompressed word.</p></blockquote><blockquote><p>There are many formats in this family:</p></blockquote><blockquote><ul><li>Oracle’s BBC is an obsolete format at this point: though it may provide good compression, it is likely much slower than more recent alternatives due to excessive branching.</li></ul></blockquote><ul><li>WAH is a patented variation on BBC that provides better performance.</li><li>Concise is a variation on the patented WAH. It some specific instances, it can compress much better than WAH (up to 2x better), but it is generally slower.</li><li>EWAH is both free of patent, and it is faster than all the above. On the downside, it does not compress quite as well. It is faster because it allows some form of “skipping” over uncompressed words. So though none of these formats are great at random access, EWAH is better than the alternatives.</li></ul><blockquote><p>There is a big problem with these formats however that can hurt you badly in some cases: there is no random access. If you want to check whether a given value is present in the set, you have to start from the beginning and “uncompress” the whole thing. This means that if you want to intersect a big set with a large set, you still have to uncompress the whole big set in the worst case…</p></blockquote><p>从中可知，BBC、WAH、Concise、EWAH都是基于run-length-encoded算法，它们很难处理随机读，而且如果想要对两个bitmap取交集，必须解压整个大集合。<br>基于这些问题，RoaringBitmap提出了另一种压缩方法。</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/bitmap/roaringbitmap.png" alt="RoaringBitmap"></p><p>图中展示了RoaringBitmap的结构，每个RoaringBitmap中都包含一个RoaringArray，名字叫highLowContainer。<br>highLowContainer存储了RoaringBitmap中的全部数据。</p><p><code>RoaringArray highLowContainer;</code><br><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/bitmap/roaringArray.png"><br>具体的讲解可以参照<a href="https://blog.csdn.net/yizishou/article/details/78342499">RoaringBitmap数据结构及原理</a>这篇文章。<br>RoaringBitmap在设计中结合了Array与Bitmap存储，当数据稀疏时，Array存储会更节省空间（试想[3,10000,200000]这三个数如果用bitmap存储会消耗空间远大于直接存储这三个的数组），当数据稠密时，bitmap存储节省空间。而且还提供了RunContainer利用run-length-encoded算法进行压缩（只有在调用runOptimize()方法才会发生转换，会分别和ArrayContainer、BitmapContainer比较空间占用大小，然后选择是否转换）。</p><h3 id="标签"><a href="#标签" class="headerlink" title="标签"></a>标签</h3><p>基于用户的行为，对用户的特征进行抽象，使用标签来反映用户的动作与特征。在用户画像中，常常需要根据用户标签去对用户做特定的运营或者活动。</p><p>在存储上，考虑到用户标签的不同，如果将所以标签类别作为一张宽表（类似星型模型），将会是个很稀疏的表，且随时面临着标签的增长，所以在存储上选择了Hbase。</p><p>而通过某些标签筛选出特定用户是个很常见的需求。而Hbase查询如果不是通过rowkey查询的化，都是scan全表，效率很低。而标签相对于用户数量而言基数较少，且常有根据多个标签组合查询（and或者or），所以想到了将标签使用bitmap索引存储。</p><p>所以在标签数据组织上，有个正排的标签表，用户id作为rowkey,主要方便查询用户的标签值。一个标签对应的bitmap索引表，用于通过标签组合过滤查询用户。</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/bitmap/tag-bitmap.png"></p><p>将tag表中的用户-标签数据，首先通过hash(uid)做分区，在对同一tag的数据做bitmap index（红色方框）。不同的partition数据分布于hbase的region中。在查询的时候通过协处理器并行查询各个region，最后将数据返回给client。其中进行partition主要是为了：有些标签所覆盖的用户很广，甚至上千万或者上亿，整个bitmap占用的空间会很大，对index构建和查询带来效率问题；划分region后，通过hbase的协处理器可以并发的查询，每个region返回的bitmap也更小，效率更高。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>bitmap提供了不一样的数据存储，以及高效的运算，成为了某些场景下的利刃。比如在标签存储中，可以很好的使用bitmap对标签组合查询用户。但bitmap并非银弹，如果是基数较高或者更新频繁的系统中，似乎并不是很好的方案。但bitmap给予我们提供了一种不同的视角，散列却又聚集。</p>]]></content>
      
      
      <categories>
          
          <category> 数据工程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> bitmap </tag>
            
            <tag> 标签 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>磁盘I/O</title>
      <link href="/article/disk-io.html"/>
      <url>/article/disk-io.html</url>
      
        <content type="html"><![CDATA[<p>最近一直在看HBase底层存储，想更深入的理解HBase采用LSM结构，而不是B-tree的缘由，所以需要更深入的理解磁盘存储。<br>本文转载于<a href="https://tech.meituan.com/about-desk-io.html">磁盘I&#x2F;O那些事</a>，该文详细讲解了磁盘结构，磁盘如何存储数据，如果读取数据，以及磁盘读写的IO过程。</p><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>计算机硬件性能在过去十年间的发展普遍遵循摩尔定律，通用计算机的CPU主频早已超过3GHz，内存也进入了普及DDR4的时代。然而传统硬盘虽然在存储容量上增长迅速，但是在读写性能上并无明显提升，同时SSD硬盘价格高昂，不能在短时间内完全替代传统硬盘。传统磁盘的I&#x2F;O读写速度成为了计算机系统性能提高的瓶颈，制约了计算机整体性能的发展。</p><p>硬盘性能的制约因素是什么？如何根据磁盘I&#x2F;O特性来进行系统设计？针对这些问题，本文将介绍硬盘的物理结构和性能指标，以及操作系统针对磁盘性能所做的优化，最后讨论下基于磁盘I&#x2F;O特性设计的技巧。</p><h3 id="硬盘的物理结构"><a href="#硬盘的物理结构" class="headerlink" title="硬盘的物理结构"></a>硬盘的物理结构</h3><p>硬盘内部主要部件为磁盘盘片、传动手臂、读写磁头和主轴马达。实际数据都是写在盘片上，读写主要是通过传动手臂上的读写磁头来完成。实际运行时，主轴让磁盘盘片转动，然后传动手臂可伸展让读取头在盘片上进行读写操作。磁盘物理结构如下图所示：</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/disk-io/disk.png" alt="磁盘结构"></p><span id="more"></span><p>由于单一盘片容量有限，一般硬盘都有两张以上的盘片，每个盘片有两面，都可记录信息，所以一张盘片对应着两个磁头。盘片被分为许多扇形的区域，每个区域叫一个扇区，硬盘中每个扇区的大小固定为512字节。盘片表面上以盘片中心为圆心，不同半径的同心圆称为磁道，不同盘片相同半径的磁道所组成的圆柱称为柱面。磁道与柱面都是表示不同半径的圆，在许多场合，磁道和柱面可以互换使用。磁盘盘片垂直视角如下图所示：</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/disk-io/panpian.png" alt="磁盘垂直视角"></p><p>早期的硬盘每磁道扇区数相同，此时由磁盘基本参数可以计算出硬盘的容量：存储容量&#x3D;磁头数<em>磁道（柱面）数</em>每道扇区数*每扇区字节数。由于每磁道扇区数相同，外圈磁道半径大，里圈磁道半径小，外圈和里圈扇区面积自然会不一样。同时，为了更好的读取数据，即使外圈扇区面积再大也只能和内圈扇区一样存放相同的字节数（512字节）。这样一来，外圈的记录密度就要比内圈小，会浪费大量的存储空间。</p><p>如今的硬盘都使用ZBR（Zoned Bit Recording，区位记录）技术，盘片表面由里向外划分为数个区域，不同区域的磁道扇区数目不同，同一区域内各磁道扇区数相同，盘片外圈区域磁道长扇区数目较多，内圈区域磁道短扇区数目较少，大体实现了等密度，从而获得了更多的存储空间。此时，由于每磁道扇区数各不相同，所以传统的容量计算公式就不再适用。实际上如今的硬盘大多使用LBA（Logical Block Addressing）逻辑块寻址模式，知道LBA后即可计算出硬盘容量。</p><h3 id="影响硬盘性能的因素"><a href="#影响硬盘性能的因素" class="headerlink" title="影响硬盘性能的因素"></a>影响硬盘性能的因素</h3><p>影响磁盘的关键因素是磁盘服务时间，即磁盘完成一个I&#x2F;O请求所花费的时间，它由寻道时间、旋转延迟和数据传输时间三部分构成。</p><h4 id="1-寻道时间"><a href="#1-寻道时间" class="headerlink" title="1. 寻道时间"></a>1. 寻道时间</h4><p>Tseek是指将读写磁头移动至正确的磁道上所需要的时间。寻道时间越短，I&#x2F;O操作越快，目前磁盘的平均寻道时间一般在3-15ms。</p><h4 id="2-旋转延迟"><a href="#2-旋转延迟" class="headerlink" title="2. 旋转延迟"></a>2. 旋转延迟</h4><p>Trotation是指盘片旋转将请求数据所在的扇区移动到读写磁盘下方所需要的时间。旋转延迟取决于磁盘转速，通常用磁盘旋转一周所需时间的1&#x2F;2表示。比如：7200rpm的磁盘平均旋转延迟大约为60*1000&#x2F;7200&#x2F;2 &#x3D; 4.17ms，而转速为15000rpm的磁盘其平均旋转延迟为2ms。</p><h4 id="3-数据传输时间"><a href="#3-数据传输时间" class="headerlink" title="3. 数据传输时间"></a>3. 数据传输时间</h4><p>Ttransfer是指完成传输所请求的数据所需要的时间，它取决于数据传输率，其值等于数据大小除以数据传输率。目前IDE&#x2F;ATA能达到133MB&#x2F;s，SATA II可达到300MB&#x2F;s的接口数据传输率，数据传输时间通常远小于前两部分消耗时间。简单计算时可忽略。</p><h3 id="衡量性能的指标"><a href="#衡量性能的指标" class="headerlink" title="衡量性能的指标"></a>衡量性能的指标</h3><p>机械硬盘的连续读写性能很好，但随机读写性能很差，这主要是因为磁头移动到正确的磁道上需要时间，随机读写时，磁头需要不停的移动，时间都浪费在了磁头寻址上，所以性能不高。衡量磁盘的重要主要指标是IOPS和吞吐量。</p><h4 id="1-IOPS"><a href="#1-IOPS" class="headerlink" title="1. IOPS"></a>1. IOPS</h4><p>IOPS（Input&#x2F;Output Per Second）即每秒的输入输出量（或读写次数），即指每秒内系统能处理的I&#x2F;O请求数量。随机读写频繁的应用，如小文件存储等，关注随机读写性能，IOPS是关键衡量指标。可以推算出磁盘的IOPS &#x3D; 1000ms &#x2F; (Tseek + Trotation + Transfer)，如果忽略数据传输时间，理论上可以计算出随机读写最大的IOPS。常见磁盘的随机读写最大IOPS为：</p><p>7200rpm的磁盘 IOPS &#x3D; 76 IOPS<br>10000rpm的磁盘IOPS &#x3D; 111 IOPS<br>15000rpm的磁盘IOPS &#x3D; 166 IOPS</p><h4 id="2-吞吐量"><a href="#2-吞吐量" class="headerlink" title="2. 吞吐量"></a>2. 吞吐量</h4><p>吞吐量（Throughput），指单位时间内可以成功传输的数据数量。顺序读写频繁的应用，如视频点播，关注连续读写性能、数据吞吐量是关键衡量指标。它主要取决于磁盘阵列的架构，通道的大小以及磁盘的个数。不同的磁盘阵列存在不同的架构，但他们都有自己的内部带宽，一般情况下，内部带宽都设计足够充足，不会存在瓶颈。磁盘阵列与服务器之间的数据通道对吞吐量影响很大，比如一个2Gbps的光纤通道，其所能支撑的最大流量仅为250MB&#x2F;s。最后，当前面的瓶颈都不再存在时，硬盘越多的情况下吞吐量越大。</p><h3 id="操作系统层的优化"><a href="#操作系统层的优化" class="headerlink" title="操作系统层的优化"></a>操作系统层的优化</h3><p>虽然15000rpm的磁盘计算出的理论最大IOPS仅为166，但在实际运行环境中，实际磁盘的IOPS往往能够突破200甚至更高。这其实就是在系统调用过程中，操作系统进行了一系列的优化。</p><p>那么操作系统是如何操作硬盘的呢？类似于网络的分层结构，下图显示了Linux系统中对于磁盘的一次读请求在核心空间中所要经历的层次模型。从图中看出：对于磁盘的一次读请求，首先经过虚拟文件系统层（VFS Layer），其次是具体的文件系统层（例如Ext2），接下来是Cache层（Page Cache Layer）、通用块层（Generic Block Layer）、I&#x2F;O调度层（I&#x2F;O Scheduler Layer）、块设备驱动层（Block Device Driver Layer），最后是物理块设备层（Block Device Layer）。<br><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/disk-io/VFS.png" alt="系统调用在核心空间中的处理层次"></p><h4 id="虚拟文件系统层（VFS-Layer）"><a href="#虚拟文件系统层（VFS-Layer）" class="headerlink" title="虚拟文件系统层（VFS Layer）"></a>虚拟文件系统层（VFS Layer）</h4><p>VFS（Virtual File System）虚拟文件系统是一种软件机制，更确切的说扮演着文件系统管理者的角色，与它相关的数据结构只存在于物理内存当中。它的作用是：屏蔽下层具体文件系统操作的差异，为上层的操作提供一个统一的接口。正是因为有了这个层次，Linux中允许众多不同的文件系统共存并且对文件的操作可以跨文件系统而执行。</p><p>VFS中包含着向物理文件系统转换的一系列数据结构，如VFS超级块、VFS的Inode、各种操作函数的转换入口等。Linux中VFS依靠四个主要的数据结构来描述其结构信息，分别为超级块、索引结点、目录项和文件对象。</p><ol><li><p>超级块（Super Block）：超级块对象表示一个文件系统。它存储一个已安装的文件系统的控制信息，包括文件系统名称（比如Ext2）、文件系统的大小和状态、块设备的引用和元数据信息（比如空闲列表等等）。VFS超级块存在于内存中，它在文件系统安装时建立，并且在文件系统卸载时自动删除。同时需要注意的是对于每个具体的文件系统来说，也有各自的超级块，它们存放于磁盘。</p></li><li><p>索引结点（Inode）：索引结点对象存储了文件的相关元数据信息，例如：文件大小、设备标识符、用户标识符、用户组标识符等等。Inode分为两种：一种是VFS的Inode，一种是具体文件系统的Inode。前者在内存中，后者在磁盘中。所以每次其实是将磁盘中的Inode调进填充内存中的Inode，这样才是算使用了磁盘文件Inode。当创建一个文件的时候，就给文件分配了一个Inode。一个Inode只对应一个实际文件，一个文件也会只有一个Inode。</p></li><li><p>目录项（Dentry）：引入目录项对象的概念主要是出于方便查找文件的目的。不同于前面的两个对象，目录项对象没有对应的磁盘数据结构，只存在于内存中。一个路径的各个组成部分，不管是目录还是普通的文件，都是一个目录项对象。如，在路径&#x2F;home&#x2F;source&#x2F;test.java中，目录 &#x2F;, home, source和文件 test.java都对应一个目录项对象。VFS在查找的时候，根据一层一层的目录项找到对应的每个目录项的Inode，那么沿着目录项进行操作就可以找到最终的文件。</p></li><li><p>文件对象（File）：文件对象描述的是进程已经打开的文件。因为一个文件可以被多个进程打开，所以一个文件可以存在多个文件对象。一个文件对应的文件对象可能不是惟一的，但是其对应的索引节点和目录项对象肯定是惟一的。</p></li></ol><h4 id="Ext2文件系统"><a href="#Ext2文件系统" class="headerlink" title="Ext2文件系统"></a>Ext2文件系统</h4><p>VFS的下一层即是具体的文件系统，本节简要介绍下Linux的Ext2文件系统。</p><p>一个文件系统一般使用块设备上一个独立的逻辑分区。对于Ext2文件系统来说，硬盘分区首先被划分为一个个的Block，一个Ext2文件系统上的每个Block都是一样大小的。但是不同Ext2文件系统，Block大小可能不同，这是在创建Ext2系统决定的，一般为1k或者4k。由于Block数量很多，为了方便管理，Ext2将这些Block聚集在一起分为几个大的块组（Block Group），每个块组包含的等量的物理块，在块组的数据块中存储文件或目录。Ext2文件系统存储结构如下图所示：</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/disk-io/ext2.png" alt="ext2文件系统存储结构"></p><p>Ext2中的Super Block和Inode Table分别对应VFS中的超级块和索引结点，存放在磁盘。每个块组都有一个块组描述符GDT（Group Descriptor Table），存储一个块组的描述信息，例如在这个块组中从哪里开始是Inode表，从哪里开始是数据块等等。Block Bitmap和Inode Bitmap分别表示Block和Inode是否空闲可用。Data Block数据块是用来真正存储文件内容数据的地方，下面我们看一下具体的存储规则。</p><p>在Ext2文件系统中所支持的Block大小有1K、2K、4K三种。在格式化时Block的大小就固定了，且每个Block都有编号，方便Inode的记录。每个Block内最多只能够放置一个文件的数据，如果文件大于Block的大小，则一个文件会占用多个Block；如果文件小于Block，则该Block的剩余容量就不能够再被使用了，即磁盘空间会浪费。下面看看Inode和Block的对应关系。</p><p>Inode要记录的数据非常多，但大小仅为固定的128字节，同时记录一个Block号码就需要4字节，假设一个文件有400MB且每个Block为4K时，那么至少也要十万笔Block号码的记录。Inode不可能有这么多的记录信息，因此Ext2将Inode记录Block号码的区域定义为12个直接、一个间接、一个双间接与一个三间接记录区。Inode存储结构如下图所示：</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/disk-io/innode.png" alt="inode结构示意图"></p><p>最左边为Inode本身（128 bytes），里面有12个直接指向Block号码的对照，这12笔记录能够直接取得Block号码。至于所谓的间接就是再拿一个Block来当作记录Block号码的记录区，如果文件太大时，就会使用间接的Block来记录编号。如上图当中间接只是拿一个Block来记录额外的号码而已。 同理，如果文件持续长大，那么就会利用所谓的双间接，第一个Block仅再指出下一个记录编号的Block在哪里，实际记录的在第二个Block当中。依此类推，三间接就是利用第三层Block来记录编号。</p><h4 id="Page-Cache层"><a href="#Page-Cache层" class="headerlink" title="Page Cache层"></a>Page Cache层</h4><p>引入Cache层的目的是为了提高Linux操作系统对磁盘访问的性能。Cache层在内存中缓存了磁盘上的部分数据。当数据的请求到达时，如果在Cache中存在该数据且是最新的，则直接将数据传递给用户程序，免除了对底层磁盘的操作，提高了性能。Cache层也正是磁盘IOPS为什么能突破200的主要原因之一。</p><p>在Linux的实现中，文件Cache分为两个层面，一是Page Cache，另一个Buffer Cache，每一个Page Cache包含若干Buffer Cache。Page Cache主要用来作为文件系统上的文件数据的缓存来用，尤其是针对当进程对文件有read&#x2F;write操作的时候。Buffer Cache则主要是设计用来在系统对块设备进行读写的时候，对块进行数据缓存的系统来使用。</p><p>磁盘Cache有两大功能：预读和回写。预读其实就是利用了局部性原理，具体过程是：对于每个文件的第一个读请求，系统读入所请求的页面并读入紧随其后的少数几个页面（通常是三个页面），这时的预读称为同步预读。对于第二次读请求，如果所读页面不在Cache中，即不在前次预读的页中，则表明文件访问不是顺序访问，系统继续采用同步预读；如果所读页面在Cache中，则表明前次预读命中，操作系统把预读页的大小扩大一倍，此时预读过程是异步的，应用程序可以不等预读完成即可返回，只要后台慢慢读页面即可，这时的预读称为异步预读。任何接下来的读请求都会处于两种情况之一：第一种情况是所请求的页面处于预读的页面中，这时继续进行异步预读；第二种情况是所请求的页面处于预读页面之外，这时系统就要进行同步预读。</p><p>回写是通过暂时将数据存在Cache里，然后统一异步写到磁盘中。通过这种异步的数据I&#x2F;O模式解决了程序中的计算速度和数据存储速度不匹配的鸿沟，减少了访问底层存储介质的次数，使存储系统的性能大大提高。Linux 2.6.32内核之前，采用pdflush机制来将脏页真正写到磁盘中，什么时候开始回写呢？下面两种情况下，脏页会被写回到磁盘：</p><ol><li><p>在空闲内存低于一个特定的阈值时，内核必须将脏页写回磁盘，以便释放内存。</p></li><li><p>当脏页在内存中驻留超过一定的阈值时，内核必须将超时的脏页写会磁盘，以确保脏页不会无限期地驻留在内存中。<br>回写开始后，pdflush会持续写数据，直到满足以下两个条件：</p></li><li><p>已经有指定的最小数目的页被写回到磁盘。</p></li><li><p>空闲内存页已经回升，超过了阈值。<br>Linux 2.6.32内核之后，放弃了原有的pdflush机制，改成了bdi_writeback机制。bdi_writeback机制主要解决了原有fdflush机制存在的一个问题：在多磁盘的系统中，pdflush管理了所有磁盘的Cache，从而导致一定程度的I&#x2F;O瓶颈。bdi_writeback机制为每个磁盘都创建了一个线程，专门负责这个磁盘的Page Cache的刷新工作，从而实现了每个磁盘的数据刷新在线程级的分离，提高了I&#x2F;O性能。</p></li></ol><p>回写机制存在的问题是回写不及时引发数据丢失（可由sync|fsync解决），回写期间读I&#x2F;O性能很差。</p><h4 id="通用块层"><a href="#通用块层" class="headerlink" title="通用块层"></a>通用块层</h4><p>通用块层的主要工作是：接收上层发出的磁盘请求，并最终发出I&#x2F;O请求。该层隐藏了底层硬件块设备的特性，为块设备提供了一个通用的抽象视图。</p><p>对于VFS和具体的文件系统来说，块（Block）是基本的数据传输单元，当内核访问文件的数据时，它首先从磁盘上读取一个块。但是对于磁盘来说，扇区是最小的可寻址单元，块设备无法对比它还小的单元进行寻址和操作。由于扇区是磁盘的最小可寻址单元，所以块不能比扇区还小，只能整数倍于扇区大小，即一个块对应磁盘上的一个或多个扇区。一般来说，块大小是2的整数倍，而且由于Page Cache层的最小单元是页（Page），所以块大小不能超过一页的长度。</p><p>大多情况下，数据的传输通过DMA方式。旧的磁盘控制器，仅仅支持简单的DMA操作：每次数据传输，只能传输磁盘上相邻的扇区，即数据在内存中也是连续的。这是因为如果传输非连续的扇区，会导致磁盘花费更多的时间在寻址操作上。而现在的磁盘控制器支持“分散&#x2F;聚合”DMA操作，这种模式下，数据传输可以在多个非连续的内存区域中进行。为了利用“分散&#x2F;聚合”DMA操作，块设备驱动必须能处理被称为段（segments）的数据单元。一个段就是一个内存页面或一个页面的部分，它包含磁盘上相邻扇区的数据。</p><p>通用块层是粘合所有上层和底层的部分，一个页的磁盘数据布局如下图所示：</p><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/disk-io/page.png" alt="页内磁盘数据布局"></p><h4 id="I-x2F-O调度层"><a href="#I-x2F-O调度层" class="headerlink" title="I&#x2F;O调度层"></a>I&#x2F;O调度层</h4><p>I&#x2F;O调度层的功能是管理块设备的请求队列。即接收通用块层发出的I&#x2F;O请求，缓存请求并试图合并相邻的请求。并根据设置好的调度算法，回调驱动层提供的请求处理函数，以处理具体的I&#x2F;O请求。</p><p>如果简单地以内核产生请求的次序直接将请求发给块设备的话，那么块设备性能肯定让人难以接受，因为磁盘寻址是整个计算机中最慢的操作之一。为了优化寻址操作，内核不会一旦接收到I&#x2F;O请求后，就按照请求的次序发起块I&#x2F;O请求。为此Linux实现了几种I&#x2F;O调度算法，算法基本思想就是通过合并和排序I&#x2F;O请求队列中的请求，以此大大降低所需的磁盘寻道时间，从而提高整体I&#x2F;O性能。</p><p>常见的I&#x2F;O调度算法包括Noop调度算法（No Operation）、CFQ（完全公正排队I&#x2F;O调度算法）、DeadLine（截止时间调度算法）、AS预测调度算法等。</p><ul><li><p>Noop算法：最简单的I&#x2F;O调度算法。该算法仅适当合并用户请求，并不排序请求。新的请求通常被插在调度队列的开头或末尾，下一个要处理的请求总是队列中的第一个请求。这种算法是为不需要寻道的块设备设计的，如SSD。因为其他三个算法的优化是基于缩短寻道时间的，而SSD硬盘没有所谓的寻道时间且I&#x2F;O响应时间非常短。</p></li><li><p>CFQ算法：算法的主要目标是在触发I&#x2F;O请求的所有进程中确保磁盘I&#x2F;O带宽的公平分配。算法使用许多个排序队列，存放了不同进程发出的请求。通过散列将同一个进程发出的请求插入同一个队列中。采用轮询方式扫描队列，从第一个非空队列开始，依次调度不同队列中特定个数（公平）的请求，然后将这些请求移动到调度队列的末尾。</p></li><li><p>Deadline算法：算法引入了两个排队队列分别包含读请求和写请求，两个最后期限队列包含相同的读和写请求。本质就是一个超时定时器，当请求被传给电梯算法时开始计时。一旦最后期限队列中的超时时间已到，就想请求移至调度队列末尾。Deadline算法避免了电梯调度策略（为了减少寻道时间，会优先处理与上一个请求相近的请求）带来的对某个请求忽略很长一段时间的可能。</p></li><li><p>AS算法：AS算法本质上依据局部性原理，预测进程发出的读请求与刚被调度的请求在磁盘上可能是“近邻”。算法统计每个进程I&#x2F;O操作信息，当刚刚调度了由某个进程的一个读请求之后，算法马上检查排序队列中的下一个请求是否来自同一个进程。如果是，立即调度下一个请求。否则，查看关于该进程的统计信息，如果确定进程p可能很快发出另一个读请求，那么就延迟一小段时间。</p></li></ul><p>前文中计算出的IOPS是理论上的随机读写的最大IOPS，在随机读写中，每次I&#x2F;O操作的寻址和旋转延时都不能忽略不计，有了这两个时间的存在也就限制了IOPS的大小。现在如果我们考虑在读取一个很大的存储连续分布在磁盘的文件，因为文件的存储的分布是连续的，磁头在完成一个读I&#x2F;O操作之后，不需要重新寻址，也不需要旋转延时，在这种情况下我们能到一个很大的IOPS值。这时由于不再考虑寻址和旋转延时，则性能瓶颈仅是数据传输时延，假设数据传输时延为0.4ms，那么IOPS&#x3D;1000 &#x2F; 0.4 &#x3D; 2500 IOPS。</p><p>在许多的开源框架如Kafka、HBase中，都通过追加写的方式来尽可能的将随机I&#x2F;O转换为顺序I&#x2F;O，以此来降低寻址时间和旋转延时，从而最大限度的提高IOPS。</p><h4 id="块设备驱动层"><a href="#块设备驱动层" class="headerlink" title="块设备驱动层"></a>块设备驱动层</h4><p>驱动层中的驱动程序对应具体的物理块设备。它从上层中取出I&#x2F;O请求，并根据该I&#x2F;O请求中指定的信息，通过向具体块设备的设备控制器发送命令的方式，来操纵设备传输数据。这里不再赘述。</p><h3 id="基于磁盘I-x2F-O特性设计的技巧"><a href="#基于磁盘I-x2F-O特性设计的技巧" class="headerlink" title="基于磁盘I&#x2F;O特性设计的技巧"></a>基于磁盘I&#x2F;O特性设计的技巧</h3><p>在上一节中我们了解了Linux系统中请求到达磁盘的一次完整过程，期间Linux通过Cache以及排序合并I&#x2F;O请求来提高系统的性能。其本质就是由于磁盘随机读写慢、顺序读写快。本节针对常见开源系统阐述一些基于磁盘I&#x2F;O特性的设计技巧。</p><h4 id="采用追加写"><a href="#采用追加写" class="headerlink" title="采用追加写"></a>采用追加写</h4><p>在进行系统设计时，良好的读性能和写性能往往不可兼得。在许多常见的开源系统中都是优先在保证写性能的前提下来优化读性能。那么如何设计能让一个系统拥有良好的写性能呢？一个好的办法就是采用追加写，每次将数据添加到文件。由于完全是顺序的，所以可以具有非常好的写操作性能。但是这种方式也存在一些缺点：从文件中读一些数据时将会需要更多的时间：需要倒序扫描，直到找到所需要的内容。当然在一些简单的场景下也能够保证读操作的性能：</p><ul><li><p>数据是被整体访问，比如HDFS</p><ul><li>HDFS建立在一次写多次读的模型之上。在HDFS中就是采用了追加写并且设计为高数据吞吐量；高吞吐量必然以高延迟为代价，所以HDFS并不适用于对数据访问要求低延迟的场景；由于采用是的追加写，也并不适用于任意修改文件的场景。HDFS设计为流式访问大文件，使用大数据块并且采用流式数据访问来保证数据被整体访问，同时最小化硬盘的寻址开销，只需要一次寻址即可，这时寻址时间相比于传输时延可忽略，从而也拥有良好的读性能。HDFS不适合存储小文件，原因之一是由于NameNode内存不足问题，还有就是因为访问大量小文件需要执行大量的寻址操作，并且需要不断的从一个datanode跳到另一个datanode，这样会大大降低数据访问性能。</li></ul></li><li><p>知道文件明确的偏移量，比如Kafka</p><ul><li>在Kafka中，采用消息追加的方式来写入每个消息，每个消息读写时都会利用Page Cache的预读和后写特性，同时partition中都使用顺序读写，以此来提高I&#x2F;O性能。虽然Kafka能够根据偏移量查找到具体的某个消息，但是查找过程是顺序查找，因此如果数据很大的话，查找效率就很低。所以Kafka中采用了分段和索引的方式来解决查找效率问题。Kafka把一个patition大文件又分成了多个小文件段，每个小文件段以偏移量命名，通过多个小文件段，不仅可以使用二分搜索法很快定位消息，同时也容易定期清除或删除已经消费完的文件，减少磁盘占用。为了进一步提高查找效率，Kafka为每个分段后的数据建立了索引文件，并通过索引文件稀疏存储来降低元数据占用大小。一个段中数据对应结构如下图所示：</li></ul></li></ul><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/disk-io/kafka.png" alt="kafka中一个段的物理结构"></p><p>在面对更复杂的读场景（比如按key）时，如何来保证读操作的性能呢？简单的方式是像Kafka那样，将文件数据有序保存，使用二分查找来优化效率；或者通过建索引的方式来进行优化；也可以采用hash的方式将数据分割为不同的桶。以上的方法都能增加读操作的性能，但是由于在数据上强加了数据结构，又会降低写操作的性能。比如如果采用索引的方式来优化读操作，那么在更新索引时就需要更新B-tree中的特定部分，这时候的写操作就是随机写。那么有没有一种办法在保证写性能不损失的同时也提供较好的读性能呢？一个好的选择就是使用LSM-tree。LSM-tree与B-tree相比，LSM-tree牺牲了部分读操作，以此大幅提高写性能。</p><p>日志结构的合并树LSM（The Log-Structured Merge-Tree）是HBase，LevelDB等NoSQL数据库的存储引擎。Log-Structured的思想是将整个磁盘看做一个日志，在日志中存放永久性数据及其索引，每次都添加到日志的末尾。并且通过将很多小文件的存取转换为连续的大批量传输，使得对于文件系统的大多数存取都是顺序的，从而提高磁盘I&#x2F;O。LSM-tree就是这样一种采用追加写、数据有序以及将随机I&#x2F;O转换为顺序I&#x2F;O的延迟更新，批量写入硬盘的数据结构。LSM-tree将数据的修改增量先保存在内存中，达到指定的大小限制后再将这些修改操作批量写入磁盘。因此比较旧的文件不会被更新，重复的纪录只会通过创建新的纪录来覆盖，这也就产生了一些冗余的数据。所以系统会周期性的合并一些数据，移除重复的更新或者删除纪录，同时也会删除上述的冗余。在进行读操作时，如果内存中没有找到相应的key，那么就是倒序从一个个磁盘文件中查找。如果文件越来越多那么读性能就会越来越低，目前的解决方案是采用页缓存来减少查询次数，周期合并文件也有助于提高读性能。在文件越来越多时，可通过布隆过滤器来避免大量的读文件操作。LSM-tree牺牲了部分读性能，以此来换取写入的最大化性能，特别适用于读需求低，会产生大量插入操作的应用环境。</p><h4 id="文件合并和元数据优化"><a href="#文件合并和元数据优化" class="headerlink" title="文件合并和元数据优化"></a>文件合并和元数据优化</h4><p>目前的大多数文件系统，如XFS&#x2F;Ext4、GFS、HDFS，在元数据管理、缓存管理等实现策略上都侧重大文件。上述基于磁盘I&#x2F;O特性设计的系统都有一个共性特点就是都运行在这些文件系统之上。这些文件系统在面临海量时在性能和存储效率方面都大幅降低，本节来探讨下海量小文件下的系统设计。</p><p>常见文件系统在海量小文件应用下性能表现不佳的根本原因是磁盘最适合顺序的大文件I&#x2F;O读写模式，而非常不适合随机的小文件I&#x2F;O读写模式。主要原因体现在元数据管理低效和数据布局低效：</p><p>元数据管理低效：由于小文件数据内容较少，因此元数据的访问性能对小文件访问性能影响巨大。Ext2文件系统中Inode和Data Block分别保存在不同的物理位置上，一次读操作需要至少经过两次的独立访问。在海量小文件应用下，Inode的频繁访问，使得原本的并发访问转变为了海量的随机访问，大大降低了性能。另外，大量的小文件会快速耗尽Inode资源，导致磁盘尽管有大量Data Block剩余也无法存储文件，会浪费磁盘空间。</p><p>数据布局低效：Ext2在Inode中使用多级指针来索引数据块。对于大文件，数据块的分配会尽量连续，这样会具有比较好的空间局部性。但是对于小文件，数据块可能零散分布在磁盘上的不同位置，并且会造成大量的磁盘碎片，不仅造成访问性能下降，还大量浪费了磁盘空间。数据块一般为1KB、2KB或4KB，对于小于4KB的小文件，Inode与数据的分开存储破坏了空间局部性，同时也造成了大量的随机I&#x2F;O。</p><p>对于海量小文件应用，常见的I&#x2F;O流程复杂也是造成磁盘性能不佳的原因。对于小文件，磁盘的读写所占用的时间较少，而用于文件的open()操作占用了绝大部分系统时间，导致磁盘有效服务时间非常低，磁盘性能低下。针对于问题的根源，优化的思路大体上分为：</p><p>针对数据布局低效，采用小文件合并策略，将小文件合并为大文件。<br>针对元数据管理低效，优化元数据的存储和管理。针对这两种优化方式，业内也出现了许多优秀的开源软件。</p><h4 id="小文件合并"><a href="#小文件合并" class="headerlink" title="小文件合并"></a>小文件合并</h4><p>小文件合并为大文件后，首先减少了大量元数据，提高了元数据的检索和查询效率，降低了文件读写的I&#x2F;O操作延时。其次将可能连续访问的小文件一同合并存储，增加了文件之间的局部性，将原本小文件间的随机访问变为了顺序访问，大大提高了性能。同时，合并存储能够有效的减少小文件存储时所产生的磁盘碎片问题，提高了磁盘的利用率。最后，合并之后小文件的访问流程也有了很大的变化，由原来许多的open操作转变为了seek操作，定位到大文件具体的位置即可。如何寻址这个大文件中的小文件呢？其实就是利用一个旁路数据库来记录每个小文件在这个大文件中的偏移量和长度等信息。其实小文件合并的策略本质上就是通过分层的思想来存储元数据。中控节点存储一级元数据，也就是大文件与底层块的对应关系；数据节点存放二级元数据，也就是最终的用户文件在这些一级大块中的存储位置对应关系，经过两级寻址来读写数据。</p><p>淘宝的TFS就采用了小文件合并存储的策略。TFS中默认Block大小为64M，每个块中会存储许多不同的小文件，但是这个块只占用一个Inode。假设一个Block为64M，数量级为1PB。那么NameServer上会有 1 1024 1024 * 1024 &#x2F; 64 &#x3D; 16.7M个Block。假设每个Block的元数据大小为0.1K，则占用内存不到2G。在TFS中，文件名中包含了Block ID和File ID，通过Block ID定位到具体的DataServer上，然后DataServer会根据本地记录的信息来得到File ID所在Block的偏移量，从而读取到正确的文件内容。TFS一次读过程如下图所示：<br><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/disk-io/TFS.png" alt="tfs_read"></p><h4 id="元数据管理优化"><a href="#元数据管理优化" class="headerlink" title="元数据管理优化"></a>元数据管理优化</h4><p>一般来说元数据信息包括名称、文件大小、设备标识符、用户标识符、用户组标识符等等，在小文件系统中可以对元数据信息进行精简，仅保存足够的信息即可。元数据精简可以减少元数据通信延时，同时相同容量的Cache能存储更多的元数据，从而提高元数据使用效率。另外可以在文件名中就包含元数据信息，从而减少一个元数据的查询操作。最后针对特别小的一些文件，可以采取元数据和数据并存的策略，将数据直接存储在元数据之中，通过减少一次寻址操作从而大大提高性能。</p><p>TFS中文件命名就隐含了位置信息等部分元数据，从而减少了一个元数据的查询操作。在Rerserfs中，对于小于1KB的小文件，Rerserfs可以将数据直接存储在Inode中。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本文从磁盘性能指标出发，探究了操作系统与磁盘的交互以及对磁盘读写的优化，最后列举了一些常用开源系统中基于磁盘I&#x2F;O特性的设计特点。期望通过展现磁盘I&#x2F;O的特性，为存储系统设计和解决一些系统性能问题提供一种新思路。</p>]]></content>
      
      
      <categories>
          
          <category> CS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> IO </tag>
            
            <tag> 数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>工程师跨越成长视频笔记</title>
      <link href="/article/career-growth.html"/>
      <url>/article/career-growth.html</url>
      
        <content type="html"><![CDATA[<p>今天看了一个分享视频，来自<a href="http://www.yxtvg.com/toutiao/5413179/20180607V0R7XU00.html">美团技术学院院长刘江的分享</a>。结合最近自己在公司里，对除技术外其他技能的要求有所反思，觉得有必要对这个分享做个纪要。下面是刘江老师的分享主要内容（包括主持人提问回答）。</p><h3 id="技术人员需要的技能"><a href="#技术人员需要的技能" class="headerlink" title="技术人员需要的技能"></a>技术人员需要的技能</h3><p>之前觉得技术很牛逼很重要，很多事情的改变都是由技术推动的，但渐渐发现跟技术同等重要的事情还有很多。技术人员的能力要求分为四个方面：技术知识，技术能力，通用能力，专业影响力。</p><p>技术知识和技术能力是一个工程师通识的技能要求，毕竟要完成任务。但是沟通能力，以及商业sense也是很重要的。随着职级上升，沟通表达能力以及<strong>商业sense</strong>也越来越重要（上次去数据库大会，百度首席科学家毕然老师也强调了商业sense）。没有商业sense的技术在公司是没有价值的。而团队合作，作为leader是需要通过演讲来凝聚团队，给与团队目标。职级越高，对表达能力要求越高。而专业影响力在于沉淀，通过文字或者演技总结经验，传输给别人。通过博客或者演讲让自己在业界有一定影响力。</p><p>公司在对技术人员培养上，也需要给予表达和演讲这样的平台和机会，push他们，让他们走出舒适区，提升自己的软实力。</p><span id="more"></span><h3 id="周报，Wiki文化"><a href="#周报，Wiki文化" class="headerlink" title="周报，Wiki文化"></a>周报，Wiki文化</h3><p>对技术解决问题通过Wiki记录下来，开会也要记录会议纪要。这些才是资产，而不是做了就做了，没有沉淀。通过沉淀，后来的员工也能够很好的避免之前遇到的坑。也减少了做类似技术选型这样的决策时前期的技术调研，提升了整个公司的效率。</p><h3 id="技术人员的年龄问题"><a href="#技术人员的年龄问题" class="headerlink" title="技术人员的年龄问题"></a>技术人员的年龄问题</h3><p>年龄大对于程序员竞争力下降是个伪命题，不是因为年龄大了，公司就不需要你了。而是看是否能力能够match。像院士这些，仍然是我们的国之珍宝。而经验丰富的技术人员，也是非常吃香的。所以最重要还是看能力。</p><h3 id="工程师要有自我判断能力，主人翁精神"><a href="#工程师要有自我判断能力，主人翁精神" class="headerlink" title="工程师要有自我判断能力，主人翁精神"></a>工程师要有自我判断能力，主人翁精神</h3><p>在中国大部分公司，技术人员是成本部门，技术是被动的，是用于帮助别人解决问题。工程师的价值怎样才能体现？作为工程师，很重要的一点是要有批判意识。根据自己的水平以及业务了解，能为当前需求做出判断，给出建议，以及勇敢的说不。而不是被产品，业务牵着鼻子走，如果这个需求是无价值的，就浪费了公司的资源。所以技术人员需要有对业务的判断能力。</p><p>对比美国硅谷文化和国内文化，有一点很大的不同。就是美国工程师往往具有主人翁意识，能够对需求给予很高的分量，对需求负责。需要对业务理解，以用户为中心，了解用户，最后再以技术来解决用户问题。</p><h3 id="工具积累，提升工作效率"><a href="#工具积累，提升工作效率" class="headerlink" title="工具积累，提升工作效率"></a>工具积累，提升工作效率</h3><p>工程师存在的价值就是用机器来取代人工，提升效率。工程师需要对工作上任务进行工具抽象，例如wiki。通过工具来减少人工管理的成本。另外对于有些商业工具，如果能够提高员工的工作效率，能够买的就买，毕竟工程师自身成本也是很高的。</p><h3 id="微软购买GitHub"><a href="#微软购买GitHub" class="headerlink" title="微软购买GitHub"></a>微软购买GitHub</h3><p>首先是对技术人员价值的肯定。微软购买的是GitHub上的技术人员，GitHub上的代码是开源的，对于微软来说是没有商业价值的。另一方面，GitHub应该不止值这么多钱，问题在哪呢？这么多年来，GitHub增长变缓，而创始人团队却没有思考出一个商业价值来。对比wiki,confluence的公司atlassian,知名度没有GitHub高，但现在市值却是GitHub的两倍。所以对于创始人团队，必须思考自己公司是<strong>赚什么人的什么钱</strong>，这点很重要，一个好的商业模式才能支撑公司不断走下去。</p>]]></content>
      
      
      <categories>
          
          <category> 成长 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 职业 </tag>
            
            <tag> 成长 </tag>
            
            <tag> 工程师 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>打算观看的美剧</title>
      <link href="/article/American-drama.html"/>
      <url>/article/American-drama.html</url>
      
        <content type="html"><![CDATA[<p>马上又要到一年一度的国产电影保护月，为了避免被好莱坞，甚至宝莱坞电影的冲击，为国产电影票房提供保障，这不就是经济学中的价格下限么。借用前面<a href="/2018/06/09/economic-thinking-one/#%E4%BB%B7%E6%A0%BC%E4%B8%8A%E9%99%90%E4%B8%8E%E4%BB%B7%E6%A0%BC%E4%B8%8B%E9%99%90">经济学</a>文章里面所讲的价格下限。价格下限会造成供大于求。因为受到了保护，失去了市场的充分竞争，造成生产的商品质量进一步下降。人们购买（观看电影）的欲望下降，而因为生产者受到了保护，使其更愿意生产。这样供需处于均衡点的下方，造成供大于求。<strong>当然，就算不保护国产电影，也是一如既往的烂。</strong></p><p>而且最近fbb事件，4天片酬6000w还逃税，以及某些明星动不动就是一亿的合同。就这样，这些明星的演技差的掉牙，竟然胱垫总橘还搞出来国产电影保护月。让整个国产电影的质量进一步下降，真是脑子被驴踢了。</p><p>就像之前冯导说的“这届观众不行”，和某网站的悖论一样：系统推荐的都是xx新闻，用户说怎么老推荐xx新闻呢；网站说系统就是根据用户的习惯和喜好，通过算法推荐的。所以到底是用户不行还是？而且，就是这么烂的国产电影还是挺赚钱的，让我也陷入了深思。</p><p>吐槽归吐槽，虽然没有什么美国大片（不让进，你能怎么办！），但最近好像有几部美剧还不错。所以我先记在小本本上。</p><span id="more"></span><h3 id="西部世界2"><a href="#西部世界2" class="headerlink" title="西部世界2"></a>西部世界2</h3><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/article/westworld.png"><br>看了美帝很多人工智能大片和科幻片，心中一直两个有个疑问：1，如果机器有了思维，能自我思考，有意识，那和人有区别么？毕竟大家都是由原子，分子构成。2，如果科技越来越发达，统治者也就更能的进行统治和剥削，而那些没权没钱的人是不是会过的更惨？这里面有个相对的概念，从时间维度来说，确实比老祖宗们过的便捷，体验更多；而在空间对比上，有权有钱的人会掠夺更多，因为手段多了。当然这也是因为优者更优，财富垄断等原因造成的。</p><h3 id="超感猎杀1，2"><a href="#超感猎杀1，2" class="headerlink" title="超感猎杀1，2"></a>超感猎杀1，2</h3><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/article/kill.png"><br>这部剧讲来自不同国家不同城市的八位陌生人实现了通感，他们不同身份，不同性取向，命运却开始彼此相连。不仅共享情感和思想，还能共享语言和技能。</p><p>这部剧由沃卓斯基兄弟，现在不能叫兄弟了&#x3D;。&#x3D; 导演的，也就是导演《黑客帝国》的俩，脑洞也是真是大。</p><h3 id="使女的故事1，2"><a href="#使女的故事1，2" class="headerlink" title="使女的故事1，2"></a>使女的故事1，2</h3><p><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/article/tale.png"><br>这部剧讲诉了未来社会，环境污染严重，人口出生率急剧下滑，这种情况下，一个极端的宗教组织趁势崛起，在美国发动政变，建立了基列共和国。</p><p>这个国家，男权当道，女性成为男性附属，内部社会分为三六九等，完全与外界隔离，所有人的最高的使命都是：<em><strong>生育</strong></em>。</p><p><strong><a href="https://baike.baidu.com/tashuo/browse/content?id=508cb2fb142516169509ee12&lemmaId=19921023&lemmaId=19921023&fr=qingtian">故事来源于现实，无数历史经验告诉我们： 历史的车轮也并非都是朝前进，它有时候也会倒退，去碾压平等，正义与自由。但如果故事有一天变成了现实。但愿我们每一个人，都不是温水中慢慢被烫死的可怜青蛙。而是一只敢举起弱小手臂，阻挡黑暗邪恶的勇敢“螳螂”</a></strong></p><h3 id="影评"><a href="#影评" class="headerlink" title="影评"></a>影评</h3><p>哈哈哈，还没看呢，评啥评~</p><p>看完了再写影评，有好看的再添加。</p>]]></content>
      
      
      <categories>
          
          <category> 影视 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 美剧 </tag>
            
            <tag> 科技 </tag>
            
            <tag> 人性 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>spark加速Bulkload</title>
      <link href="/article/spark-bulkload.html"/>
      <url>/article/spark-bulkload.html</url>
      
        <content type="html"><![CDATA[<p>本文介绍HBase在大数据量导入时Bulkload的操作过程，以及使用spark加速整个Bulkload。</p><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在第一次建立Hbase表的时候，我们可能需要往里面一次性导入大量的初始化数据。我们很自然地想到将数据一条条插入到Hbase中，或者通过MR方式等。但是这些方式不是慢就是在导入的过程的占用Region资源导致效率低下，所以很不适合一次性导入大量数据。使用 Bulk Load 方式由于利用了 HBase 的数据信息是按照特定格式存储在 HDFS 里的这一特性，直接在 HDFS 中生成持久化的 HFile 数据格式文件，然后完成巨量数据快速入库的操作，配合 MapReduce 完成这样的操作，不占用 Region 资源，不会产生巨量的写入 I&#x2F;O，所以需要较少的 CPU 和网络资源。</p><h2 id="Bulkload实现过程"><a href="#Bulkload实现过程" class="headerlink" title="Bulkload实现过程"></a>Bulkload实现过程</h2><h3 id="利用MR生成HFile"><a href="#利用MR生成HFile" class="headerlink" title="利用MR生成HFile"></a>利用MR生成HFile</h3><p>因为HBase底层存储结构是HFile，而Hbase API为我们提供了生成HFile，我们只需要按照要求，写Mapper，生成特定的(ImmutableBytesWritable, Put)对，或者(ImmutableBytesWritable, KeyValue)即可。</p><span id="more"></span><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">BulkLoadMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, ImmutableBytesWritable, Put&gt;&#123;</span><br><span class="line">        <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">            <span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span> value.toString();</span><br><span class="line">            String[] items = line.split(<span class="string">&quot;\t&quot;</span>);</span><br><span class="line">  </span><br><span class="line">            <span class="type">ImmutableBytesWritable</span> <span class="variable">rowKey</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ImmutableBytesWritable</span>(items[<span class="number">0</span>].getBytes());</span><br><span class="line">            <span class="type">Put</span> <span class="variable">put</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Put</span>(Bytes.toBytes(items[<span class="number">0</span>]));   <span class="comment">//ROWKEY</span></span><br><span class="line">            put.addColumn(<span class="string">&quot;f1&quot;</span>.getBytes(), <span class="string">&quot;url&quot;</span>.getBytes(), items[<span class="number">1</span>].getBytes());</span><br><span class="line">            put.addColumn(<span class="string">&quot;f1&quot;</span>.getBytes(), <span class="string">&quot;name&quot;</span>.getBytes(), items[<span class="number">2</span>].getBytes());</span><br><span class="line">            </span><br><span class="line">            context.write(rowkey, put);</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Mapper中的KEYIN, VALUEIN根据你的文件格式来指定读取类。</p><p>MR驱动程序类：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">BulkLoadDriver</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException, InterruptedException &#123;</span><br><span class="line">        <span class="keyword">final</span> String SRC_PATH= <span class="string">&quot;hdfs://input&quot;</span>;</span><br><span class="line">        <span class="keyword">final</span> String DESC_PATH= <span class="string">&quot;hdfs://output&quot;</span>;</span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> HBaseConfiguration.create();</span><br><span class="line">       </span><br><span class="line">        Job job=Job.getInstance(conf);</span><br><span class="line">        job.setJarByClass(BulkLoadDriver.class);</span><br><span class="line">        job.setMapperClass(BulkLoadMapper.class);</span><br><span class="line">        job.setMapOutputKeyClass(ImmutableBytesWritable.class);</span><br><span class="line">        <span class="comment">/** 根据VALUEOUT 类别指定Put 或者 KeyValue</span></span><br><span class="line"><span class="comment">         *框架会自行根据 MapOutputValueClass 来决定是使用 KeyValueSortReducer 还是 PutSortReducer</span></span><br><span class="line"><span class="comment">        **/</span></span><br><span class="line">        job.setMapOutputValueClass(Put.class);  </span><br><span class="line">        job.setOutputFormatClass(HFileOutputFormat2.class);</span><br><span class="line">        <span class="type">HTable</span> <span class="variable">table</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">HTable</span>(conf,<span class="string">&quot;user_tag&quot;</span>);</span><br><span class="line">        HFileOutputFormat2.configureIncrementalLoad(job,table,table.getRegionLocator());</span><br><span class="line">        FileInputFormat.addInputPath(job,<span class="keyword">new</span> <span class="title class_">Path</span>(SRC_PATH));</span><br><span class="line">        FileOutputFormat.setOutputPath(job,<span class="keyword">new</span> <span class="title class_">Path</span>(DESC_PATH));</span><br><span class="line">          </span><br><span class="line">        System.exit(job.waitForCompletion(<span class="literal">true</span>)?<span class="number">0</span>:<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="通过BlukLoad方式加载HFile文件"><a href="#通过BlukLoad方式加载HFile文件" class="headerlink" title="通过BlukLoad方式加载HFile文件"></a>通过BlukLoad方式加载HFile文件</h3><p>生成的HFile还需要通过LoadIncrementalHFiles类的doBulkLoad方法，将HFile加载入hbase的目录下。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> HBaseConfiguration.create();</span><br><span class="line"><span class="type">Connection</span> <span class="variable">connection</span> <span class="operator">=</span> ConnectionFactory.createConnection(configuration);</span><br><span class="line"><span class="type">LoadIncrementalHFiles</span> <span class="variable">loder</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">LoadIncrementalHFiles</span>(configuration);</span><br><span class="line">loder.doBulkLoad(<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;hdfs://output&quot;</span>),<span class="keyword">new</span> <span class="title class_">HTable</span>(conf,<span class="string">&quot;table_name&quot;</span>));</span><br></pre></td></tr></table></figure><h2 id="使用spark进行Bulkload"><a href="#使用spark进行Bulkload" class="headerlink" title="使用spark进行Bulkload"></a>使用spark进行Bulkload</h2><p>在前面生成HFile的步骤中，使用了MR生成，效率较慢，且不能很好的使用hive特性，只能从底层读取hdfs文件进行解析，对于不同格式的数据文件需要进行不同操作。而通过使用spark on hive可以很好的借用hive特性，屏蔽底层数据文件格式，且使用spark也在执行效率上进行提升。<br>和MR类似，使用spark也是通过把数据转换成(ImmutableBytesWritable, Put)对，或者(ImmutableBytesWritable, KeyValue)对，示例如下：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> partitionData = data.rdd.map(s =&gt; &#123;</span><br><span class="line">      ((s.get(<span class="number">0</span>).toString, s.get(<span class="number">1</span>).toString, s.getString(<span class="number">2</span>)), s.getString(<span class="number">3</span>))</span><br><span class="line">    &#125;).repartitionAndSortWithinPartitions(<span class="keyword">new</span> <span class="type">SaltPrefixPartitioner</span>(hashV))</span><br><span class="line">    </span><br><span class="line"><span class="keyword">val</span> hfile = partitionData.map &#123; s =&gt;</span><br><span class="line">      <span class="keyword">val</span> uid = s._1._1</span><br><span class="line">      <span class="keyword">val</span> rowkey = uid</span><br><span class="line">      <span class="keyword">val</span> immutable = <span class="keyword">new</span> <span class="type">ImmutableBytesWritable</span>(<span class="type">Bytes</span>.toBytes(rowkey))</span><br><span class="line">      <span class="keyword">val</span> value = s._2</span><br><span class="line">      <span class="keyword">val</span> keyValue = <span class="keyword">new</span> <span class="type">KeyValue</span>(<span class="type">Bytes</span>.toBytes(rowkey), <span class="type">Bytes</span>.toBytes(s._1._2),</span><br><span class="line">        <span class="type">Bytes</span>.toBytes(s._1._3), <span class="type">Utils</span>.transferDateToTs(dt), <span class="type">Bytes</span>.toBytes(value))</span><br><span class="line">      (immutable, keyValue)</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>在示例中，data是个DataFrame，schema为：用户id,列族，列名，value。但是我们在查询hive数据时往往表结构为用户id，列1，列2 …. ，所以需要把其转成hbase存储方式（rowkey，family,qualifier,value）。其中有个很重要的一步：repartitionAndSortWithinPartitions。在MR时，MR框架会进行SortReducer，所以刚好满足了HFile有序的要求，但是spark计算生成HFile的过程中只有map类算子，是无序的，所以需要手工进行排序操作。<strong>在Hbase中，需要按照(rowkey，family,qualifier)顺序进行排序</strong>，因为我在Hbase表进行了手工region划分，而region可正好对应spark partition，所以就很好的利用repartitionAndSortWithinPartitions这个算子进行region划分并对region中的数据进行排序了。SaltPrefixPartitioner是我实现的根据用户id进行hash分区的算法。</p><p>然后仍然需要定义个Job,和BulkLoadDriver中一样，指定MapOutputKeyClass，MapOutputValueClass，OutputFormatClass，然后使用HFileOutputFormat2.configureIncrementalLoad(job,table,table.getRegionLocator()) ，再调用rdd的算子saveAsNewAPIHadoopFile。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hfile.saveAsNewAPIHadoopFile(stagingFolder, classOf[ImmutableBytesWritable], classOf[KeyValue], classOf[HFileOutputFormat2], job.getConfiguration)</span><br></pre></td></tr></table></figure><p>这样就按照HFile格式把数据生成在了stagingFolder目录中，最后还需执行Bulkload步骤。</p><h2 id="spark-Bulkload的一些注意事项"><a href="#spark-Bulkload的一些注意事项" class="headerlink" title="spark Bulkload的一些注意事项"></a>spark Bulkload的一些注意事项</h2><h3 id="kerberos权限问题"><a href="#kerberos权限问题" class="headerlink" title="kerberos权限问题"></a>kerberos权限问题</h3><p>在整个过程中，其实是使用了两套账号，在提交spark的过程中，是spark的账号管理，且会提交给yarn(所以账号权限是客户端的账号权限)；而使用MR的话，整个job是通过程序中的configuration配置的，所以你可以对其进行任何权限配置。在Bulkload过程中，也是使用配程序configuration，也是可随意账号配置。而Bulkload只是个普通hdfs操作，并没有通过yarn（也在调研能否通过yarn模式）。</p><h3 id="数据snappy压缩问题"><a href="#数据snappy压缩问题" class="headerlink" title="数据snappy压缩问题"></a>数据snappy压缩问题</h3><p>有时候我们需要把HFile进行压缩，以减少文件存储，在这里我使用了snappy压缩（snappy在存储和CPU计算上相对其他压缩算法更平衡）。因为snappy压缩依赖snappy.so本地方法库，在进行spark计算生成HFile或Bulkload过程中都可能出现这样的错误：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java.lang.RuntimeException: native snappy library not available: this version of libhadoop was built without snappy support</span><br></pre></td></tr></table></figure><p>如果在spark计算生成HFile过程中报错，这就涉及了spark配置读取的问题（因为我们集群对snappy压缩是没问题的，这肯定是在spark任务提交过程中读取了错误的配置项），后续我会专门讲解spark的配置加载。因为我们spark客户端（docker镜像）是官网spark版本，而集群是使用的CDH部署的，所以在配置上有所不同，以及spark文件路径也有所不同。所以问题也出于此，最终在spark-default.conf加上即可。</p><p>而在Bulkload过程中，通过LoadIncrementalHFiles源码我们可以知道，因为会根据region进行加载（groupOrSplitPhase），他会去读取HFile文件的位置偏移，如果当前执行Bulkload客户端的hadoop没有snappy库或者配置错误的话，也就读取HFile失败。</p><h2 id="后续"><a href="#后续" class="headerlink" title="后续"></a>后续</h2><p>HBase 官方和cloudera都提供了hbase-spark模块，里面有HbaseContext类，很好的封装了spark在Hbase上面的使用（包括读取Hbase数据转成rdd，Bulkload等），但cloudera版本的使用的spark依然为1.6，所以在使用过程中需要依赖的包也是1.6，而我们docker环境的spark版本是2.0，会有一些问题（看了下code，竟然引入了spark某个不重要的Logging类，然鹅在2.0这个类被移了位置 囧），后续也没有更新了。<br>Apache hbase-spark_2.0我看源码好像修复了，不在依赖具体spark中的logging类了，但我们CDH中的hbase版本降低，担心会有其他影响，便还未进行测试。</p>]]></content>
      
      
      <categories>
          
          <category> 数据工程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spark </tag>
            
            <tag> hbase </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>经济思维读书笔记（二）</title>
      <link href="/article/economic-thinking-two.html"/>
      <url>/article/economic-thinking-two.html</url>
      
        <content type="html"><![CDATA[<p>主要是以下两本书的读书笔记：《斯坦福极简经济学》，《经济学的思维方式》。本篇是第二篇，这篇主要介绍宏观经济。我认为宏观经济让我们关注社会资产变动，能让我们更好的理解加息，降准等货币政策背后的真正意图，以及这些政策对自己资产的影响。</p><h3 id="宏观经济"><a href="#宏观经济" class="headerlink" title="宏观经济"></a>宏观经济</h3><p>宏观经济政策的四个目标是：经济增长，充分就业，物价稳定和国际收支平衡。</p><p>宏观经济政策的两组主要工具：财政政策和货币政策。</p><p>财政政策是政府税收和支出的政策，包括政府预算和预算赤字。货币政策是值中央银行的政策，它会影响利率，信用以及社会上借贷与放款的数量。</p><h3 id="GDP与经济增长"><a href="#GDP与经济增长" class="headerlink" title="GDP与经济增长"></a>GDP与经济增长</h3><p>GDP：一年内所生产的最终商品和服务的总价值。GDP&#x3D;C+I+G+X-M,也就是消费+投资+政府支出+出口-进口。</p><p>经济长期增长的根本原因是生产力的提升。生产力增长的三大驱动因素：实物资本增加（更多的资本设备让员工使用），更多的人力资本（员工有更多的经验或者更好的教育）以及更好的技术（更有效率的生产方式）。</p><span id="more"></span><h3 id="通胀"><a href="#通胀" class="headerlink" title="通胀"></a>通胀</h3><p>通货膨胀，是指任一商品与服务的价格全面上升的现象。</p><p>通胀不是什么坏事。<strong>然而，现实世界中，通货膨胀不是均匀分配的，且不容易预知，因此会有某些团体收益，并把成本转嫁给别人。</strong></p><p>通胀的鸽派认为，2%-5%的通胀并不是洪水猛兽。假如通胀率是4%，员工只加薪2%，其实就是变相减薪，但看起来像加薪，所以不会伤害员工士气。<strong>温和的通货膨胀，优于过度补贴所造成的通货紧缩。通货紧缩会使目前的所有贷款额变高，且会造成违约欠款增加，导致经济增长停滞。</strong></p><h3 id="贸易顺差"><a href="#贸易顺差" class="headerlink" title="贸易顺差"></a>贸易顺差</h3><p>贸易差额：贸易顺差与逆差，是指金钱的流向，以及向哪边的流动比较大。</p><p>贸易顺差和贸易逆差谈的不是商品的流向，谈的是金钱的流向！<br><em>题外话：这次贸易战就是因为钱从美国流向中国，但中国却不去美国消费或者投资。当然还有其他一些原因，不扩散</em></p><h3 id="短期看需求，长期看供给"><a href="#短期看需求，长期看供给" class="headerlink" title="短期看需求，长期看供给"></a>短期看需求，长期看供给</h3><p>萨伊定律：主张“供给创造其自身的需求”。基于这个理论，宏观经济意义上的供应价值，必定在社会某处创造了等值的收入及需求。支持萨伊定律的经济学家，称为新古典学派经济学家。萨伊定律面临的主要挑战是经济衰退。</p><p>凯恩斯法则：主张“需求创造自身的供给”。凯恩斯认为，经济大萧条以及很多一般性的经济衰退，不是由潜在供给下降引起的。相反，经济衰退是因为整个社会缺乏需求，导致生产者没有足够的动力生产。凯恩斯法则的主要挑战是需求可以通过政府大量增加支出或大幅减税来促进消费，但供给取决于劳动力数量，实物资本，可获取的技术以及市场结构与经济制度所限制。</p><p>在萨伊定律和凯恩斯法则之间一个看似折中的方法：短期看需求，长期看供给。</p><h3 id="财政政策"><a href="#财政政策" class="headerlink" title="财政政策"></a>财政政策</h3><p>财政政策服务于经济增长，充分就业，物价稳定和国际收支平衡。</p><p>财政政策通过调节税收和支出来影响社会需求。使社会的总需求或购买力提高的政策，称为“宽松”的财政政策，相反，称为“紧缩”的财政政策。</p><h3 id="货币政策"><a href="#货币政策" class="headerlink" title="货币政策"></a>货币政策</h3><p>注：货币，银行又是一个很大的学科，平时我们经常听到的“加息”，“降息”，“降准”等都是央行为了调节社会货币的总需求，来调节通货，就业等。</p><h4 id="货币"><a href="#货币" class="headerlink" title="货币"></a>货币</h4><p>什么是货币？具备下列三个功能的任何物品：交易媒介，价值储存，记账单位。</p><p><strong>在恶性通胀情况下，货币几乎不能再称为货币，因为它再也不能储存价值</strong></p><p>银行通过放款的过程来创造货币。银行依法必须持有一部分存款作为准备金。当银行拼命放款时，由于这些放款造成购买力增加，社会将会出现大量的总需求。反之，社会的购买力和总需求减少。</p><h4 id="中央银行"><a href="#中央银行" class="headerlink" title="中央银行"></a>中央银行</h4><p>在中国，就是央行；在美国，是美联储。</p><p>货币政策是指货币供给的扩张或收缩，其目的是助长或抑制总需求。中央银行有三个传统工具，可在银行与货币的架构内运作：法定准备金，贴现率，公开市场操作。</p><p>美联储锁定一个特定利率，称为“联邦基金利率”。联邦基金利率是银行同业间短期隔夜放款的利率，随着这个利率的上升或下降，其他利率会大致同步上升或下降。</p><h3 id="中国当前经济"><a href="#中国当前经济" class="headerlink" title="中国当前经济"></a>中国当前经济</h3><p>下图是我画的当前经济图（水平有限，有错望提出），在前面说到宏观经济政策的四个目标是：经济增长，充分就业，物价稳定和国际收支平衡。但因为社会需求，内部供给，外部环境等原因，这些目标之间存在着矛盾点。<br><img src="https://hexo-1256892004.cos.ap-beijing.myqcloud.com/article/macro-economy.png"><br>因为消费，政府支出和出口是现阶段经济增长的主要方面，且政府拉动的投资和出口占据了主要比例，为了经济的增长，需要稳住出口和政府投资。但因现在房地产泡沫严重，政府需要进行去杠杆，开始货币紧缩的政策，造成社会上总购买力和总需求减少。同时因为美国进行加息，因为美元是国际化货币，全球贸易只认美元，所以为了稳定出口顺差，我们还需要稳住和美元的汇率，也需要加息等货币紧缩的政策。因为去杠杆和美元加息，企业融资变难，渐渐有些企业爆发债务危机。另一方面，由于历史原因，很多地方财政收入主要依赖土地财政，因为房地产去杠杆及社会购买力下降，地方财政开始出现财政赤字。所以之前出现房地产定向加息，以及向企业进行的定向降准等货币政策，都是为了维持房地产的泡沫不进一步扩大，又能让企业苟活着，不至于造成大量的失业。</p><p>内部环境与外部环境都让当前情形日益艰难，巨象接下来会怎样，这就考验智囊团的智慧了，我们吃瓜就行了。大家可以大胆预测，毕竟<strong>赌国运成功的人，有曾被亏待过吗？</strong></p>]]></content>
      
      
      <categories>
          
          <category> 经济 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 经济 </tag>
            
            <tag> 思维 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>经济思维读书笔记（一）</title>
      <link href="/article/economic-thinking-one.html"/>
      <url>/article/economic-thinking-one.html</url>
      
        <content type="html"><![CDATA[<p>主要是以下两本书的读书笔记：《斯坦福极简经济学》，《经济学的思维方式》，本篇是第一篇。经济思维并不能帮助我们像金融那样赚钱，但能帮助我们更好的做决策。</p><h3 id="经济学的三个基础问题"><a href="#经济学的三个基础问题" class="headerlink" title="经济学的三个基础问题"></a>经济学的三个基础问题</h3><blockquote><p>社会应该生产什么？</p></blockquote><blockquote><p>应该怎么生产？</p></blockquote><blockquote><p>谁来消费所生产的东西？</p></blockquote><p>这三个问题是每种经济制度乃至每个社会的基础，无论是资本主义，社会主义还是共产主义，或是低收入，中等收入或高收入社会。</p><p>经济学与政治立场无关，经济学是一个思考问题的架构。</p><p>自利(self-interest)是组成社会的有效方式。每个人通常不打算促进公共利益，只盘算自己的利益，但被一只看不见的手引导，去促成一个与他本意无关的目的。（_？如果只靠市场，整个社会似乎会平衡大家的私利。那法律，道德在中间扮演的角色又是什么，是否必需要_）</p><span id="more"></span><p>所有成本都是机会成本。当你做一个选择时，你没有选择的东西就是经济学家所谓的“机会成本”。</p><h3 id="市场均衡点"><a href="#市场均衡点" class="headerlink" title="市场均衡点"></a>市场均衡点</h3><p>交换价值与使用价值</p><p>替代效应与收入效应</p><blockquote><p>商品价格上涨，人们会拿其他商品替代；</p><p>商品价格上涨，收入的购买力降低。</p></blockquote><p>需求量：在某一特定价格下，人们想得到该商品的特定数量。</p><p>需求：是价格与需求量之间的关系，指的是每种价格下，人们想要该商品的数量是多少。</p><p>均衡点：需求量等于供给量的点。</p><h3 id="价格上限与价格下限"><a href="#价格上限与价格下限" class="headerlink" title="价格上限与价格下限"></a>价格上限与价格下限</h3><p>价格上限造成供不应求：</p><p>如果设定的价格上限低于原本的均衡价，那么想购买的消费者的反应就会很热烈，但该商品的供给者则不然。</p><p>价格下限造成供大于求。</p><p><em>价格上限与下限，在学理上并不是最好的政策工具，却是官方最倾向采取的方案。看起来像零成本的政策，因为政府不需要增加支出或减税。事实上，价格管制会掩盖成本。</em></p><h3 id="弹性"><a href="#弹性" class="headerlink" title="弹性"></a>弹性</h3><p>经济学中的弹性是什么？通俗的理解，就是可替代性的大小，比如香烟，价格涨了，对于有烟瘾的人来说，需求还是在那，价格波动对他影响很小。但是像猪肉这种，价格上涨，人们可以用牛肉，羊肉代替，价格波动对其影响就很大。</p><p>供给弹性的定义是供给量变动的百分比除以价格变动的百分比。</p><p>书中的问题，州提高香烟税，税收能转接到消费者么？同样类似问题，在天朝，提高房产交易的税，税能转接到买房的人身上么？</p><h3 id="金融市场与报酬率"><a href="#金融市场与报酬率" class="headerlink" title="金融市场与报酬率"></a>金融市场与报酬率</h3><p>从经济学家的观点来看，资本需求也是借款人的资金需求量与他们需要支付的报酬率之间的关系。</p><p>折现值就是未来这笔钱值多少钱。</p><p>评估投资标的时，要衡量四个要项：报酬率，风险，流动性，税负。</p><h3 id="外部性"><a href="#外部性" class="headerlink" title="外部性"></a>外部性</h3><h4 id="负外部性与环境"><a href="#负外部性与环境" class="headerlink" title="负外部性与环境"></a>负外部性与环境</h4><p>解决环境污染的方法，已经从命令与控制转变为市场导向的激励设计。</p><p>环保人士会把自由市场视为环境的敌人，其实自由市场并不是环境的最大敌人。在这里，核心的经济学概念是“外部性”，指在直接的买家和卖家之外，有第三方直接受到这笔交易的影响。</p><p>外部性可以是正面的或者负面的。污染是负外部性最重要的例子。在不受约束的市场交易中，厂商为了私人成本，至于社会成本，是不用支付的生产成本，因此厂商不会将其纳入考虑范围。</p><p>市场为导向的环保管控，文中列举了两种方案：</p><ul><li>可交易的许可制度</li><li>以财产权做激励</li></ul><h4 id="正外部性与技术"><a href="#正外部性与技术" class="headerlink" title="正外部性与技术"></a>正外部性与技术</h4><p>自由市场并不保证会给发明创造者奖励。</p><p>创新是正外部性。推动创新的关键因素，是创新者从研发投资中得到大部分经济利益的能力，经济学家称之为“专属性”。</p><h3 id="公共物品与缴税"><a href="#公共物品与缴税" class="headerlink" title="公共物品与缴税"></a>公共物品与缴税</h3><p>公共物品：顺着每个人自利的本性，将无法创造公共物品，所以政府必须征税来建设。</p><p>公共物品有两个重要特性：非竞争性与非排他性。非竞争性是指商品本身不会因为更多人使用而变少。非排他性是指卖家无法排除那些没付钱也能使用商品的人。</p><p>某些人从公共物品中受益，却没有付出相对合理的成本时，称为“搭便车(free-rider)”。</p><h3 id="信息不完全与保险"><a href="#信息不完全与保险" class="headerlink" title="信息不完全与保险"></a>信息不完全与保险</h3><p>信息不完全造成了保险市场难以解决的失衡问题。</p><p>信息完全情况下，会选择最便宜的；信息不完全情况下，会担心便宜的有问题。市场上有各种试图减少信息不完全的方法。担保，质押，资质证明这些都是用来减少信息不完全。</p><p>保险趋向于让更不容易赔偿的人来购买，让避免让容易赔偿的人购买，信息不完全造成了这样的失衡问题。（车险中有过赔偿的消费者下次购买保险，价格更高，估计也是为了消减这种信息不完全带来的损失）</p><h3 id="微观经济学总结"><a href="#微观经济学总结" class="headerlink" title="微观经济学总结"></a>微观经济学总结</h3><p>市场是非常有用的制度，社会可以通过市场来分配其稀有资源。市场为有效率的生产、创新、善用资源、满足消费者需求和欲望，以及逐渐提高生活水平提供动力。</p><p>市场有时可能会产生我们不想要的结果：垄断、不完全竞争、负外部性、贫穷、收入不均、信息不完全，以及管理不善的问题。</p><p>政府在处理市场问题时可以扮演有用的角色，但它的行动也是不完美的，某些情况下，可能会造成更大或者另外的问题。</p>]]></content>
      
      
      <categories>
          
          <category> 经济 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 经济 </tag>
            
            <tag> 思维 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hexo搭建博客教程相关链接</title>
      <link href="/article/hexo-link.html"/>
      <url>/article/hexo-link.html</url>
      
        <content type="html"><![CDATA[<h3 id="hexo-shell"><a href="#hexo-shell" class="headerlink" title="hexo shell"></a>hexo shell</h3><h4 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h4 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><span id="more"></span><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h4 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h4 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html">Deployment</a></p><h3 id="hexo搭建博客"><a href="#hexo搭建博客" class="headerlink" title="hexo搭建博客"></a>hexo搭建博客</h3><p><a href="https://yq.aliyun.com/articles/64953">github pages + Hexo + 域名绑定搭建个人博客</a></p><p><a href="https://formulahendry.github.io/2016/12/04/hexo-ci/">Hexo的版本控制与持续集成</a></p><p><a href="https://github.com/hexojs/hexo">hexo github</a></p><h3 id="主题"><a href="#主题" class="headerlink" title="主题"></a>主题</h3><p><a href="https://github.com/iissnan/hexo-theme-next">Next主题</a></p><p><a href="https://github.com/Molunerfinn/hexo-theme-melody">melody主题</a></p><p><a href="https://molunerfinn.com/hexo-theme-melody-doc/#/">melody主题配置</a></p><!-- More --><h3 id="插件"><a href="#插件" class="headerlink" title="插件"></a>插件</h3><p><a href="https://github.com/zhuzhuyule/HexoEditor">hexoEditor</a></p><p><a href="https://github.com/xCss/Valine">Valine评论框</a></p><p><a href="https://github.com/LouisBarranqueiro/hexo-algoliasearch">algolia搜索器</a></p>]]></content>
      
      
      <categories>
          
          <category> hexo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
